<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>Junhui&#39;s Journal</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Junhui&#39;s Journal">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Junhui&#39;s Journal">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Junhui">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Junhui&#39;s Journal" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 4.2.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Junhui&#39;s Journal</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-CUDA-并行一维卷积" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/02/28/CUDA-%E5%B9%B6%E8%A1%8C%E4%B8%80%E7%BB%B4%E5%8D%B7%E7%A7%AF/" class="article-date">
  <time datetime="2020-02-28T13:17:08.000Z" itemprop="datePublished">2020-02-28</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/CUDA/">CUDA</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/02/28/CUDA-%E5%B9%B6%E8%A1%8C%E4%B8%80%E7%BB%B4%E5%8D%B7%E7%A7%AF/">CUDA-并行一维卷积</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>卷积操作应用于许多领域，而其特点：计算量大，每个输出元素的计算都是相互独立的。这两个特点是并行计算期望处理的。卷积中对于边界的处理影响着分块算法的效率。</p>
<h1 id="一维卷积基本形式"><a href="#一维卷积基本形式" class="headerlink" title="一维卷积基本形式"></a>一维卷积基本形式</h1><p>假设一维数组N是被操作对象，一维数组M是卷积核，一维数组P为卷积结果。假如对于边界元素（幽灵元素）的处理是赋值为0，也就是说幽灵元素与对应的M元素的乘积为0.</p>
<p>每个thread负责P数组中的一个元素，那么一维卷积的基本形式如下图：</p>
<p>&lt;&gt;pic1&lt;&gt;</p>
<div align="center"><img src="/2020/02/28/CUDA-%E5%B9%B6%E8%A1%8C%E4%B8%80%E7%BB%B4%E5%8D%B7%E7%A7%AF/IMAGE_PATH.png" width="500"></div>

<div align="center">图：一维卷积基本形式</div>

<p>一个thread得到结果数组P中一个元素。实现：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">__<span class="function">global__ <span class="keyword">void</span> <span class="title">conv1D</span><span class="params">(<span class="keyword">float</span>* N, <span class="keyword">float</span>* M, <span class="keyword">float</span>* P, </span></span></span><br><span class="line"><span class="function"><span class="params">						<span class="keyword">int</span> kernelSize, <span class="keyword">int</span> NLength)</span></span>&#123;</span><br><span class="line">	<span class="keyword">int</span> tid = threadIdx.x + blockDim.x * blockIdx.x;</span><br><span class="line">	<span class="keyword">float</span> Pvalue = <span class="number">0.0f</span>;</span><br><span class="line">	<span class="keyword">int</span> start = tid-kernelSize/<span class="number">2</span>;</span><br><span class="line">	<span class="keyword">for</span> (<span class="keyword">int</span> j=<span class="number">0</span>; j&lt;kernelSize; j++)&#123;</span><br><span class="line">		<span class="keyword">if</span>(start + j &gt;= <span class="number">0</span> &amp;&amp; start + j &lt;= NLength)&#123;</span><br><span class="line">			Pvalue += N[start + j] * M[j]; 	</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	P[tid] = Pvalue;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>一般卷积核的长度是奇数，这样计算过程是对称的。</p>
<p>上述实现的缺点：</p>
<ul>
<li>代码中这句 <code>Pvalue += N[start + j] * M[j]</code>包含两次对Global 的访存，和两次算术运算（一个乘法，一个加法）。<font color="red">运算访存比</font>仅为1.0。性能有限。 </li>
<li>对边界的处理出现Divergence。</li>
</ul>
<h1 id="Constant-Memory优化的一维卷积"><a href="#Constant-Memory优化的一维卷积" class="headerlink" title="Constant Memory优化的一维卷积"></a>Constant Memory优化的一维卷积</h1><p>卷积操作有三个特点：</p>
<ol>
<li>考虑到卷积计算的过程，以及实际中的卷积操作，比如在Google Inception Net<a href="https://ashburnlee.github.io/2019/08/01/Google-Inception-Net-%E5%88%86%E7%BB%84%E5%8D%B7%E7%A7%AF%E5%8D%95%E5%85%83-Inception-Module/" target="_blank" rel="noopener">分组卷积</a>，MobileNet<a href="https://ashburnlee.github.io/2019/08/01/Mobile-Net-%E6%B7%B1%E5%BA%A6%E5%8F%AF%E5%88%86%E7%A6%BB%E5%8D%B7%E7%A7%AF/" target="_blank" rel="noopener">深度可分离卷积</a>，ResNet中的<a href="https://ashburnlee.github.io/2019/08/01/ResNet-%E6%AE%8B%E5%B7%AE%E5%AD%A6%E4%B9%A0%E5%8D%95%E5%85%83-Residual-Unit/" target="_blank" rel="noopener">残差学习单元</a>，中的描述，卷积核大小都是3x3, 1x1, 1x7, 7x1，5x5很小的卷积核。</li>
<li>卷积核的内容是不变的。</li>
<li>所有的threads都访问卷积核，并且访问顺序是一样的。</li>
</ol>
<p>根据这些特点结合Ray-Tracing这篇笔记中<a href="https://ashburnlee.github.io/2020/02/20/CUDA-%E5%B8%B8%E9%87%8F%E5%86%85%E5%AD%98%E6%8F%90%E5%8D%87%E6%80%A7%E8%83%BD-%E4%BE%8B-RayTracing/" target="_blank" rel="noopener">Constant Memory</a><br>描述的Constant Memory的特性。考虑将卷积核放入Constant Memory。</p>
<p>这里补充一点，Constant Memory中的内容对于所有Blocks可见。使用<code>.totalConstMem</code>可以查询其大小。</p>
<p>与Ray-Tracing中的使用一样：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> MAX_KERNEL_LENGTH 10;</span></span><br><span class="line">__constant__ <span class="keyword">float</span> M[MAX_KERNEL_LENGTH];</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="comment">// 在main函数中使用cudaMemcpy的特殊版本函数</span></span><br><span class="line">cudaMemcpyToSymbol(M, h_M, kernel_length*<span class="keyword">sizeof</span>(<span class="keyword">float</span>));</span><br><span class="line"></span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>kernel函数与基本形式一样，除了参数列表中不需要再传入卷积核数组M。</p>
<p>虽然Constant Memory在Global中，但是cuda知道Constant Memory中的内容是不变的。所以直接将其放入高速缓存中（L1缓存）。</p>
<p><font color="gree" size="4">补充</font><br><br>高速缓存的层次结构。从DRAM中访问一个变量需要数百上千个时钟周期，而且处理器处理数据要比访存快得多。DRAM的长延迟和有限带宽成了现代处理器的性能瓶颈，称为<font color="red" size="4">存储器墙</font>。现在的处理器都会有片内的高速缓存，来减少DRAM的访存次数。</p>
<p><font color="red" size="4">缓存一致性</font>使用高速缓存的一个重要设计问题是缓存一致性，当一个或多个处理器核心试图修改缓存中的数据时，问题出现了。每一个处理器核心有自己的L1缓存，如果这个被修改了，而其他核心的L1缓存不变，缓存中的内容就不一致了。在并行处理器中处理缓存一致性开销很大（就相当于实现全局线程同步开销很大一样）。所以GPU中没有缓存一致性的机制。</p>
<p>将Constant memory放到L1高速缓存中。WHY</p>
<ul>
<li>Constant memory中的内容在kernel执行期间<font color="red">不会被改变</font>，因此没有缓存一致性的问题干扰。所以硬件可以直接将Constant memory放到L1高速缓存中。</li>
<li>在处理器的缓存设计中通常优化了线程的广播。所以当一个warp中的线程访问同一个Constant memory中的变量时，<font color="red">高速缓存能为threads所需要的数据提供巨大的带宽</font>。</li>
</ul>
<h1 id="shared-memory优化的分块并行卷积"><a href="#shared-memory优化的分块并行卷积" class="headerlink" title="shared memory优化的分块并行卷积"></a>shared memory优化的分块并行卷积</h1><p>分析卷积过程，以一维卷积为例，假设卷积核的长度是5，N（Global）中有100个元素，其中每一个元素要平均被访问5次，那么就需要500次的Global memory的访存。显然，N中每个元素被访问了多次。所以考虑是用分块Shared memory来降低Global的访存。</p>
<p>假设N长度为15，M长度为5，block大小为4，Shared memory大小为4，输出到P。过程如下图：</p>
<p>&lt;&gt;pic2&lt;&gt;</p>
<div align="center"><img src="/2020/02/28/CUDA-%E5%B9%B6%E8%A1%8C%E4%B8%80%E7%BB%B4%E5%8D%B7%E7%A7%AF/IMAGE_PATH.png" width="500"></div>

<div align="center">图：一维分块卷积</div>

<p>每一个thread处理一个P中元素，对于每一个block，分两步操作：</p>
<ol>
<li>将数据从P中写入blocks对应的Shared 中。</li>
<li>执行卷积计算。</li>
</ol>
<p>而读入Shared的操作分为左中右，三部分</p>
<p>实现：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> KERNEL_LENGTH 5;</span></span><br><span class="line">__constant__ <span class="keyword">float</span> M[KERNEL_LENGTH]; <span class="comment">// 卷积核</span></span><br><span class="line"></span><br><span class="line">__<span class="function">global__ <span class="keyword">void</span> <span class="title">Convolution</span><span class="params">(<span class="keyword">float</span>* N, <span class="keyword">float</span>* P, <span class="keyword">int</span> N_size)</span></span>&#123;</span><br><span class="line">    __shared__ <span class="keyword">float</span> N_ds[TILE_SIZE + KERNEL_LENGTH<span class="number">-1</span>];</span><br><span class="line">    <span class="keyword">int</span> tid = threadIdx.x + blockDim.x * blockIdx.x;</span><br><span class="line">    <span class="keyword">int</span> n = KERNEL_LENGTH/<span class="number">2</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 读左</span></span><br><span class="line">    <span class="keyword">int</span> left = (blockIdx.x <span class="number">-1</span>)*blockDim.x + threadIdx.x;</span><br><span class="line">    <span class="keyword">if</span>(threadIdx.x &gt;= blockDim.x - n)&#123;</span><br><span class="line">        N_ds[threadIdx - (blockDim.x - n)] = (left&lt;<span class="number">0</span>) ? <span class="number">0</span> : N[left];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 读中</span></span><br><span class="line">    N_ds[n+threadIdx.x] = N[tid];</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 读右</span></span><br><span class="line">    <span class="keyword">int</span> right = (blockIdx.x + <span class="number">1</span>)*blockDim.x + threadIdx.x;</span><br><span class="line">    <span class="keyword">if</span>(threadIdx.x &lt; n)&#123;</span><br><span class="line">        N_ds[n+blockDim.x+threadIdx.x] = (left&gt;=N_size) ? <span class="number">0</span> : N[right];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    __syncthreads();</span><br><span class="line">    <span class="comment">// 卷积操作</span></span><br><span class="line">    <span class="keyword">float</span> Pvalue = <span class="number">0.0f</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;KERNEL_LENGTH; i++)&#123;</span><br><span class="line">        Pvalue += N_ds[threadIdx.x + i] * M[i];</span><br><span class="line">    &#125;</span><br><span class="line">    P[tid] = Pvalue;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h1 id="L2缓存了的分块并行卷积"><a href="#L2缓存了的分块并行卷积" class="headerlink" title="L2缓存了的分块并行卷积"></a>L2缓存了的分块并行卷积</h1><p><font color="red" size="5">新内容</font>:<br>上个实现的代码复杂度集中在了将左右元素加载到Shared 中，注意，一个block的左右元素，同时又是相邻block的内部元素，因此<font color="orange" size="4">很有可能在<code>block #1</code>需要这些左右元素时，它们已经由于<code>block #2</code>的访问而存储到了L2缓存上</font>。这样对于左右元素的访问从代码上是访问了global，实际上却是转化为对L2缓存的访问。依然达到减少Global访存的目的。</p>
<p>如此一来，shared memory 的大小变成如下，与block的大小一致了：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">__shared__ <span class="keyword">float</span> N_ds[TILE_SIZE];</span><br></pre></td></tr></table></figure>

<p>从而Shared memory的加载就更简单了：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> tid = threadIdx.x + blockDim.x * blockIdx.x;</span><br><span class="line">N_ds[threadIdx.x] = N[tid];</span><br></pre></td></tr></table></figure>

<p>之后就是对于每一个thread遍历卷积核中元素，乘累加。只是对于中间元素，已经存在于自己的Shared中了，访问自己的Shared；对于左右元素，访问<code>N</code>，实际上是访问L2 缓存。</p>
<p>实现与基本形式相似：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> KERNEL_LENGTH 5;</span></span><br><span class="line">__constant__ <span class="keyword">float</span> M[KERNEL_LENGTH]; <span class="comment">// 卷积核</span></span><br><span class="line"></span><br><span class="line">__<span class="function">global__ <span class="keyword">void</span> <span class="title">Convolution</span><span class="params">(<span class="keyword">float</span>* N, <span class="keyword">float</span>* P, <span class="keyword">int</span> N_size)</span></span>&#123;</span><br><span class="line">    __shared__ <span class="keyword">float</span> N_ds[TILE_SIZE];</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> tid = threadIdx.x + blockDim.x * blockIdx.x;</span><br><span class="line">    N_ds[threadIdx.x] = N[tid];</span><br><span class="line"></span><br><span class="line">    __syncthreads();</span><br><span class="line">    <span class="keyword">int</span> this_block_start = blockIdx.x * blockDim.x;</span><br><span class="line">    <span class="keyword">int</span> next_block_start = (blockIdx.x+<span class="number">1</span>) * blockDim.x;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> n_start = tid-(KERNEL_LENGTH/<span class="number">2</span>);</span><br><span class="line">    <span class="keyword">float</span> Pvalue=<span class="number">0.0f</span>;</span><br><span class="line">    <span class="comment">// 遍历卷积核：</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>;j&lt;KERNEL_LENGTH; j++)&#123;</span><br><span class="line">        <span class="keyword">int</span> index = n_start + j;</span><br><span class="line">        <span class="comment">// 对于有效Index：</span></span><br><span class="line">        <span class="keyword">if</span>(index&gt;=<span class="number">0</span> &amp;&amp; index&lt;=N_size)&#123;</span><br><span class="line">            <span class="comment">// 对于中间元素：</span></span><br><span class="line">            <span class="keyword">if</span>((index &gt;= this_block_start) &amp;&amp; (index &lt; next_block_start))&#123;</span><br><span class="line">                Pvalue += N_ds[threadIdx.x + j-KERNEL_LENGTH/<span class="number">2</span>]*M[j];</span><br><span class="line">            &#125;<span class="keyword">else</span>&#123;  <span class="comment">// 对于左右元素：</span></span><br><span class="line">                Pvalue += N[index]*M[j];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    P[tid] = Pvalue;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/02/28/CUDA-%E5%B9%B6%E8%A1%8C%E4%B8%80%E7%BB%B4%E5%8D%B7%E7%A7%AF/" data-id="ck767cchg0000odfzb9r43xl9" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/CUDA/" rel="tag">CUDA</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-LeetCode-方法论-stack" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/02/25/LeetCode-%E6%96%B9%E6%B3%95%E8%AE%BA-stack/" class="article-date">
  <time datetime="2020-02-25T04:21:48.000Z" itemprop="datePublished">2020-02-25</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/LeetCode/">LeetCode</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/02/25/LeetCode-%E6%96%B9%E6%B3%95%E8%AE%BA-stack/">LeetCode-方法论-stack</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>20, 1021, 1019, 155，921，</p>
<h2 id="20-valid-parenthese"><a href="#20-valid-parenthese" class="headerlink" title="#20 valid parenthese"></a>#20 valid parenthese</h2><ul>
<li><p>问题描述</p>
<p>  对于string S，判断是否是合法的括号对儿。</p>
<p>  如：</p>
  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&#123;[()]()&#125;()  合法</span><br><span class="line">&#123;()]       不合法</span><br></pre></td></tr></table></figure>
</li>
<li><p>思路</p>
<p>  遍历s：</p>
<ol>
<li><p>如果<code>s[i]</code>是左括号“(”，“[”, “{”，则入栈<code>stack.push(s[i])</code>。</p>
</li>
<li><p>如果是右括号，如果栈为空，表示第一个就不合法，结束。否则，记录栈顶元素<code>curr=stack.top()</code>，后出栈顶元素<code>stack.pop()</code>。</p>
</li>
<li><p>根据匹配规则，得到<code>curr</code><font color="red">应该</font>是什么，用<code>match</code>表示。然后匹配：看<code>实际curr</code>是否与<code>应该match</code>相同。若相同，继续遍历，否则不合法，结束。</p>
<p>关键：判断当前元素<font color="red">应该</font>是什么，与<font color="red">实际</font>是什么，是否一致。</p>
</li>
</ol>
</li>
<li><p>实现</p>
  <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">matchParenthese</span><span class="params">(<span class="built_in">string</span> S)</span></span>&#123;</span><br><span class="line">       <span class="built_in">stack</span>&lt;<span class="keyword">char</span>&gt; <span class="built_in">stack</span>;</span><br><span class="line">       <span class="comment">// 遍历每一个字符</span></span><br><span class="line">       <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;S.size(); i++)&#123;</span><br><span class="line">           <span class="comment">// 如果是'(', 入栈</span></span><br><span class="line">           <span class="keyword">if</span>(S[i] == <span class="string">'('</span> || S[i] == <span class="string">'['</span> || S[i] == <span class="string">'&#123;'</span> )</span><br><span class="line">               <span class="built_in">stack</span>.push(S[i]);</span><br><span class="line">           <span class="comment">// 如果是')'：</span></span><br><span class="line">           <span class="keyword">else</span> &#123;</span><br><span class="line">               <span class="comment">// 如果栈开始就为空，则不合法</span></span><br><span class="line">               <span class="keyword">if</span>(<span class="built_in">stack</span>.size() == <span class="number">0</span>) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">               <span class="comment">// 得到栈顶元素 “实际”是啥</span></span><br><span class="line">               <span class="keyword">char</span> curr = <span class="built_in">stack</span>.top();</span><br><span class="line">               <span class="built_in">stack</span>.pop();</span><br><span class="line">               <span class="comment">// 匹配原则 得到“应该”是啥</span></span><br><span class="line">               <span class="keyword">char</span> match;</span><br><span class="line">               <span class="keyword">if</span> (S[i] == <span class="string">')'</span>) match = <span class="string">'('</span>;</span><br><span class="line">               <span class="keyword">else</span> <span class="keyword">if</span>(S[i] == <span class="string">']'</span>) match = <span class="string">'['</span>;</span><br><span class="line">               <span class="keyword">else</span> <span class="keyword">if</span>(S[i] == <span class="string">'&#125;'</span>) match = <span class="string">'&#123;'</span>;</span><br><span class="line">                   </span><br><span class="line">               <span class="comment">// 这时才开始匹配 “实际”与“应该”一致否</span></span><br><span class="line">               <span class="keyword">if</span>(curr != match) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="keyword">if</span>(<span class="built_in">stack</span>.size() != <span class="number">0</span>) </span><br><span class="line">           <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">       <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</li>
</ul>
<p>这个问题是stack 的经典应用。</p>
<h2 id="1021-remove-outermost-parentheses"><a href="#1021-remove-outermost-parentheses" class="headerlink" title="#1021 remove outermost parentheses"></a>#1021 remove outermost parentheses</h2><ul>
<li><p>问题描述</p>
<p>  括号对儿是和法的。对于输入，返回输出：</p>
  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Input: <span class="string">"(()())(())"</span></span><br><span class="line">Ouput: <span class="string">"()()()"</span></span><br><span class="line">Explanation: </span><br><span class="line">The input string is <span class="string">"(()())(())"</span>, with primitive decomposition <span class="string">"(()())"</span> + <span class="string">"(())"</span>.</span><br><span class="line">After removing outer parentheses of each part, this is <span class="string">"()()"</span> + <span class="string">"()"</span> = <span class="string">"()()()"</span>.</span><br><span class="line"></span><br><span class="line">Input: <span class="string">"()()"</span></span><br><span class="line">Output: <span class="string">""</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>思路</p>
<ol>
<li><p>第一步，遍历<code>S</code>，将每一对儿最外层的括号的右括号的<code>Index</code>记录在<code>arr</code>中，（初始化的<code>arr</code>中有个-1）。例：</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">S:     ( ( (  ) ) )  ( ( ) ( )  )</span><br><span class="line">index: 0 1 2  3 4 5  6 7 8 9 10 11</span><br></pre></td></tr></table></figure>
<p> 根据描述，返回<code>arr: [-1, 5, 11]</code>。因为<code>0~5</code>是第一对儿最外层括号，<code>6~11</code>是第二对儿最外层括号。</p>
</li>
<li><p>第二步，对arr中的前<code>n-1</code>个元素，取<code>arr[i]+2</code>和<code>arr[i+1]-1</code>之间的 所有对应的<code>S</code>中的元素。结束。</p>
</li>
</ol>
</li>
</ul>
<ul>
<li><p>实现</p>
  <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="built_in">string</span> <span class="title">removeOutermostParentheses</span><span class="params">(<span class="built_in">string</span> S)</span></span>&#123;</span><br><span class="line">       <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; arr;</span><br><span class="line">       arr.push_back(<span class="number">-1</span>);</span><br><span class="line">       <span class="comment">// the 1st step</span></span><br><span class="line">       <span class="built_in">stack</span>&lt;<span class="keyword">char</span>&gt; <span class="built_in">stack</span>;</span><br><span class="line">       <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;S.size(); i++)&#123;</span><br><span class="line">           <span class="keyword">if</span>(S[i] == <span class="string">'('</span>)</span><br><span class="line">               <span class="built_in">stack</span>.push(S[i]);</span><br><span class="line">           <span class="keyword">else</span>&#123;</span><br><span class="line">               <span class="built_in">stack</span>.pop();</span><br><span class="line">               <span class="comment">// 当stack为空，表示一组匹配结束，记录结束的index</span></span><br><span class="line">               <span class="keyword">if</span>(<span class="built_in">stack</span>.size()==<span class="number">0</span>)</span><br><span class="line">                   arr.push_back(i);</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="comment">// the 2nd step</span></span><br><span class="line">       <span class="built_in">string</span> resS;</span><br><span class="line">       <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;arr.size()<span class="number">-1</span>; i++)&#123;</span><br><span class="line">           <span class="keyword">int</span> start = arr[i]+<span class="number">2</span>;</span><br><span class="line">           <span class="keyword">int</span> end = arr[i+<span class="number">1</span>]<span class="number">-1</span>;</span><br><span class="line">           <span class="keyword">if</span>(start&gt;=end) <span class="keyword">continue</span>;</span><br><span class="line">           <span class="comment">// 将outermost括号内的所有内用append到resS中</span></span><br><span class="line">           <span class="keyword">for</span>(<span class="keyword">int</span> j=start; j&lt;=end; j++)&#123;</span><br><span class="line">               resS+=S[j];</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="keyword">return</span> resS;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h2 id="1019-next-greater-nodes-in-linked-list"><a href="#1019-next-greater-nodes-in-linked-list" class="headerlink" title="#1019 next greater nodes in linked list"></a>#1019 next greater nodes in linked list</h2><ul>
<li><p>问题描述</p>
<p>  看下面这个例子：</p>
  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Input: [2,7,4,3,5]</span><br><span class="line">Output: [7,0,5,5,0]</span><br><span class="line"></span><br><span class="line">解释：</span><br><span class="line">对于2，其后第一个比他大的是7</span><br><span class="line">对于7，气候第一个比他大的没有，0</span><br><span class="line">对于4，其后第一个比他大的是5</span><br><span class="line">对于3，其后第一个比他大的是5</span><br><span class="line">对于5，为最后一个元素，其后没有比他大的，0</span><br><span class="line">所以返回[7,0,5,5,0]</span><br></pre></td></tr></table></figure>
</li>
<li><p>思路</p>
</li>
<li><p>实现</p>
</li>
</ul>
<h2 id="155-Min-Stack"><a href="#155-Min-Stack" class="headerlink" title="#155 Min Stack"></a>#155 Min Stack</h2><ul>
<li><p>描述 </p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Design a stack that supports push(), pop(), top(), and retrieving the minimum element in constant time: getMin().</span><br></pre></td></tr></table></figure>
</li>
<li><p>逻辑<br>  在这个类中，使用两个stack。一个<code>mystack</code>正常工作，另一个<code>min</code>记录栈<code>mystack</code>目前的最小值，保证<code>min</code>中的栈顶元素是最小的，而且<code>min</code>从栈顶到栈底元素大小递增。比如<code>min： 底|3|2|1 ...  |顶</code>。并且始终<font color="red">保持min的性质始终不变</font>。</p>
<p>  特点：<font color="orange">使用两个stack，一个正常工作，引入另一个使得整个stack类有了其他功能</font>。</p>
</li>
</ul>
<ul>
<li><p>实现</p>
  <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MinStack</span>&#123;</span></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="built_in">stack</span>&lt;<span class="keyword">int</span>&gt; mystack;  <span class="comment">// 提供stack正常的功能。</span></span><br><span class="line">    <span class="built_in">stack</span>&lt;<span class="keyword">int</span>&gt; min;   <span class="comment">// 记录最小值。</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    MinStack()&#123;&#125;;</span><br><span class="line">    ~MinStack()&#123;&#125;;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">push</span><span class="params">(<span class="keyword">int</span> x)</span></span>&#123;</span><br><span class="line">        mystack.push(x);</span><br><span class="line">        <span class="comment">// 只要待处理元素小于min的top元素，</span></span><br><span class="line">        <span class="comment">// min也要push进这个元素，</span></span><br><span class="line">        <span class="comment">// 保证min的top为当前mystack的最小值</span></span><br><span class="line">        <span class="keyword">if</span>(min.empty() || x&lt;=min.top())</span><br><span class="line">            min.push(x);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">top</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> mystack.top();   </span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">getMin</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> min.top();   </span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">empty</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> mystack.empty();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 当mystack.top() == min.top()时，两个stack都要pop()</span></span><br><span class="line">    <span class="comment">// 保证min的top为当前mystack的最小值。</span></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">pop</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(mystack.top() == min.top())</span><br><span class="line">            min.pop();</span><br><span class="line">        mystack.pop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>


</li>
</ul>
<h2 id="921-Minimum-Add-to-Make-Parentheses-Valid"><a href="#921-Minimum-Add-to-Make-Parentheses-Valid" class="headerlink" title="#921 Minimum Add to Make Parentheses Valid"></a>#921 Minimum Add to Make Parentheses Valid</h2><ul>
<li><p>描述</p>
<p>  添加最少的括号，使得括号字符串有效，例子：</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Input: &quot;())&quot;</span><br><span class="line">Output: 1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Input: &quot;(((&quot;</span><br><span class="line">Output: 3</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Input: &quot;()&quot;</span><br><span class="line">Output: 0</span><br></pre></td></tr></table></figure>
</li>
<li><p>逻辑</p>
<p>  使用栈：</p>
<p>  遍历S，遇到<code>&#39;(&#39;</code>入站，遇到<code>&#39;)&#39;</code>出站，表示有一对是匹配的，并将记录匹配对数的count+1。遍历完后，只需要：<code>S.length()-2*count</code>。的结果。</p>
<p>  还可以不使用栈。其实栈的作用只是记录<code>&#39;(&#39;</code>，所以可以只是用一个int变量来记录。如此空间复杂度从<code>O(N)</code>变为<code>O(1)</code>。</p>
<p>  <font color="orange">所有思路中一定有一个是适用于所有情况的，所以如果一个思路中有很多情况不能满足，思路不对</font>。</p>
</li>
<li><p>实现</p>
  <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">   <span class="comment">// use stack</span></span><br><span class="line">   <span class="function"><span class="keyword">int</span> <span class="title">minAddToMakeValid</span><span class="params">(<span class="built_in">string</span> S)</span></span>&#123;</span><br><span class="line">	<span class="built_in">stack</span>&lt;<span class="keyword">int</span>&gt; <span class="built_in">stack</span>;</span><br><span class="line">	<span class="keyword">int</span> count=<span class="number">0</span>;</span><br><span class="line">       <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;S.size(); i++)&#123;</span><br><span class="line">           <span class="keyword">if</span>(S[i] == <span class="string">'('</span>)</span><br><span class="line">               <span class="built_in">stack</span>.push(S[i]);</span><br><span class="line"></span><br><span class="line">           <span class="keyword">else</span> <span class="keyword">if</span>(S[i] == <span class="string">')'</span>)&#123;</span><br><span class="line">               <span class="keyword">if</span>(!<span class="built_in">stack</span>.empty())&#123;</span><br><span class="line">                   <span class="built_in">stack</span>.pop();</span><br><span class="line">				count++;</span><br><span class="line">               &#125;   </span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="keyword">return</span> S.length()<span class="number">-2</span>*count;</span><br><span class="line">&#125;</span><br><span class="line">   <span class="comment">// No stack</span></span><br><span class="line">   <span class="function"><span class="keyword">int</span> <span class="title">minAddToMakeValid</span><span class="params">(<span class="built_in">string</span> S)</span></span>&#123;</span><br><span class="line">	<span class="keyword">int</span> left_p=<span class="number">0</span>;</span><br><span class="line">	<span class="keyword">int</span> count=<span class="number">0</span>;</span><br><span class="line">       <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;S.size(); i++)&#123;</span><br><span class="line">           <span class="keyword">if</span>(S[i] == <span class="string">'('</span>)</span><br><span class="line">               left_p++;</span><br><span class="line"></span><br><span class="line">           <span class="keyword">else</span> <span class="keyword">if</span>(S[i] == <span class="string">')'</span>)&#123;</span><br><span class="line">               <span class="keyword">if</span>(left_p!=<span class="number">0</span>)&#123;</span><br><span class="line">                   left_p--;;</span><br><span class="line">				count++;</span><br><span class="line">               &#125;   </span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="keyword">return</span> S.length()<span class="number">-2</span>*count;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/02/25/LeetCode-%E6%96%B9%E6%B3%95%E8%AE%BA-stack/" data-id="ck71en4jy002ihefz75c8awc0" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Algorithms/" rel="tag">Algorithms</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-CUDA-杂记待归类" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/02/20/CUDA-%E6%9D%82%E8%AE%B0%E5%BE%85%E5%BD%92%E7%B1%BB/" class="article-date">
  <time datetime="2020-02-20T02:40:58.000Z" itemprop="datePublished">2020-02-20</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/CUDA/">CUDA</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/02/20/CUDA-%E6%9D%82%E8%AE%B0%E5%BE%85%E5%BD%92%E7%B1%BB/">CUDA-杂记待归类</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <ol start="4">
<li><p>向量数据类型</p>
<p> 同时适用于Host和Device，通过<code>make_&lt;type name&gt;</code>来构造，如</p>
<p> <code>int2 i2 = make_int2(3,4)</code>：i2向量含有3和4两个元素。<br> <code>float4 f4 = make_float4(1.0f, 2.0f, 3.0f, 4.0f)</code>：f4是含有4个元素的数组。</p>
<p> 访问方式如下：</p>
<p> <code>int x = i2.x; int y = i2.y;</code></p>
</li>
<li><p>CUDA程序调试和开发</p>
<ul>
<li>可以使用<code>ssh</code>登路远程含有CUDA enabled GPU的服务器。</li>
<li>通常使用双GPU的系统开发CUDA程序，一个GPU负责显示，另一个负责计算，可以使用<code>Nsight</code>等工具。</li>
<li>只有一个GPU时，在Linux系统中可以关闭桌面环境（释放桌面环境对GPU的占用），只在命令行中使用<code>CUDA-gdb</code>调试。（实际上，实验阶段不关闭桌面环境，也是可以正确执行的）</li>
</ul>
</li>
<li><p>CUDA开发的任务</p>
<p><font color="red" size="4">有效的数据并行算法</font> + <font color="gree" size="4">针对GPU架构特性的优化</font> = 获得并行<font color="orange" size="4">最优性能</font></p>
</li>
<li><p>OpenCL</p>
<p>OpenCL使用起来繁琐，而且运行速度远远低于CUDA运行速度。OpenCL与CUDA的主要功能有着十分相似之处，一个CUDA程序员很容易掌握OpenCL编程。</p>
</li>
<li><p>half-warp </p>
<p>截图</p>
</li>
<li><p>Streams-流</p>
<p>任务并行（Task Parallelism），不同于在大量的数据上执行相同的任务（SIMD），而是同时执行多个不同的任务。</p>
</li>
<li><p>CUDA数据并行原语</p>
<p>啥是原语，就是这个领域的基本操作。CUDA并行原语库（CUDA Data Parallel Primitive Library, CUDPP）. 含有并行前缀和，并i选哪个排序，并行规约等。<font color="orange">这些原语为许多数据并行算法提供了重要基础</font>。如果你正在编写某个复杂算法，那么CUDPP很可能已经提供了这个算法。</p>
<p>CUDPP 下载地址：<a href="http://code.google.com/p/cudpp" target="_blank" rel="noopener">http://code.google.com/p/cudpp</a></p>
<p>for more information：CUDA By Example 178页 </p>
</li>
</ol>
<ol start="26">
<li><p>想清楚一个问题</p>
<p>如果使用shared memory，每个block对应自己的shared memory，<font color="red">当这个block中threads的ID更新后，这个block并没有再被分配新的shared memory</font>. 也就是说如果使用两个blocks, 两个blocks有两段shared memory, block中threads 的ID更新后, 所计算结果会写入这个thread所在block的shared memory中. <font color="red">thread ID变了, 但所属的block不变</font>.  </p>
</li>
</ol>
<ol start="27">
<li><p>理解SIMD，SIMT</p>
<p>Single Instruction Multiple Data（Thread）. </p>
<ul>
<li>Single：相同的操作，kernel函数只有一个</li>
<li>Instruction：kernel函数所做的事情</li>
<li>Multiple：所处理的数据量大，要拆分为一批一批</li>
<li>Data：大的数据量</li>
<li>Threads：<font color="orange">一个SP上的大量thread超快速切换，获得延时隐藏</font></li>
</ul>
</li>
<li><p>warp中的divergence</p>
<p>已经知道，在一个warp中，所有的threads执行相同的指令，但是如果指令中含有条件分支语句，很大程度上会发生divergence。比如<code>优化并行归约</code> 中的描述：一个宿舍的6个学生可以是一个warp，今天有的想先上厕所，后吃饭，而有的不需要上厕所，此时所有的同学都会一起先上厕所，后一起吃饭。</p>
<p>总之，分支发散使得性能明显下降。但是，注意<font color="orange">divergence只发生在一个warp中</font>。</p>
<p>可以综合算法的上下文，将divergence的粒度变为32（warp的大小）的倍数，从而避免warp内的分支发散。比如：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">__<span class="function">global__ <span class="keyword">void</span> <span class="title">kernel</span><span class="params">(<span class="keyword">float</span>* c)</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> tid = threadIdx.x + blockDim.x * blockIdx.x;</span><br><span class="line">    <span class="keyword">float</span> a=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">float</span> b=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">if</span> (tid%<span class="number">2</span> == <span class="number">0</span>)&#123;  </span><br><span class="line">        c[tid] = <span class="number">100</span>;</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        c[tid] = <span class="number">200</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>偶数id的thread把100写入偶数编号的地址，奇数id的thread将200写入奇数编号的地址。会发生分支发散。如果将分支的粒度定为32，则没有了divergence <font color="red">[代码中tid%32 == 0有问题]</font>：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">__<span class="function">global__ <span class="keyword">void</span> <span class="title">kernel</span><span class="params">(<span class="keyword">float</span>* c)</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> tid = threadIdx.x + blockDim.x * blockIdx.x;</span><br><span class="line">    <span class="keyword">float</span> a=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">float</span> b=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">if</span> ( tid%<span class="number">32</span> == <span class="number">0</span> )&#123;</span><br><span class="line">        c[tid] = <span class="number">100</span>;</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        c[tid] = <span class="number">200</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>但是两者的结果的是不同的，实际中，需要根据算法上下文考虑结合此方法。</p>
<p>使用<code>brand_efficiency</code>指标来查看divergence的情况：</p>
<p><code>$ nvprof --mereics brand_efficiency ./out</code>, 但是CUDA编译器会进行优化，将短的，有条件的代码段的断定指令取代了分支指令。所以，会看到虽然代码中有分支，却显示分支效率100%。</p>
</li>
</ol>
<ol start="41">
<li><p>数据预读取</p>
<p><font color="orange">在一次读取global memory的操作和使用这个数据之间，插入独立于以上数据的操作，可以隐藏访问延迟</font>。如：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">float</span> m = dev_a[i];  <span class="comment">// 1. 从global memory中读取</span></span><br><span class="line"><span class="keyword">float</span> f = a * b;     <span class="comment">// 2. 与m无关的操作 </span></span><br><span class="line"><span class="keyword">float</span> f2 = m*f;      <span class="comment">// 3. 使用m</span></span><br></pre></td></tr></table></figure>
<p>分析：在warp切换中，</p>
</li>
<li><p>指令优化</p>
<p>GPU中执行指令时很快速的，所以通常不用太在意指令的优化。优化顺序一般是存储优化，后执行配置优化，最后可以考虑指令优化。</p>
<p>比如：除以<code>2^n</code>，使用移位操作<code>&gt;&gt;n</code>，以<code>2^n</code>求模，使用<code>&amp;(2^n - 1)</code>；避免从double到float的自动转换，<code>float a = 0.0</code>，使用<code>float a = 0.0f</code>。</p>
<p>还比如，两种运行时数学库函数的取舍，精度高的速度低，精度低的速度高。使用<code>-use-fast-math</code>编译选项后，强制将速度慢的<code>func()</code>转化为速度快的<code>__func()</code>。</p>
<p>还比如循环展开。</p>
</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/02/20/CUDA-%E6%9D%82%E8%AE%B0%E5%BE%85%E5%BD%92%E7%B1%BB/" data-id="ck71en4jl001ohefz114t5kh2" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/CUDA/" rel="tag">CUDA</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-CUDA-扫描算法" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/02/20/CUDA-%E6%89%AB%E6%8F%8F%E7%AE%97%E6%B3%95/" class="article-date">
  <time datetime="2020-02-20T02:39:23.000Z" itemprop="datePublished">2020-02-20</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/CUDA/">CUDA</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/02/20/CUDA-%E6%89%AB%E6%8F%8F%E7%AE%97%E6%B3%95/">CUDA-扫描算法</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="扫描算法"><a href="#扫描算法" class="headerlink" title="扫描算法"></a>扫描算法</h1><p>Scan，是并行编程的一个重要原语，作为基本模块使用与很多不同的算法。Scan做的是什么事呢？看下图：</p>
<p>&lt;&gt;pic17&lt;&gt;</p>
<div align="center"><img src></div>

<p>其特点是，输出的每一个值有前缀依赖性，就是说每个输出依赖前面的所有输入。两种基本的扫描的过程如下：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="class"><span class="keyword">class</span> <span class="title">T</span>&gt;</span></span><br><span class="line"><span class="class"><span class="title">T</span> <span class="title">scan1</span>(<span class="title">T</span>* <span class="title">out</span>, <span class="title">T</span>* <span class="title">in</span>, <span class="title">size_t</span> <span class="title">N</span>)&#123;</span></span><br><span class="line">    T sum = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> <span class="keyword">int</span> i=<span class="number">0</span>;i&lt;N;i++)&#123;</span><br><span class="line">        sum += in[i];</span><br><span class="line">        out[i] = sum;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="class"><span class="keyword">class</span> <span class="title">T</span>&gt;</span></span><br><span class="line"><span class="class"><span class="title">T</span> <span class="title">scan2</span>(<span class="title">T</span>* <span class="title">out</span>, <span class="title">T</span>* <span class="title">in</span>, <span class="title">size_t</span> <span class="title">N</span>)&#123;</span></span><br><span class="line">    T sum=<span class="number">0</span>; </span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;N;i++)&#123;</span><br><span class="line">        out[i] = sum;</span><br><span class="line">        sum += in[i];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>无需解释。</p>
<p>因为其每个元素的前缀依赖性，</p>
<h1 id="Blelloch并行扫描算法"><a href="#Blelloch并行扫描算法" class="headerlink" title="Blelloch并行扫描算法"></a>Blelloch并行扫描算法</h1><p>这个方法在前元素后依赖的情况下，并行实现。Blelloch算法分了两段执行。过程如下图：</p>
<p>&lt;&gt;pic18&lt;&gt;</p>
<div align="center"><img src></div>

<p>每个阶段的操作虽然容易想到，但是，<font color="orange" size="5">这个框架是很值得借鉴的</font>。图中实例，每两行之间的操作是并行的，而且这两行之间的并行操作必须全部执行完毕，才能向下执行，所以需要同步操作，尤其是当存在线程ID更新时。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/02/20/CUDA-%E6%89%AB%E6%8F%8F%E7%AE%97%E6%B3%95/" data-id="ck71en4jg001chefzhx54a8kw" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/CUDA/" rel="tag">CUDA</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-CUDA-再看规约-一段规约" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/02/20/CUDA-%E5%86%8D%E7%9C%8B%E8%A7%84%E7%BA%A6-%E4%B8%80%E6%AE%B5%E8%A7%84%E7%BA%A6/" class="article-date">
  <time datetime="2020-02-20T02:27:03.000Z" itemprop="datePublished">2020-02-20</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/CUDA/">CUDA</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/02/20/CUDA-%E5%86%8D%E7%9C%8B%E8%A7%84%E7%BA%A6-%E4%B8%80%E6%AE%B5%E8%A7%84%E7%BA%A6/">CUDA-再看规约-一段规约</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="一阶段规约"><a href="#一阶段规约" class="headerlink" title="一阶段规约"></a>一阶段规约</h1><p>使用原子操作和shared memory的组合可以避免第二个kernel的调用。使用一个（global还是shared）变量记录哪个block已经做完了自己的工作。一旦所有的block都完成后，使用一个block执行最有的规约。</p>
<p>【CUDA专家手册 269页】</p>
<h1 id="更简洁的一段规约"><a href="#更简洁的一段规约" class="headerlink" title="更简洁的一段规约"></a>更简洁的一段规约</h1><p>在之前的二段归约中，每一阶段的第一步是每个block的每个thread得到部分和，由于block间是不能同步的，所以才有了第二阶段。</p>
<p>现在是使用一个寄存器来存储每个thread对应的自己的部分和，最后使用 原子操作对这些部分和再求和：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">__<span class="function">global__ <span class="keyword">void</span> <span class="title">reductionKernel</span><span class="params">(<span class="keyword">int</span>* out, <span class="keyword">int</span>* in, <span class="keyword">size_t</span> N)</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> tid = threadIdx.x + blockDim.x * blockIdx.x;</span><br><span class="line">    <span class="keyword">int</span> stride = blockDim.x * gridDim.x;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 每个thread得到自己的部分和，</span></span><br><span class="line">    <span class="keyword">int</span> partialSum = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">size_t</span> i = tid; i&lt;N; i+=stride)&#123;</span><br><span class="line">        partialSum += in[i];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 使用原子操作，求部分和的和</span></span><br><span class="line">    atomicAdd(out, partialSum);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">func</span><span class="params">(<span class="keyword">int</span>* res, <span class="keyword">int</span>* in, <span class="keyword">size_t</span> N)</span></span>&#123;</span><br><span class="line">    <span class="comment">// 初始化</span></span><br><span class="line">    cudaMemset(res, <span class="number">0</span>, <span class="keyword">sizeof</span>(<span class="keyword">int</span>));</span><br><span class="line">    reductionKernel&lt;&lt;&lt;numBlock, threadsPerBlock&gt;&gt;&gt;(answer, in ,N);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>注意一点，要写入<code>out数组</code>，那么<code>out数组</code>的初始值必须设为0；</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/02/20/CUDA-%E5%86%8D%E7%9C%8B%E8%A7%84%E7%BA%A6-%E4%B8%80%E6%AE%B5%E8%A7%84%E7%BA%A6/" data-id="ck71en4jd0013hefzhery7c4u" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/CUDA/" rel="tag">CUDA</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-CUDA-再看规约-循环展开" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/02/20/CUDA-%E5%86%8D%E7%9C%8B%E8%A7%84%E7%BA%A6-%E5%BE%AA%E7%8E%AF%E5%B1%95%E5%BC%80/" class="article-date">
  <time datetime="2020-02-20T02:23:04.000Z" itemprop="datePublished">2020-02-20</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/CUDA/">CUDA</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/02/20/CUDA-%E5%86%8D%E7%9C%8B%E8%A7%84%E7%BA%A6-%E5%BE%AA%E7%8E%AF%E5%B1%95%E5%BC%80/">CUDA-再看规约-循环展开</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="循环展开"><a href="#循环展开" class="headerlink" title="循环展开"></a>循环展开</h1><p>循环展开减少了循环中的变量的判断，自加等其他操作，是提升性能一个手段。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;<span class="number">1000</span>; i++)&#123;</span><br><span class="line">    a[i] = b[i] + c[i];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>将循环次数减少一半：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;<span class="number">1000</span>; i+=<span class="number">2</span>)&#123;</span><br><span class="line">    a[i] = b[i] + c[i];</span><br><span class="line">    a[i+<span class="number">1</span>] = b[i+<span class="number">1</span>] + c[i+<span class="number">1</span>];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>下面的两段规约法，展示使用完全的循环展开。</p>
<h1 id="再看规约-两段规约"><a href="#再看规约-两段规约" class="headerlink" title="再看规约-两段规约"></a>再看规约-两段规约</h1><p>类似与<code>点积</code>中的两段法。两段规约同样使用shared memory。</p>
<p>过程见下图：</p>
<div align="center"><img src="/2020/02/20/CUDA-%E5%86%8D%E7%9C%8B%E8%A7%84%E7%BA%A6-%E5%BE%AA%E7%8E%AF%E5%B1%95%E5%BC%80/pic14.png" width="700"></div>

<p>实现上图过程：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">* in: 待读取的数组。out: 待写入的数组。N: in数组的长度</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line">__<span class="function">global__ <span class="keyword">void</span> <span class="title">reductionKernel</span><span class="params">(<span class="keyword">int</span>* out, <span class="keyword">int</span>* in, <span class="keyword">size_t</span> N)</span></span>&#123;</span><br><span class="line">    <span class="comment">// 此处是一个未分配大小的shared memory</span></span><br><span class="line">    __shared__ <span class="keyword">int</span> buffer[];</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 第一阶段，</span></span><br><span class="line">    <span class="keyword">int</span> sum=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">int</span> tid = threadIdx.x + blockDim.x * blockIdx.x;</span><br><span class="line">    <span class="keyword">int</span> stride = blockDim.x * gridDim.x;</span><br><span class="line">    <span class="comment">// 使用stride loop</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">size_t</span> i = tid; i&lt;N; i+=stride)&#123;</span><br><span class="line">        sum += in[i];</span><br><span class="line">    &#125;</span><br><span class="line">    buffer[threadIdx.x] = sum;</span><br><span class="line">    <span class="comment">// 等待得到所有threads的sum值</span></span><br><span class="line">    <span class="comment">// block与block之间怎样同步呢？这里不需要同步</span></span><br><span class="line">    __syncthreads();   </span><br><span class="line"></span><br><span class="line">    <span class="comment">// 第二阶段，规约求每个block的最终值</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = blockDim.x &gt;&gt; <span class="number">1</span>; i!=<span class="number">0</span>; i&gt;&gt;=<span class="number">1</span>)&#123;</span><br><span class="line">        <span class="keyword">if</span> (threadIdx.x &lt; i)&#123;</span><br><span class="line">            buffer[threadIdx.x] += buffer[threadIdx.x + i];</span><br><span class="line">        &#125;</span><br><span class="line">        __syncthreads();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 最后一步，将每个block对应的buffer中的第一个元素放入out数组</span></span><br><span class="line">    <span class="comment">// 此时out数组中存放的是每个block的最终值。</span></span><br><span class="line">    <span class="keyword">if</span> (threadIdx.x == <span class="number">0</span>)</span><br><span class="line">        out[blockIdx.x] = buffer[<span class="number">0</span>];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>分析说明：</p>
<ul>
<li>强调：第一阶段的<font color="red" size="4">blockDim.x应该是32的倍数</font>，每个block对应的<font color="red" size="4">Shared memory大小也要是32的倍数</font>。这样才能保证<font color="red" size="4">在第二阶段所处理的数据是整齐的</font>。</li>
<li>第二阶段结束后block与block间结果怎样同步？kernel函数执行完毕，表示两个block都得到了结果，即同步了。所以一种方式的到最终结果是两次调用这个kernel函数。见下面code。</li>
<li>对out数组的最终处理，可以考虑将out传回host后在CPU中计算，就像<code>向量点积</code>。也可以使用一个block，第二次调用上述kernel函数，得到最终值。（我感觉不如传回CPU）。</li>
<li>shared memory 的访问索引是<code>threadIdx.x</code>。</li>
<li>使用<code>blockDim.x &gt;&gt; 1</code>和<code>i&gt;&gt;=1</code>，这属于指令优化。</li>
<li>kernel中的Shared memory可以不分配大小，调用kernel函数时再制定大小。</li>
</ul>
<p>在Host中调用kernel函数：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">reduction</span><span class="params">(<span class="keyword">int</span>* res, <span class="keyword">int</span>* partial, <span class="keyword">int</span>* in, </span></span></span><br><span class="line"><span class="function"><span class="params">                <span class="keyword">size_t</span> N, <span class="keyword">int</span> numBlocks, <span class="keyword">int</span> numThreads)</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> sharedSize = numThreads*<span class="keyword">sizeof</span>(<span class="keyword">int</span>);</span><br><span class="line">    <span class="comment">// 第一个kernel得到所有block对应的buffer，</span></span><br><span class="line">    <span class="comment">// 这些block之间没有同步，所以只有所有的block的buffer都得到了</span></span><br><span class="line">    <span class="comment">// 这个kernel才时执行结束，也就是说，为了同步所有的block的buffer，</span></span><br><span class="line">    <span class="comment">// 只能再调用一次这个和函数了。</span></span><br><span class="line">    reductionKernel&lt;&lt;&lt;numBlocks, numThreads, sharedSize&gt;&gt;&gt;</span><br><span class="line">                    (partial, in, N);</span><br><span class="line">    reductionKernel&lt;&lt;&lt;<span class="number">1</span>, numThreads, sharedSize&gt;&gt;&gt;</span><br><span class="line">                    (res, partial, numBlocks);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>看到了吧：</p>
<ul>
<li>第二次调用kernel只是用一个block。</li>
<li>注意：此处在<code>&lt;&lt; , , &gt;&gt;&gt;</code>中出现了第三个参数，由于在kernel中，没有指定shared memory的大小，所以在调用kernel函数时要制定大小了。</li>
<li>这个kernel中的第二个for循环中，循环的之后阶段，当threads数小于等于<code>32</code>时，可以特殊处理，此时的所有活动threads在一个warp中，所以不需要同步。细节间<code>32特殊处理规约</code>。</li>
<li>补充：<font color="orange">每个block中的warp时按照lockstep的方式执行每条指令</font>。</li>
</ul>
<h1 id="再看规约-第二阶段循环展开"><a href="#再看规约-第二阶段循环展开" class="headerlink" title="再看规约-第二阶段循环展开"></a>再看规约-第二阶段循环展开</h1><p><font color="orange" size="4">优化意识</font>：当threads数小于等于<code>32</code>时，也就是<code>threadIdx.x从0到31</code>时，可以特殊处理。这种处理就是循环展开。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">* in: 待读取的数组。out: 待写入的数组。N: in数组的长度</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line">__<span class="function">global__ <span class="keyword">void</span> <span class="title">reductionKernel</span><span class="params">(<span class="keyword">int</span>* out, <span class="keyword">int</span>* in, <span class="keyword">size_t</span> N)</span></span>&#123;</span><br><span class="line">    <span class="comment">// 此处是一个未分配大小的shared memory</span></span><br><span class="line">    __shared__ <span class="keyword">int</span> buffer[];</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 第一阶段，</span></span><br><span class="line">    <span class="keyword">int</span> sum=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">int</span> tid = threadIdx.x + blockDim.x * blockIdx.x;</span><br><span class="line">    <span class="keyword">int</span> stride = blockDim.x * gridDim.x;</span><br><span class="line">    <span class="comment">// 使用stride loop</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">size_t</span> i = tid; i&lt;N; i+=stride)&#123;</span><br><span class="line">        sum += in[i];</span><br><span class="line">    &#125;</span><br><span class="line">    buffer[threadIdx.x] = sum;</span><br><span class="line">    <span class="comment">// 等待得到所有threads的sum值</span></span><br><span class="line">    __syncthreads();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 第二阶段，规约求每个block的最终值, 直到i=32.</span></span><br><span class="line">    <span class="comment">// 之后就是特殊处理了</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = blockDim.x &gt;&gt; <span class="number">1</span>; i&gt;<span class="number">32</span>; i&gt;&gt;=<span class="number">1</span>)&#123;</span><br><span class="line">        <span class="keyword">if</span> (threadIdx.x &lt; i)&#123;</span><br><span class="line">            buffer[threadIdx.x] += buffer[threadIdx.x + i];</span><br><span class="line">        &#125;</span><br><span class="line">        __syncthreads();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 第三步，当元素个数小于等于32时：</span></span><br><span class="line">    <span class="comment">// 这个展开避免了循环控制的开销，和thread同步的逻辑</span></span><br><span class="line">    <span class="keyword">if</span>(threadIdx.x &lt; <span class="number">32</span>)&#123;</span><br><span class="line">        <span class="keyword">volatile</span> <span class="keyword">int</span>* wsSum = buffer;</span><br><span class="line">        <span class="keyword">if</span>(blockDim.x &gt; <span class="number">32</span>)</span><br><span class="line">            wsSum[threadIdx.x] += wsSum[threadIdx.x + <span class="number">32</span>];</span><br><span class="line">        <span class="comment">// 一下5条指令，一定都会被执行，不过也可以加上if条件。</span></span><br><span class="line">        wsSum[threadIdx.x] += wsSum[threadIdx.x + <span class="number">16</span>];</span><br><span class="line">        wsSum[threadIdx.x] += wsSum[threadIdx.x + <span class="number">8</span>];</span><br><span class="line">        wsSum[threadIdx.x] += wsSum[threadIdx.x + <span class="number">4</span>];</span><br><span class="line">        wsSum[threadIdx.x] += wsSum[threadIdx.x + <span class="number">2</span>];</span><br><span class="line">        wsSum[threadIdx.x] += wsSum[threadIdx.x + <span class="number">1</span>];</span><br><span class="line">        <span class="keyword">if</span> (threadIdx.x == <span class="number">0</span>)&#123;</span><br><span class="line">            <span class="keyword">volatile</span> <span class="keyword">int</span>* wsSum = buffer;</span><br><span class="line">            out[blockIdx.x] = wsSum[<span class="number">0</span>];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>注意：当编写warp同步的code时，必须对shared memory 的指针使用<code>volatile</code>关键字。这个关键字告诉编译器必须将<code>wsSum[threadIdx.x]</code>的值存回global中。如果没有<code>volatile</code>，为什么不能得到正确结果？</p>
<p>第三步为什么正确，看下图之前，看下假设：</p>
<ul>
<li>下图将大小为32的warp假设为4，即<code>warp size=4</code>：</li>
<li>所展示的情况是从上一个图片中的第一阶段的结果开始，即<code>blockDim.x=8</code>.</li>
</ul>
<p>对于code中的第三步，见下图：</p>
<div align="center"><img src="/2020/02/20/CUDA-%E5%86%8D%E7%9C%8B%E8%A7%84%E7%BA%A6-%E5%BE%AA%E7%8E%AF%E5%B1%95%E5%BC%80/pic15.png" width="700"></div>

<p>从上述code第二阶段的循环开始：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">blockDim.x=8;</span><br><span class="line"><span class="keyword">for</span>(i=8&gt;&gt;1; i&gt;4; i&gt;&gt;=1)&#123;</span><br><span class="line">    i=4, i!&gt;4, 退出循环;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">对于 threadIdx.x&lt;4，blockDim.x&gt;4，即 0 1 2 3. 执行下面操作：</span><br><span class="line">wsSum[0 1 2 3] += wsSum[(0 1 2 3) + 4];</span><br><span class="line">wsSum[0 1 2 3] += wsSum[(0 1 2 3) + 2];</span><br><span class="line">wsSum[0 1 2 3] += wsSum[(0 1 2 3) + 1];</span><br></pre></td></tr></table></figure>

<p>说明：</p>
<ul>
<li>其中执行单元只有这个block 中的第一个warp。</li>
<li>最终需要的时每个block对应buffer是<font color="orange">第一个值</font>，所以除第一个位置以外的位置，其值是无意义的。但是由于warp中的线程执行相同的指令，所以warp中其他threads也工作了，只不过这些结果我并不需要。</li>
<li>再强调：第一阶段的<font color="red" size="4">blockDim.x应该是32的倍数</font>，每个block对应的<font color="red" size="4">Shared memory大小也要是32的倍数</font>。这样才能保证<font color="red" size="4">在第二阶段所处理的数据是整齐的</font>。</li>
</ul>
<p>再次证明，用<font color="orange">假设小的数值，用小的例子，小的数据</font>有助于理解，</p>
<h1 id="再看规约-第二阶段进一步循环展开"><a href="#再看规约-第二阶段进一步循环展开" class="headerlink" title="再看规约-第二阶段进一步循环展开"></a>再看规约-第二阶段进一步循环展开</h1><p>使用<code>template</code>把上述实现的第二阶段的for循环，做循环展开，这个展开是完全的展开。思路与上述实现一样，warp同步的优化方案就更近一步了。code如下：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">int</span> threadsPerBlock&gt;</span><br><span class="line">__<span class="function">global__ <span class="keyword">void</span> <span class="title">reductionKernel</span><span class="params">(<span class="keyword">int</span>* in, <span class="keyword">int</span>* out, <span class="keyword">size_t</span> N)</span></span>&#123;</span><br><span class="line">    __shared__ <span class="keyword">int</span> buffer[];</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 第一步，</span></span><br><span class="line">    <span class="keyword">int</span> tid = threadIdx.x;</span><br><span class="line">    <span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">int</span> id = tid + threadsPerBlock * blockIdx.x;</span><br><span class="line">    <span class="keyword">int</span> stride = threadsPerBlock * gridDim.x; </span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">size_t</span> i = id; i&lt; N; i += stride)&#123;</span><br><span class="line">        sum += in[i];</span><br><span class="line">    &#125;</span><br><span class="line">    buffer[tid] = sum;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 第二步，循环展开, 从1024开始，</span></span><br><span class="line">    <span class="comment">// 每个block最多threads个数是1024（就目前的GPU架构）</span></span><br><span class="line">    <span class="keyword">if</span>(threadsPerBlock &gt;= <span class="number">1024</span>)&#123;</span><br><span class="line">        <span class="keyword">if</span>(tid &lt; <span class="number">512</span>)   <span class="comment">// tid 小于512 的threads开始工作</span></span><br><span class="line">            buffer[tid] += buffer[tid + <span class="number">512</span>];</span><br><span class="line">        __syncthreads();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>(threadsPerBlock &gt;= <span class="number">512</span>)&#123;</span><br><span class="line">        <span class="keyword">if</span>(tid &lt; <span class="number">256</span>)  <span class="comment">// tid 小于256 的threads开始工作</span></span><br><span class="line">            buffer[tid] += buffer[tid + <span class="number">256</span>];</span><br><span class="line">        __syncthreads();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>(threadsPerBlock &gt;= <span class="number">256</span>)&#123;</span><br><span class="line">        <span class="keyword">if</span>(tid &lt; <span class="number">128</span>)  <span class="comment">// tid 小于128 的threads开始工作</span></span><br><span class="line">            buffer[tid] += buffer[tid + <span class="number">128</span>];</span><br><span class="line">        __syncthreads();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>(threadsPerBlock &gt;= <span class="number">128</span>)&#123;</span><br><span class="line">        <span class="keyword">if</span>(tid &lt; <span class="number">64</span>)  <span class="comment">// tid 小于64 的threads开始工作</span></span><br><span class="line">            buffer[tid] += buffer[tid + <span class="number">64</span>];</span><br><span class="line">        __syncthreads();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 第三步。warp同步操作，不需要__syncthreads()</span></span><br><span class="line">    <span class="keyword">if</span>( tid&lt;<span class="number">32</span> )&#123;     <span class="comment">// tid 小于32 的threads开始工作</span></span><br><span class="line">        <span class="keyword">volatile</span> <span class="keyword">int</span>* wsSum = buffer;</span><br><span class="line">        <span class="comment">// 下面的6条if语句都会被执行，</span></span><br><span class="line">        <span class="comment">// 看第一个if的64与第二步最后的64连接上了。</span></span><br><span class="line">        <span class="keyword">if</span> (threadsPerBlock &gt;= <span class="number">64</span>) wsSum[tid] += wsSum[tid + <span class="number">32</span>];</span><br><span class="line">        <span class="keyword">if</span> (threadsPerBlock &gt;= <span class="number">32</span>) wsSum[tid] += wsSum[tid + <span class="number">16</span>];</span><br><span class="line">        <span class="keyword">if</span> (threadsPerBlock &gt;= <span class="number">16</span>) wsSum[tid] += wsSum[tid + <span class="number">8</span>];</span><br><span class="line">        <span class="keyword">if</span> (threadsPerBlock &gt;= <span class="number">8</span>) wsSum[tid] += wsSum[tid + <span class="number">4</span>];</span><br><span class="line">        <span class="keyword">if</span> (threadsPerBlock &gt;= <span class="number">4</span>) wsSum[tid] += wsSum[tid + <span class="number">2</span>];</span><br><span class="line">        <span class="keyword">if</span> (threadsPerBlock &gt;= <span class="number">2</span>) wsSum[tid] += wsSum[tid + <span class="number">1</span>];</span><br><span class="line">        <span class="keyword">if</span> (tid == <span class="number">0</span>) out[blockIdx.x] = wsSum[<span class="number">0</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><font color="orange">完全展开， 避免了循环控制的开销，第三步的展开还避免了thread同步的逻辑</font>。</p>
<p>这里的执行有个特点，看<code>if</code>判断中的数字：<code>1024，512，256，128，64，32，16，8，4，2，1</code>，从逻辑看，一定是从大到小排列的，而且执行的时候，如果有一个<code>if</code>满足，那么这个<code>if</code>及其之后的<code>if</code>语句都会被执行。过程看下图。</p>
<p>第三次强调：第一阶段的<font color="red" size="4">blockDim.x应该是32的倍数</font>，每个block对应的<font color="red" size="4">Shared memory大小也要是32的倍数</font>。这样才能保证<font color="red" size="4">在第二阶段所处理的数据是整齐的</font>。</p>
<p>所以设<code>threadPerBLock</code>为<code>512</code>时的示意图如下：</p>
<div align="center"><img src="/2020/02/20/CUDA-%E5%86%8D%E7%9C%8B%E8%A7%84%E7%BA%A6-%E5%BE%AA%E7%8E%AF%E5%B1%95%E5%BC%80/pic16.png" width="700"></div>

<p>第三步中，不需要<code>__syncthreads()</code>，一个warp中的threads天然同步。</p>
<p>这个kernel是个模板kernel，在被host函数调用时，要指定<code>threadsPerBlock</code>的值。</p>
<p>调用kernel的host函数也必须是一个模板函数： </p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">int</span> threadsPerBlock&gt;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">callReduction</span><span class="params">(<span class="keyword">int</span>* res, <span class="keyword">int</span>* partial, </span></span></span><br><span class="line"><span class="function"><span class="params">                    <span class="keyword">int</span>* in, <span class="keyword">size_t</span> N, </span></span></span><br><span class="line"><span class="function"><span class="params">                    <span class="keyword">int</span> numBlocks)</span></span>&#123;</span><br><span class="line">    <span class="comment">// 第一阶段，得到所有block对应的shared memory中的值</span></span><br><span class="line">    reductionKernel&lt;numBlocks&gt;&lt;&lt;&lt;numBlocks, </span><br><span class="line">                                threadsPerBlocks, </span><br><span class="line">                                <span class="function">threadsPerBlocks*<span class="title">sizeof</span><span class="params">(<span class="keyword">int</span>)</span></span></span><br><span class="line">                                &gt;&gt;&gt;(partial, in, N);</span><br><span class="line">    <span class="comment">// 两个阶段串行</span></span><br><span class="line">    <span class="comment">// 第二阶段，对上一步中partial中的所有值，执行规约</span></span><br><span class="line">    reductionKernel&lt;numBlocks&gt;&lt;&lt;&lt;<span class="number">1</span>, </span><br><span class="line">                                threadsPerBlocks, </span><br><span class="line">                                <span class="function">threadsPerBlocks*<span class="title">sizeof</span><span class="params">(<span class="keyword">int</span>)</span></span></span><br><span class="line">                                &gt;&gt;&gt;(res, partial, numBlocks);             </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用switch语句，按照不同 block大小出发对应的模板函数。</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">func</span><span class="params">(<span class="keyword">int</span>* out, <span class="keyword">int</span>* partial, </span></span></span><br><span class="line"><span class="function"><span class="params">            <span class="keyword">int</span>* in, <span class="keyword">size_t</span> N, </span></span></span><br><span class="line"><span class="function"><span class="params">            <span class="keyword">int</span> numBlocks, <span class="keyword">int</span> threadsPerBlock)</span></span>&#123;</span><br><span class="line">    <span class="keyword">switch</span>( theadsPerBlock )&#123;</span><br><span class="line">        <span class="keyword">case</span> <span class="number">1</span>: <span class="keyword">return</span> callReduction&lt; <span class="number">1</span> &gt;(...);</span><br><span class="line">        <span class="keyword">case</span> <span class="number">2</span>: <span class="keyword">return</span> callReduction&lt; <span class="number">2</span> &gt;(...);</span><br><span class="line">        <span class="keyword">case</span> <span class="number">4</span>: <span class="keyword">return</span> callReduction&lt; <span class="number">4</span> &gt;(...);</span><br><span class="line">        <span class="keyword">case</span> <span class="number">8</span>: <span class="keyword">return</span> callReduction&lt; <span class="number">8</span> &gt;(...);</span><br><span class="line">        <span class="keyword">case</span> <span class="number">16</span>: <span class="keyword">return</span> callReduction&lt; <span class="number">16</span> &gt;(...);</span><br><span class="line">        <span class="keyword">case</span> <span class="number">32</span>: <span class="keyword">return</span> callReduction&lt; <span class="number">32</span> &gt;(...);</span><br><span class="line">        <span class="keyword">case</span> <span class="number">64</span>: <span class="keyword">return</span> callReduction&lt; <span class="number">64</span> &gt;(...);</span><br><span class="line">        <span class="keyword">case</span> <span class="number">128</span>: <span class="keyword">return</span> callReduction&lt; <span class="number">128</span> &gt;(...);</span><br><span class="line">        <span class="keyword">case</span> <span class="number">256</span>: <span class="keyword">return</span> callReduction&lt; <span class="number">256</span> &gt;(...);</span><br><span class="line">        <span class="keyword">case</span> <span class="number">512</span>: <span class="keyword">return</span> callReduction&lt; <span class="number">512</span> &gt;(...);</span><br><span class="line">        <span class="keyword">case</span> <span class="number">1024</span>: <span class="keyword">return</span> callReduction&lt; <span class="number">1024</span> &gt;(...);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>之所以不能再一个kernel中获得最后结果，是因为，<font color="red">block与block之间是没有同步的</font>。而第二阶段的规约需要所有block的buffer中第一个值，集合在一起，作为前提，如第一幅图所示。可不可以只一阶段就完成任务呢。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/02/20/CUDA-%E5%86%8D%E7%9C%8B%E8%A7%84%E7%BA%A6-%E5%BE%AA%E7%8E%AF%E5%B1%95%E5%BC%80/" data-id="ck71en4l7004hhefz4mgg8l9v" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/CUDA/" rel="tag">CUDA</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-CUDA-ComputeCapacity-SM-version6-1的参数值" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/02/20/CUDA-ComputeCapacity-SM-version6-1%E7%9A%84%E5%8F%82%E6%95%B0%E5%80%BC/" class="article-date">
  <time datetime="2020-02-20T02:15:23.000Z" itemprop="datePublished">2020-02-20</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/CUDA/">CUDA</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/02/20/CUDA-ComputeCapacity-SM-version6-1%E7%9A%84%E5%8F%82%E6%95%B0%E5%80%BC/">CUDA-ComputeCapacity-SM_version6.1的参数值</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <ol>
<li><p>Compute Capability</p>
<p> 对于CPU，不同架构的CPU有者不同的功能和指令集（MMX，SSE，SSE2）。而对于GPU，不同的功能由不同的<code>Compute Capability</code>表示。</p>
<p> NVIDIA GPU支持的Compute Capability有<code>1.0，1.0，... 2.0，... 6.0，6.1，7.5</code>。高版本的<code>Compute Capability</code>是低版本<code>Compute Capability</code>的超集，就是俄罗斯套娃式的嵌套结构。比如6.1版本支持1.0版本的所有功能。</p>
<p> 比如，原子操作时硬件在内存上执行的。而只有<code>1.1和1.1之后</code>的版本才支持global memory上的原子操作，而只有<code>1.2和1.2之后</code>的版本才支持shared memory上的原子操作</p>
<p> 在应用中，通常会指定最低<code>Compute Capability</code>版本，如2.3，告诉编译器，如果硬件支持的<code>Compute Capability</code>版本低于2.3，那么将无法执行这个和函数。做法是使用nvcc时增加一个选项<code>nvcc -arch=sm_23</code>，所以<code>Compute Capability</code>有称作<code>SM版本</code>。</p>
<p> <code>SM版本</code>的形式是<code>X.Y</code>，X表示核心的架构，7表示Volta，6表示Pascal。Y表示硬件的特性版本。</p>
<p> 不同的SM版本所支持的特性，和技术参数，间这个页面的table14和table15：<br>  <a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#compute-capabilities" target="_blank" rel="noopener">https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#compute-capabilities</a></p>
</li>
<li><p>SM version=6.1 的关键参数</p>
<table>
<thead>
<tr>
<th align="left">指标</th>
<th align="left">值</th>
</tr>
</thead>
<tbody><tr>
<td align="left">Maximum dimensionality of grid of thread blocks</td>
<td align="left">3</td>
</tr>
<tr>
<td align="left">Maximum x- or y-dimension of a block</td>
<td align="left">1024</td>
</tr>
<tr>
<td align="left">Maximum z-dimension of a block</td>
<td align="left">64</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th align="left">指标</th>
<th align="left">值</th>
</tr>
</thead>
<tbody><tr>
<td align="left">Maximum number of threads per block</td>
<td align="left">1024</td>
</tr>
<tr>
<td align="left">Warp size</td>
<td align="left">32</td>
</tr>
<tr>
<td align="left">Maximum number of resident <strong>grids</strong> per device</td>
<td align="left">32</td>
</tr>
<tr>
<td align="left">Maximum number of resident <strong>blocks</strong> per multiprocessor</td>
<td align="left">32</td>
</tr>
<tr>
<td align="left">Maximum number of resident <strong>warps</strong> per multiprocessor</td>
<td align="left">64</td>
</tr>
<tr>
<td align="left">Maximum number of resident <strong>threads</strong> per multiprocessor</td>
<td align="left">2048</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th align="left">指标</th>
<th align="left">值</th>
</tr>
</thead>
<tbody><tr>
<td align="left">Number of 32-bit registers <strong>per multiprocessor</strong></td>
<td align="left">64 K</td>
</tr>
<tr>
<td align="left">Maximum number of 32-bit registers <strong>per thread block</strong></td>
<td align="left">64 KB</td>
</tr>
<tr>
<td align="left">Maximum number of 32-bit registers <strong>per thread</strong></td>
<td align="left">255</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th align="left">指标</th>
<th align="left">值</th>
</tr>
</thead>
<tbody><tr>
<td align="left">Maximum amount of shared memory per multiprocessor</td>
<td align="left">96 KB</td>
</tr>
<tr>
<td align="left">Maximum amount of shared memory per thread block</td>
<td align="left">48 KB</td>
</tr>
<tr>
<td align="left">Number of shared memory banks</td>
<td align="left">32</td>
</tr>
<tr>
<td align="left">Amount of local memory per thread</td>
<td align="left">512 KB</td>
</tr>
<tr>
<td align="left">Constant memory size</td>
<td align="left">64 KB</td>
</tr>
<tr>
<td align="left">Maximum number of instructions per kernel</td>
<td align="left">512 million</td>
</tr>
</tbody></table>
</li>
</ol>
<p>这些指标要心里有数</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/02/20/CUDA-ComputeCapacity-SM-version6-1%E7%9A%84%E5%8F%82%E6%95%B0%E5%80%BC/" data-id="ck71en4ii0000hefzbfvja7pw" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/CUDA/" rel="tag">CUDA</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-CUDA-原子操作-例-直方图" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/02/20/CUDA-%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C-%E4%BE%8B-%E7%9B%B4%E6%96%B9%E5%9B%BE/" class="article-date">
  <time datetime="2020-02-20T02:11:52.000Z" itemprop="datePublished">2020-02-20</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/CUDA/">CUDA</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/02/20/CUDA-%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C-%E4%BE%8B-%E7%9B%B4%E6%96%B9%E5%9B%BE/">CUDA-原子操作-例-直方图</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="原子操作"><a href="#原子操作" class="headerlink" title="原子操作"></a>原子操作</h1><p><code>atomicAdd(), atomicSub(), atomicXor()...</code></p>
<p>原子操作要排队，所以，能不用就不要使用。</p>
<h1 id="原子操作-直方图"><a href="#原子操作-直方图" class="headerlink" title="原子操作-直方图"></a>原子操作-直方图</h1><p>前面说过了，原子操作能不用就不使用。但是有些情况只能使用原子操作，<font color="orange">当成千上万个threads同时修改同一个内存地址时，大规模并行系统会带来负担</font>，在硬件中支持的原子操作可以减轻这种负担。比如计算“直方图”：计算一个数组中元素的出现频率。许多算法需要计算直方图，比如在图像处理使用过。s</p>
<p>这里给出计算直方图的3种方法，CPU，未优化的GPU，优化后的GPU。</p>
<p>假如有一个很大的字符数组，实际中可能是像素的颜色值，或者是音频的采样数据。计算这个字符数组的直方图。由于每个随机的字符（一个char型占1 byte）都有<code>2x2x2x2x2x2x2x2=256</code>个不同的可能取值。所以直方图中要包含256个元素。</p>
<ol>
<li><p>CPU版本</p>
 <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> SIZE (100*1024*1024)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> main&#123;</span><br><span class="line">    <span class="comment">// 1) 生成100MB的随机数据</span></span><br><span class="line">    <span class="keyword">char</span>* buffer = (<span class="keyword">char</span>*)big_random_block( SIZE );</span><br><span class="line">    <span class="comment">// 2) 将buffer数组初始化为0</span></span><br><span class="line">    <span class="keyword">int</span> histo[<span class="number">256</span>];</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;<span class="number">256</span>;i++)&#123;</span><br><span class="line">        histo[i] = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 3) 计算每个字符出现的频率</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;SIZE;i++)&#123;</span><br><span class="line">        histo[buffer[i]]++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 4) 回收资源</span></span><br><span class="line">    <span class="built_in">free</span>(buffer);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p> 不必解释。</p>
</li>
<li><p>未优化的GPU</p>
<p> 计算直方图的特点是，读取buffer中的每一个元素，在histo数组中找到这个元素，后这个元素的频数加一，直到得到最后的直方图。如果使用并行计算，看到了吧，问题在哪？每一个thread读取buffer中不同的地址，取元素，没毛病。<font color="red">但是当写入histo数组时，会同时有多个threads写入histo的同一个位置，只必然造成Race condition（竞争）</font>。所以多个threads写入同一个地址时，将写操作串行。</p>
 <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">( <span class="keyword">void</span> )</span> </span>&#123;</span><br><span class="line">    <span class="keyword">char</span> *buffer = (<span class="keyword">unsigned</span> <span class="keyword">char</span>*)big_random_block( SIZE );</span><br><span class="line"></span><br><span class="line">    <span class="keyword">char</span> *dev_buffer;</span><br><span class="line">    <span class="keyword">int</span> *dev_histo;</span><br><span class="line">    HANDLE_ERROR( cudaMalloc( (<span class="keyword">void</span>**)&amp;dev_buffer, SIZE ) );</span><br><span class="line">    HANDLE_ERROR( cudaMemcpy( dev_buffer, buffer, SIZE,cudaMemcpyHostToDevice ) );</span><br><span class="line"></span><br><span class="line">    HANDLE_ERROR( cudaMalloc( (<span class="keyword">void</span>**)&amp;dev_histo, <span class="number">256</span> * <span class="keyword">sizeof</span>( <span class="keyword">long</span> ) ) );</span><br><span class="line">    <span class="comment">// dev_histo的初始化使用cudaMemset(), 将所有元素值设为0</span></span><br><span class="line">    HANDLE_ERROR( cudaMemset( dev_histo, <span class="number">0</span>, <span class="number">256</span> * <span class="keyword">sizeof</span>( <span class="keyword">int</span> ) ) );</span><br><span class="line"></span><br><span class="line">    kernel&lt;&lt;&lt;&gt;&gt;&gt;();  <span class="comment">//！！！</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> histo[<span class="number">256</span>];</span><br><span class="line">    HANDLE_ERROR( cudaMemcpy( histo, dev_histo, <span class="number">256</span> * <span class="keyword">sizeof</span>(<span class="keyword">int</span>), cudaMemcpyDeviceToHost ) );</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 验证GPU上计算的正确性，执行逆向运算，</span></span><br><span class="line">    <span class="comment">// 判断最后histo数组是否全为零（看是否可以会到初始值）</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;SIZE; i++)</span><br><span class="line">        histo[buffer[i]]--;  </span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;<span class="number">256</span>; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (histo[i] != <span class="number">0</span>)</span><br><span class="line">            <span class="built_in">printf</span>( <span class="string">"Failure at %d!\n"</span>, i );</span><br><span class="line">    &#125;</span><br><span class="line">    cudaFree( dev_histo );</span><br><span class="line">    cudaFree( dev_buffer );</span><br><span class="line">    <span class="built_in">free</span>( buffer );</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p> 现在只剩下kernel函数。结果直方图数组有<code>256</code>个元素，所以考虑每个block含有<code>256</code>个threads。其实可以有其他的配置，比如<code>100MB</code>数据共有<code>104,857,600</code>个字节，所以可以启动一个block，让每个thread处理<code>409,600</code>个数据，或者可以启动<code>409600</code>个blocks，每个thread处理1个元素。</p>
<p> 最有的配置方案介于这两种极端情况之间。实验发现，<font color="orange">当block的数量是芯片SM数量的2倍时，将达到最有性能。</font></p>
<p> 所以要先查硬件信息得到所使用GPU的SM数量：</p>
 <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cudaDeviceProp prop;</span><br><span class="line">HANDLE_ERROR( cudaGetDeviceProperties( &amp;prop, <span class="number">0</span> ) ); <span class="comment">// 使用0号GPU</span></span><br><span class="line"><span class="keyword">int</span> numSM = prop.multiProcessorCount;</span><br><span class="line">kernel&lt;&lt;&lt;numSM*<span class="number">2</span>, <span class="number">256</span>&gt;&gt;&gt;(dev_buffer, SIZE, dev_histo); <span class="comment">// 未实现</span></span><br></pre></td></tr></table></figure>

<p> 下面实现kernel。</p>
<p> kernel的参数有三个：一个指向输入数组的指针，输入数组的长度，一个指向输出直方图数组的指针。</p>
 <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">__<span class="function">global__ <span class="keyword">void</span> <span class="title">histo_kernel</span><span class="params">( <span class="keyword">char</span> *buffer,</span></span></span><br><span class="line"><span class="function"><span class="params">                                <span class="keyword">long</span> size,</span></span></span><br><span class="line"><span class="function"><span class="params">                                <span class="keyword">int</span> *histo )</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">    <span class="keyword">int</span> stride = blockDim.x * gridDim.x;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// stride loop</span></span><br><span class="line">    <span class="keyword">while</span> (i &lt; size) &#123;</span><br><span class="line">        atomicAdd( &amp;(histo[buffer[i]]), <span class="number">1</span> );</span><br><span class="line">        i += stride;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p> 其中<code>atomicAdd( &amp;(histo[buffer[i]]), 1 )</code>展示了如何使用原子操作：<code>atomicAdd( add, y )</code>, 这个操作读取地址add中值，将y加到add的值上。这个例子中add就是直方图中相应元素的位置。</p>
<p> 性能结果怎样呢？实验得GPU版本比CPU版本性能差许多被。分析原因：</p>
<ul>
<li><p>第一，kernel函数实际上只包含了非常少的计算工作，而对global的访问远远多于计算，并且对global的访问相当慢。<font color="orange">计算少，访存多，撞上性能瓶颈</font>。</p>
</li>
<li><p>第二，当上<font color="red">万</font>个threads访问<font color="red">少量</font>（256）的内存位置时，发生<font color="red">严重</font>的race condition。而且原子操作为了保证结果的正确性，对于相同的内存位置都将<font color="red">串行化</font>。这导致<font color="red">排了非常长</font>的队伍，因此抵消了并行带来的性能提升。</p>
<p>所以尝试优化GPU</p>
</li>
</ul>
</li>
<li><p>使用shared memory优化原子操作</p>
<p> 主要问题并不是使用了过多的原子操作，而是有<font color="orange">太多的threads写入太少的地址造成的竞争</font>。考虑使用两段操作。</p>
<p> 为方便画图表示，假如元素只有<code>x，y，z</code>三种字符。那么自然地，每个block使用3个threads干活，对应的Shared memory大小也为3。假设block个数是2。两阶段如下图：</p>
 <div align="center"><img src="/2020/02/20/CUDA-%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C-%E4%BE%8B-%E7%9B%B4%E6%96%B9%E5%9B%BE/histo.png" width="700"></div>

<p> 过程如下：</p>
<p> 第一段，让每个并行的block计算它所处理的数据，将结果写入各自block对应的shared memory中。这样做的好处有：</p>
<ul>
<li><p>第一，所有blocks之间的计算是<font color="orange">并行的</font>。</p>
</li>
<li><p>第二，写入shared memory效率远高于写入global memory。</p>
</li>
<li><p>第三，这种方式仍然需要原子操作，但是此时是<font color="orange">256个threads在256个地址上的竞争，竞争程度显著减少</font>。</p>
<p>所以，第一阶段计算得到每个block的临时直方图，比如，有三个blocks, 那么遍历完所有元素后会得到三个临时直方图。当得到所有三个临时直方图后（要同步），开始第二个计算阶段。</p>
<p>第二段，将得到的全部临时直方图合并为最终直方图，也应该是原子操作。这一段是，会有<font color="orange">block数量个threads在256个地址上的竞争，竞争程度又显著减少</font>。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">__<span class="function">global__ <span class="keyword">void</span> <span class="title">histo_kernel</span><span class="params">( <span class="keyword">char</span>* buffer,</span></span></span><br><span class="line"><span class="function"><span class="params">                                <span class="keyword">long</span> size,</span></span></span><br><span class="line"><span class="function"><span class="params">                                <span class="keyword">int</span>* histo )</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 初始化</span></span><br><span class="line">    __shared__ <span class="keyword">unsigned</span> <span class="keyword">int</span> temp[<span class="number">256</span>];</span><br><span class="line">    temp[threadIdx.x] = <span class="number">0</span>;</span><br><span class="line">    __syncthreads();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> i = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">    <span class="keyword">int</span> offset = blockDim.x * gridDim.x;</span><br><span class="line">    <span class="comment">// 第一段计算</span></span><br><span class="line">    <span class="keyword">while</span> (i &lt; size) &#123;</span><br><span class="line">        atomicAdd( &amp;temp[buffer[i]], <span class="number">1</span> );</span><br><span class="line">        i += offset;</span><br><span class="line">    &#125;</span><br><span class="line">    __syncthreads();</span><br><span class="line"></span><br><span class="line">    <span class="comment">//第二段计算</span></span><br><span class="line">    atomicAdd( &amp;(histo[threadIdx.x]), temp[threadIdx.x] );</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// kernel 的配置如下</span></span><br><span class="line">kernel&lt;&lt;&lt;numSM*<span class="number">2</span>, <span class="number">256</span>&gt;&gt;&gt;(dev_buffer, SIZE, dev_histo);</span><br></pre></td></tr></table></figure>

<p>在实际SP和threads执行中，上述代码（指令）被复制很多份，有多少个threads就复制多少份。这些拷贝的不同在于，<code>threadIdx.x</code>，<code>blockIdx.x</code>这些值会被自动赋值，<code>0, 1, 2, 3, ...</code></p>
<p>性能如何？比CPU版本的<font color="red">快了一个数量级</font>。</p>
</li>
</ul>
</li>
</ol>
<p>总结：使用了一种两阶段的算法，从而降低了在global memory上访存的竞争程度。这种降低竞争的策略总能获得不错的效果，所以当使用原子操作时，记住这种操作。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/02/20/CUDA-%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C-%E4%BE%8B-%E7%9B%B4%E6%96%B9%E5%9B%BE/" data-id="ck71en4l8004jhefz34t25pva" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/CUDA/" rel="tag">CUDA</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-CUDA-常量内存提升性能-例-RayTracing" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/02/20/CUDA-%E5%B8%B8%E9%87%8F%E5%86%85%E5%AD%98%E6%8F%90%E5%8D%87%E6%80%A7%E8%83%BD-%E4%BE%8B-RayTracing/" class="article-date">
  <time datetime="2020-02-20T02:09:40.000Z" itemprop="datePublished">2020-02-20</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/CUDA/">CUDA</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/02/20/CUDA-%E5%B8%B8%E9%87%8F%E5%86%85%E5%AD%98%E6%8F%90%E5%8D%87%E6%80%A7%E8%83%BD-%E4%BE%8B-RayTracing/">CUDA-常量内存提升性能-例-RayTracing</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <ol>
<li><p>constants 常量必须在函数外声明</p>
</li>
<li><p><code>cudaMemcpyToSymbol()</code></p>
<p> 这个函数是特殊版本的<code>cudaMemcpy()</code>, 唯一的不同是，<code>cudaMemcpyToSymbol()</code>将数据复制到<font color="red">常量内存constant memory</font>，而<code>cudaMemcpy()</code>将数据复制到global memory。</p>
</li>
<li><p>常量内存为什么能提升性能-Ray tracing</p>
<p> <code>__constant__</code> 把变量的访问限制为<code>read-only</code>，有了这个限制，必然获得某种回报。这个回报是：<font>与从global memory中读取数据相比，从constant memory中读取相同的数据可以节约内存带宽</font>，有两个原因：</p>
<ul>
<li><p>对constant memory的<font color="red">单次读</font>操作可以广播到其他<font>临近</font>的threads。 </p>
</li>
<li><p>constant memory的数据将会缓存起来，因此<font color="red">相同地址的连续读操作</font>不会产生额外的内存通信。</p>
<p>half-warp的 广播是一把双刃剑。当16 个threads都读取constant memory<font color="red">相同</font>的地址的时，性能极大地提升。但是当16个threads分别读取从constant memory<font color="red">不同</font>的地址时，读操作会被串行化，性能会下降，这种情况就不如从global中读取。</p>
<p>从<code>Ray-Tracing</code>实例中体会：</p>
<p>要使用到的数据结构：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> INF 2e10f</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Sphere</span> &#123;</span></span><br><span class="line">    <span class="keyword">float</span> r,b,g;</span><br><span class="line">    <span class="keyword">float</span> radius;</span><br><span class="line">    <span class="keyword">float</span> x,y,z;</span><br><span class="line">    <span class="comment">// 假设有一个观察平面，那么（ox，oy）是这个观察平面中一个像素的坐标，</span></span><br><span class="line">    <span class="comment">// 这个方法将计算从这个像素中发射出的光线是否与这个球面相交。</span></span><br><span class="line">    <span class="comment">// 如果相交，则计算从这个像素点到这个球面的距离。当光线命中多个球时，</span></span><br><span class="line">    <span class="comment">// 只有最近的球面才会被看到。</span></span><br><span class="line">    __<span class="function">device__ <span class="keyword">float</span> <span class="title">hit</span><span class="params">( <span class="keyword">float</span> ox, <span class="keyword">float</span> oy, <span class="keyword">float</span> *n )</span> </span>&#123;</span><br><span class="line">        <span class="keyword">float</span> dx = ox - x;</span><br><span class="line">        <span class="keyword">float</span> dy = oy - y;</span><br><span class="line">        <span class="keyword">if</span> (dx*dx + dy*dy &lt; radius*radius) &#123;</span><br><span class="line">            <span class="keyword">float</span> dz = sqrtf( radius*radius - dx*dx - dy*dy );</span><br><span class="line">            *n = dz / sqrtf( radius * radius );</span><br><span class="line">            <span class="keyword">return</span> dz + z;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> -INF;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>kernel函数输入一个bitmap：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">__<span class="function">global__ <span class="keyword">void</span> <span class="title">kernel</span><span class="params">( <span class="keyword">unsigned</span> <span class="keyword">char</span> *ptr )</span> </span>&#123;</span><br><span class="line">    <span class="comment">// map from threadIdx/BlockIdx to pixel position</span></span><br><span class="line">    <span class="keyword">int</span> x = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">    <span class="keyword">int</span> y = threadIdx.y + blockIdx.y * blockDim.y;</span><br><span class="line">    <span class="keyword">int</span> offset = x + y * blockDim.x * gridDim.x;</span><br><span class="line">    <span class="keyword">float</span> ox = (x - DIM/<span class="number">2</span>);</span><br><span class="line">    <span class="keyword">float</span> oy = (y - DIM/<span class="number">2</span>);</span><br><span class="line">    <span class="keyword">float</span> r=<span class="number">0</span>, g=<span class="number">0</span>, b=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">float</span> maxz = -INF;</span><br><span class="line">    <span class="comment">// 每个线程考察所有的球，得到每个距离每个像素最近的球面。</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;SPHERES; i++) &#123;</span><br><span class="line">        <span class="keyword">float</span> n;</span><br><span class="line">        <span class="keyword">float</span> t = s[i].hit( ox, oy, &amp;n );</span><br><span class="line">        <span class="keyword">if</span> (t &gt; maxz) &#123;</span><br><span class="line">            <span class="keyword">float</span> fscale = n;</span><br><span class="line">            r = s[i].r * fscale;</span><br><span class="line">            g = s[i].g * fscale;</span><br><span class="line">            b = s[i].b * fscale;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    ptr[offset*<span class="number">4</span> + <span class="number">0</span>] = (<span class="keyword">int</span>)(r * <span class="number">255</span>);</span><br><span class="line">    ptr[offset*<span class="number">4</span> + <span class="number">1</span>] = (<span class="keyword">int</span>)(g * <span class="number">255</span>);</span><br><span class="line">    ptr[offset*<span class="number">4</span> + <span class="number">2</span>] = (<span class="keyword">int</span>)(b * <span class="number">255</span>);</span><br><span class="line">    ptr[offset*<span class="number">4</span> + <span class="number">3</span>] = <span class="number">255</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>for循环中，每一个thread循环球集合<code>Sphere *s</code>中的所有球<code>s[i]</code>，得到每个像素的一个颜色值。这里的模式是：<font color="red">所有threads都会只读相同的存储地址</font>。考虑上述的关于constant的特点，使用constant memory 进行优化。</p>
<p>优化前的main函数如下：其中<code>s</code>是声明在global memory中的。用constant memory优化只需要将下面code中的<code>&lt;1&gt;&lt;2&gt;</code>分别修改为</p>
</li>
<li><p>&lt;1&gt; <code>__constant__ Sphere s[SPHERES]</code>;</p>
</li>
<li><p>&lt;2&gt; <code>HANDLE_ERROR( cudaMemcpyToSymbol( s, temp_s, sizeof(Sphere) * SPHERES) );</code></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"cpu_bitmap.h"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> rnd( x ) (x * rand() / RAND_MAX)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> SPHERES 20</span></span><br><span class="line">Sphere *s; <span class="comment">// &lt;1&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">( <span class="keyword">void</span> )</span> </span>&#123;</span><br><span class="line">    <span class="function">CPUBitmap <span class="title">bitmap</span><span class="params">( DIM, DIM )</span></span>;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">char</span> *dev_bitmap;</span><br><span class="line">    <span class="comment">// allocate memory on the GPU for the output bitmap</span></span><br><span class="line">    HANDLE_ERROR( cudaMalloc( (<span class="keyword">void</span>**)&amp;dev_bitmap, bitmap.image_size() ) );</span><br><span class="line">    <span class="comment">// allocate memory for the Sphere dataset</span></span><br><span class="line">    HANDLE_ERROR( cudaMalloc( (<span class="keyword">void</span>**)&amp;s, <span class="keyword">sizeof</span>(Sphere) * SPHERES ) ); <span class="comment">// &lt;2&gt;</span></span><br><span class="line"></span><br><span class="line">    Sphere *temp_s = (Sphere*)<span class="built_in">malloc</span>( <span class="keyword">sizeof</span>(Sphere) * SPHERES );</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;SPHERES; i++) &#123;</span><br><span class="line">        temp_s[i].r = rnd( <span class="number">1.0f</span> );</span><br><span class="line">        temp_s[i].g = rnd( <span class="number">1.0f</span> );</span><br><span class="line">        temp_s[i].b = rnd( <span class="number">1.0f</span> );</span><br><span class="line">        temp_s[i].x = rnd( <span class="number">1000.0f</span> ) - <span class="number">500</span>;</span><br><span class="line">        temp_s[i].y = rnd( <span class="number">1000.0f</span> ) - <span class="number">500</span>;</span><br><span class="line">        temp_s[i].z = rnd( <span class="number">1000.0f</span> ) - <span class="number">500</span>;</span><br><span class="line">        temp_s[i].radius = rnd( <span class="number">100.0f</span> ) + <span class="number">20</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    HANDLE_ERROR( cudaMemcpy( s, temp_s, <span class="keyword">sizeof</span>(Sphere) * SPHERES,</span><br><span class="line">                                cudaMemcpyHostToDevice ) );</span><br><span class="line">    <span class="built_in">free</span>( temp_s );</span><br><span class="line"></span><br><span class="line">    <span class="comment">// generate a bitmap from our sphere data</span></span><br><span class="line">    <span class="function">dim3 <span class="title">grids</span><span class="params">(DIM/<span class="number">16</span>,DIM/<span class="number">16</span>)</span></span>;</span><br><span class="line">    <span class="function">dim3 <span class="title">threads</span><span class="params">(<span class="number">16</span>,<span class="number">16</span>)</span></span>;</span><br><span class="line">    kernel&lt;&lt;&lt;grids,threads&gt;&gt;&gt;( dev_bitmap );</span><br><span class="line"></span><br><span class="line">    <span class="comment">// copy our bitmap back from the GPU for display</span></span><br><span class="line">    HANDLE_ERROR( cudaMemcpy( bitmap.get_ptr(), dev_bitmap, bitmap.image_size(),</span><br><span class="line">                                cudaMemcpyDeviceToHost ) );</span><br><span class="line">    bitmap.display_and_exit();</span><br><span class="line">    <span class="comment">// free our memory</span></span><br><span class="line">    cudaFree( dev_bitmap );</span><br><span class="line">    cudaFree( s );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>上述过程使用constant memory保存只读对象。感受这个模式：<font color="red">每个threads都访问相同的只读数据时，将获得额外的性能提升</font>. 前面说了的两个原因：第一，这种模式将读取操作在半个warp中广播，第二，芯片上包含了常量内存缓存。</p>
<p>在许多算法中，内存带宽都是瓶颈，因此要时刻想着改善这种情况，</p>
</li>
</ul>
</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/02/20/CUDA-%E5%B8%B8%E9%87%8F%E5%86%85%E5%AD%98%E6%8F%90%E5%8D%87%E6%80%A7%E8%83%BD-%E4%BE%8B-RayTracing/" data-id="ck71en4jk001lhefz73iv71r7" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/CUDA/" rel="tag">CUDA</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-CUDA-死锁-例-点积" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/02/20/CUDA-%E6%AD%BB%E9%94%81-%E4%BE%8B-%E7%82%B9%E7%A7%AF/" class="article-date">
  <time datetime="2020-02-20T02:06:51.000Z" itemprop="datePublished">2020-02-20</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/CUDA/">CUDA</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/02/20/CUDA-%E6%AD%BB%E9%94%81-%E4%BE%8B-%E7%82%B9%E7%A7%AF/">CUDA-死锁-例-点积</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="好好体会-Dot-product"><a href="#好好体会-Dot-product" class="headerlink" title="好好体会-Dot product"></a>好好体会-Dot product</h1><p>（CUDA by example 55页）</p>
<p><font color="orange" size="3">这个例子值得好好感悟</font></p>
<p>点积：两个长度相同的向量A和B，对应元素相乘后相加。</p>
<p>CUDA实现思路：每个线程分别读取A和B中对应位置的元素，紧接着执行相乘操作，最后将相乘结果存入shared memory的对应位置。</p>
<p>注意，当向量元素个数远远超过一个block中的threads数量时的处理。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> N = <span class="number">33</span>*<span class="number">1025</span>;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> threadsPerBlock = <span class="number">256</span>;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> blocksPerGrid = (N+threadsPerBlock<span class="number">-1</span>)/threadsPerBlock;</span><br><span class="line"></span><br><span class="line">__<span class="function">global__ <span class="keyword">void</span> <span class="title">dotProduction</span><span class="params">(<span class="keyword">float</span>* a, <span class="keyword">float</span>* b)</span></span>&#123;</span><br><span class="line">    <span class="comment">/// 第一步：thread计算得到a和b对应元素的乘积，</span></span><br><span class="line">    <span class="comment">// 存入这个thread对应的shared memory中的位置</span></span><br><span class="line">    <span class="comment">// 每个block对应的shared memory的大小为这个block中的threads数量</span></span><br><span class="line">    __shared__ <span class="keyword">float</span> cache[threadsPerBlock];</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> tid = threadIdx.x + blockDim.x*blocIdx.x;</span><br><span class="line">    <span class="comment">// 每个block的shared memory的索引就是threadIdx.x，与blockIdx.x 无关,</span></span><br><span class="line">    <span class="comment">// 这个block和那个block中的thread的ID是一摸一样的。</span></span><br><span class="line">    <span class="keyword">int</span> cacheIndex = threadsIdx.x;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 执行乘法操作，更新threads ID，</span></span><br><span class="line">    <span class="comment">// 同stride-loop</span></span><br><span class="line">    <span class="comment">// 看图一的过程</span></span><br><span class="line">    <span class="keyword">float</span> tmp = <span class="number">0.0f</span>;</span><br><span class="line">    <span class="keyword">while</span> (tid&lt;N)&#123;</span><br><span class="line">        tmp += a[tid]*b[tid];</span><br><span class="line">        tid += blockDim.x*gridDim.x;</span><br><span class="line">    &#125;</span><br><span class="line">    cache[cacheIndex] = tmp;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 同步这个block中的所有threads</span></span><br><span class="line">    __syncthreads();</span><br><span class="line">    <span class="comment">// 确保所有threads完成工作之后，执行后续指令</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/// 第二步：对于每个block对应的shared memory中的元素，进行规约求和。</span></span><br><span class="line">    <span class="comment">// 其中threadPerBlock必须是2的指数。</span></span><br><span class="line">    <span class="comment">// 同for-loop</span></span><br><span class="line">    <span class="keyword">int</span> i = blockDim.x/<span class="number">2</span>;</span><br><span class="line">    <span class="keyword">while</span>(i != <span class="number">0</span>)&#123;</span><br><span class="line">        <span class="keyword">if</span> (cacheIndex &lt;i )</span><br><span class="line">            cache[cacheIndex] += cache[cacheIndex + i];</span><br><span class="line">        <span class="comment">// 确保上一轮所有和得到，所以要同步</span></span><br><span class="line">        __syncthreads();</span><br><span class="line">        i /= <span class="number">2</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 把每个shared memory中的第一个元素，也就是这个shared memory中</span></span><br><span class="line">    <span class="comment">// 所有元素之和，写入c中对应的位置。</span></span><br><span class="line">    <span class="keyword">if</span>(cacheIndex == <span class="number">0</span>)</span><br><span class="line">        c[blockIdx.x] = cache[<span class="number">0</span>];</span><br><span class="line">&#125;</span><br><span class="line">...</span><br><span class="line"><span class="comment">// 在主函数中，把c从device拷贝到host，以及之后：</span></span><br><span class="line">cudaMemcpy(h_c, c, cudaMemcpyDeviceToHost);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 在CPU上将h_c中的结果求和，于此同时GPU上可以后其他任务执行。</span></span><br><span class="line"><span class="comment">// CPU和GPU并行执行。隐藏延时</span></span><br><span class="line"><span class="keyword">float</span> sum = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>;i &lt; blocksPerGrid; i++)&#123;</span><br><span class="line">    sum += h_c[i];</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// sum即是最终点积结果。</span></span><br></pre></td></tr></table></figure>

<p>其中这一部分：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">float</span> tmp = <span class="number">0.0f</span>;</span><br><span class="line"><span class="keyword">while</span> (tid&lt;N)&#123;</span><br><span class="line">    tmp += a[tid]*b[tid];</span><br><span class="line">    tid += blockDim.x*gridDim.x; <span class="comment">// 更新tid，自加不是1，而是所有threads数量。</span></span><br><span class="line">&#125;</span><br><span class="line">cache[cacheIndex] = tmp;</span><br></pre></td></tr></table></figure>

<p>当所有threads的数目小于a或b中的元素个数时（不论有多少个blocks），上述保证正确，与<font color="red">stride更新</font>效果相同。当threads个数等于元素个数时，也正确。所以这样写，分析见下图：</p>
<div align="center"><img src="/2020/02/20/CUDA-%E6%AD%BB%E9%94%81-%E4%BE%8B-%E7%82%B9%E7%A7%AF/dot0.png" width="600"></div>

<p>上图中只使用了<font color="orange">一个block</font>，所以在第二步归约计算时，就可以在第0个位置上得到最终结果。当使用多个blocks时，第二步得到<font color="orange">每个block的第0个元素</font>，而这些若干个第0个元素保存于c（Global）中，最终还要将c中元素求和。</p>
<p>而下面这种实现：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (tid&lt;N)&#123;</span><br><span class="line">    cache[threadIdx.x] = a[tid]*b[tid];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>只适用于thread个数等于元素个数时。但通常元素个数会远大于threads数。所以不适用此法。</p>
<div align="center"><img src="/2020/02/20/CUDA-%E6%AD%BB%E9%94%81-%E4%BE%8B-%E7%82%B9%E7%A7%AF/dot1.png" width="600"></div>

<ul>
<li><p>技能：<font color="orange" size="4">多个blocks中的各个shared memory 缓存同时被s操作</font>。</p>
</li>
<li><p>为什么要将最后的结果传回host计算？</p>
<p>  因为，事实证明，<font color="orange">想GPU这种大规模并行机器在执行最后的规约步骤时，通常会浪费计算资源，因为此时的数据集非常小。比如，当使用480 个threads将32 个数相加时，将难以充分使用每一个threads</font>。</p>
</li>
</ul>
<p>总结一下，使用shared memory优化dot-production为什么有效，因为减少了写入global memory的次数，并且复制回host的数据量减少。性能增加。</p>
<p><font color="gree" size="4">敲黑板</font>注意threadIdx.x 与threads ID的区别，前者相对ID后者绝对ID。<font color="red" size="4">访存Shared memory时，一定使用threadIdx.x</font>。</p>
<h1 id="syncthreads-放错位置会导致死锁"><a href="#syncthreads-放错位置会导致死锁" class="headerlink" title="__syncthreads() 放错位置会导致死锁"></a>__syncthreads() 放错位置会导致死锁</h1><p>规约程序中：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> i=blockDim.x/<span class="number">2</span>;</span><br><span class="line"><span class="keyword">while</span>(i != <span class="number">0</span>)&#123;</span><br><span class="line">    <span class="keyword">if</span> (cacheIndex &lt;i )</span><br><span class="line">        cache[cacheIndex] += cache[cacheIndex + i];</span><br><span class="line">    __syncthreads();</span><br><span class="line">    i /= <span class="number">2</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>如果将<code>__syncthreads()</code>放入if语句，会产生死锁：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> i=blockDim.x/<span class="number">2</span>;</span><br><span class="line"><span class="keyword">while</span>(i != <span class="number">0</span>)&#123;</span><br><span class="line">    <span class="keyword">if</span> (cacheIndex &lt;i )&#123;</span><br><span class="line">        cache[cacheIndex] += cache[cacheIndex + i];</span><br><span class="line">        __syncthreads();</span><br><span class="line">    &#125;</span><br><span class="line">    i /= <span class="number">2</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>解释一下，当出现线程发散时，发散的分支会使得某些threads处于空闲状态，而其他threads将执行分支中的代码。而对于<code>__syncthreads()</code>而言，<font color="orange" size="4">CUDA架构确保，一个block中的所有threads都执行到<code>__syncthreads()</code>，才能执行<code>__syncthreads()</code>之后的语句</font>。这样一来，上述代码块，只要有一个threads没有执行if语句，也就不能够执行<code>__syncthreads()</code>，其他执行了if语句的threads会等待哪一个thread，一直等下去，造成死锁。</p>
<p>所以，对于<code>__syncthreads()</code>要谨慎使用。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/02/20/CUDA-%E6%AD%BB%E9%94%81-%E4%BE%8B-%E7%82%B9%E7%A7%AF/" data-id="ck71en4jm001rhefz49u2ezt5" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/CUDA/" rel="tag">CUDA</a></li></ul>

    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/8/">8</a><a class="extend next" rel="next" href="/page/2/">Next &amp;raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/C/">C++</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/CUDA/">CUDA</a><span class="category-list-count">35</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Deep-Learning-Algorithms/">Deep Learning Algorithms</a><span class="category-list-count">11</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hardware/">Hardware</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/LeetCode/">LeetCode</a><span class="category-list-count">11</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linear-Algebra/">Linear Algebra</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Utility/">Utility</a><span class="category-list-count">9</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%BE%85%E5%BD%92%E7%B1%BB/">待归类</a><span class="category-list-count">1</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Algorithms/" rel="tag">Algorithms</a><span class="tag-list-count">15</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CUDA/" rel="tag">CUDA</a><span class="tag-list-count">31</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Test-Analysis/" rel="tag">Test Analysis</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hardware/" rel="tag">hardware</a><span class="tag-list-count">1</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Algorithms/" style="font-size: 16.67px;">Algorithms</a> <a href="/tags/CUDA/" style="font-size: 20px;">CUDA</a> <a href="/tags/Test-Analysis/" style="font-size: 13.33px;">Test Analysis</a> <a href="/tags/hardware/" style="font-size: 10px;">hardware</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/02/">February 2020</a><span class="archive-list-count">15</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">January 2020</a><span class="archive-list-count">9</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">December 2019</a><span class="archive-list-count">10</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">November 2019</a><span class="archive-list-count">6</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/10/">October 2019</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/09/">September 2019</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/08/">August 2019</a><span class="archive-list-count">23</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/07/">July 2019</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/1970/01/">January 1970</a><span class="archive-list-count">1</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2020/02/28/CUDA-%E5%B9%B6%E8%A1%8C%E4%B8%80%E7%BB%B4%E5%8D%B7%E7%A7%AF/">CUDA-并行一维卷积</a>
          </li>
        
          <li>
            <a href="/2020/02/25/LeetCode-%E6%96%B9%E6%B3%95%E8%AE%BA-stack/">LeetCode-方法论-stack</a>
          </li>
        
          <li>
            <a href="/2020/02/20/CUDA-%E6%9D%82%E8%AE%B0%E5%BE%85%E5%BD%92%E7%B1%BB/">CUDA-杂记待归类</a>
          </li>
        
          <li>
            <a href="/2020/02/20/CUDA-%E6%89%AB%E6%8F%8F%E7%AE%97%E6%B3%95/">CUDA-扫描算法</a>
          </li>
        
          <li>
            <a href="/2020/02/20/CUDA-%E5%86%8D%E7%9C%8B%E8%A7%84%E7%BA%A6-%E4%B8%80%E6%AE%B5%E8%A7%84%E7%BA%A6/">CUDA-再看规约-一段规约</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2020 Junhui<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div>
</body>
</html>