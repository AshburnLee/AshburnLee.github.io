<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>CUDA-overlap data transfer | Junhui&#39;s Journal</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Overlap Data Transfers目的是通过并发，隐藏延时。we discuss how to overlap data transfers with computation on the host。并发是指数据传输和host上的操作一同执行。Achieving overlap between data transfers and other operations requires th">
<meta property="og:type" content="article">
<meta property="og:title" content="CUDA-overlap data transfer">
<meta property="og:url" content="http://yoursite.com/2019/11/28/CUDA-overlap-data-transfer/index.html">
<meta property="og:site_name" content="Junhui&#39;s Journal">
<meta property="og:description" content="Overlap Data Transfers目的是通过并发，隐藏延时。we discuss how to overlap data transfers with computation on the host。并发是指数据传输和host上的操作一同执行。Achieving overlap between data transfers and other operations requires th">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2019-11-28T15:01:48.000Z">
<meta property="article:modified_time" content="2020-01-12T14:52:22.293Z">
<meta property="article:author" content="Junhui">
<meta property="article:tag" content="CUDA">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Junhui&#39;s Journal" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 4.2.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Junhui&#39;s Journal</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-CUDA-overlap-data-transfer" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/11/28/CUDA-overlap-data-transfer/" class="article-date">
  <time datetime="2019-11-28T15:01:48.000Z" itemprop="datePublished">2019-11-28</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/CUDA/">CUDA</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      CUDA-overlap data transfer
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="Overlap-Data-Transfers"><a href="#Overlap-Data-Transfers" class="headerlink" title="Overlap Data Transfers"></a>Overlap Data Transfers</h1><p>目的是通过并发，隐藏延时。we discuss how to overlap data transfers with computation on the host。并发是指数据传输和host上的操作一同执行。Achieving overlap between data transfers and other operations requires the use of CUDA streams, so first let’s learn about streams.</p>
<h2 id="CUDA-Srteam"><a href="#CUDA-Srteam" class="headerlink" title="CUDA Srteam"></a>CUDA Srteam</h2><p>A stream in CUDA is a sequence of operations that execute on the device in the order in which they are issued by the host code. While operations within a stream are guaranteed to execute in the prescribed order, operations in different streams can be interleaved and, when possible, they can even run concurrently.</p>
<h3 id="1-The-default-stream"><a href="#1-The-default-stream" class="headerlink" title="1. The default stream"></a>1. The default stream</h3><p>All device operations (kernels and data transfers) in CUDA run in a stream. When no stream is specified, the default stream (also called the “null stream”) is used. The default stream is different from other streams because it is a synchronizing stream with respect to operations on the device: no operation in the default stream will begin until all previously issued operations in any stream on the device have completed, and an operation in the default stream must complete before any other operation (in any stream on the device) will begin.</p>
<p>Please note that CUDA 7, released in 2015, introduced a new option to use a separate default stream per host thread, and to treat per-thread default streams as regular streams (i.e. they don’t synchronize with operations in other streams)</p>
<p>Let’s look at some simple code examples that use the default stream, and discuss how operations progress from the perspective of the host as well as the device.</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cudaMemcpy(d_a, a, numBytes, cudaMemcpyHostToDevice);</span><br><span class="line">increment&lt;&lt;&lt;<span class="number">1</span>,N&gt;&gt;&gt;(d_a)</span><br><span class="line">cudaMemcpy(a, d_a, numBytes, cudaMemcpyDeviceToHost);</span><br></pre></td></tr></table></figure>

<p>From the perspective of the device, all three operations are issued to the same (default) stream and will execute in the order that they were issued.</p>
<p>From the perspective of the host, the implicit data transfers are blocking or synchronous transfers, while the kernel launch is asynchronous. </p>
<p>Since the host-to-device data transfer on the first line is synchronous, the CPU thread will not reach the kernel call on the second line until the host-to-device transfer is complete. Once the kernel is issued, the CPU thread moves to the third line, but the transfer on that line cannot begin due to the device-side order of execution.</p>
<p>The asynchronous behavior of kernel launches from the host’s perspective makes overlapping device and host computation very simple. We can modify the code to add some independent CPU computation as follows.</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cudaMemcpy(d_a, a, numBytes, cudaMemcpyHostToDevice);</span><br><span class="line">increment&lt;&lt;&lt;<span class="number">1</span>,N&gt;&gt;&gt;(d_a)    <span class="comment">// device 执行这个</span></span><br><span class="line">myCpuFunction(b)           <span class="comment">// 同时 host 执行这个</span></span><br><span class="line">cudaMemcpy(a, d_a, numBytes, cudaMemcpyDeviceToHost);</span><br></pre></td></tr></table></figure>

<p>上述code实现了一个overlap，在<code>increment()</code>和<code>myCpuFunction()</code>同时分别在device和host端执行。Whether the host function or device kernel completes first doesn’t affect the subsequent device-to-host transfer, which will begin only after the kernel completes.  From the perspective of the device, nothing has changed from the previous example; the device is completely unaware of myCpuFunction(). 从device的角度看，device并不知道<code>myCpuFunction()</code>这个操作的存在，device端的操作与前一段code一模一样。</p>
<h3 id="2-Non-default-streams"><a href="#2-Non-default-streams" class="headerlink" title="2. Non-default streams"></a>2. Non-default streams</h3><p>Non-default streams in CUDA C/C++ are declared, created, and destroyed in host code as follows.</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cudaStream_t stream1;    <span class="comment">// 声明一个stream</span></span><br><span class="line">cudaError_t result;</span><br><span class="line">result = cudaStreamCreate(&amp;stream1)  <span class="comment">// create</span></span><br><span class="line">result = cudaStreamDestroy(stream1)   <span class="comment">// destroy</span></span><br></pre></td></tr></table></figure>

<p>To issue a data transfer to a non-default stream we use the <code>cudaMemcpyAsync()</code> function, which is similar to the <code>cudaMemcpy()</code> function discussed in the previous post, but takes a stream identifier as a <strong>fifth</strong> argument.</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">result = cudaMemcpyAsync(d_a, a, N, cudaMemcpyHostToDevice, stream1)</span><br></pre></td></tr></table></figure>

<p><code>cudaMemcpyAsync()</code> is non-blocking on the host, so control returns to the host thread immediately after the transfer is issued. There are <code>cudaMemcpy2DAsync()</code> and <code>cudaMemcpy3DAsync()</code> variants of this routine which can transfer 2D and 3D array sections asynchronously in the specified streams.</p>
<p>To issue a kernel to a non-default stream we specify the stream identifier as a <strong>fourth</strong> execution configuration parameter (the <strong>third</strong> execution configuration parameter allocates <code>shared device memory</code>, which we’ll talk about later; use 0 for now).</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">increment&lt;&lt;&lt;<span class="number">1</span>, N, <span class="number">0</span>, stream1&gt;&gt;&gt;(d_a)</span><br></pre></td></tr></table></figure>

<h3 id="3-Synchronization-with-streams"><a href="#3-Synchronization-with-streams" class="headerlink" title="3. Synchronization with streams"></a>3. Synchronization with streams</h3><p>在执行cudaMemcpy()时，code变为同步的，就是说，host code要等待这个copy函数执行完毕，才能接着往下执行。而all operations in non-default streams are non-blocking with respect to the host code,  you will run across situations where you need to synchronize the host code with operations in a stream. 同步就需要我们来做了。有若干种方法来同步：The “heavy hammer” way is to use <code>cudaDeviceSynchronize()</code>, which blocks the host code until all previously issued operations on the device have completed. In most cases this is <strong>overkill</strong>, and can really hurt performance due to stalling the entire device and host thread.</p>
<p>The <strong>CUDA stream API</strong> has multiple less severe methods of synchronizing the host with a stream. </p>
<ul>
<li><code>cudaStreamSynchronize(stream)</code> can be used to block the host thread until all previously issued operations in the specified stream have completed.</li>
<li><code>cudaStreamQuery(stream)</code> tests whether all operations issued to the specified stream have completed, without blocking host execution.</li>
<li><code>cudaEventSynchronize(event)</code> &amp; <code>cudaEventQuery(event)</code> act similar to their stream counterparts, except that their result is based on whether a specified event has been recorded rather than whether a specified stream is idle.</li>
<li><code>cudaStreamWaitEvent(event)</code> You can also synchronize operations within a single stream on a specific event using cudaStreamWaitEvent(event) (even if the event is recorded in a different stream, or on a different device!).</li>
</ul>
<h2 id="Overlapping-Kernel-Execution-and-Data-Transfers"><a href="#Overlapping-Kernel-Execution-and-Data-Transfers" class="headerlink" title="Overlapping Kernel Execution and Data Transfers"></a>Overlapping Kernel Execution and Data Transfers</h2><p>Earlier we demonstrated how to overlap kernel execution in the default stream with execution of code on the host. But our main goal in this post is to show you how to overlap kernel execution with data transfers. There are several requirements for this to happen. There are several requirements for this to happen.</p>
<ul>
<li>The device must be capable of <code>“concurrent copy and execution”</code>.  This can be queried from the deviceOverlap field of a <code>cudaDeviceProp</code> struct, or from the output of the deviceQuery sample included with the CUDA SDK/Toolkit. Nearly all devices with compute capability 1.1 and higher have this capability.</li>
<li>The kernel execution and the data transfer to be overlapped must both occur <strong>in different, non-default streams</strong>.</li>
<li>The host memory involved in the data transfer must be <strong>pinned</strong> memory.</li>
</ul>
<p>附录为实例程序，we break up the array of size <code>N</code> into chunks of <code>streamSize</code> elements. Since the kernel operates independently on all elements, each of the chunks can be processed independently. The number of (non-default) streams used is <code>nStreams=N/streamSize</code>. There are multiple ways to implement the domain decomposition of the data and processing; one is to loop over all the operations for each chunk of the array as in this example code.</p>
<p>原文内容作者Mark Harris<br>原文<a href="https://devblogs.nvidia.com/how-overlap-data-transfers-cuda-cc/" target="_blank" rel="noopener">链接</a><br>原文<a href="https://github.com/NVIDIA-developer-blog/code-samples/blob/master/series/cuda-cpp/overlap-data-transfers/async.cu" target="_blank" rel="noopener">程序</a></p>
<hr>
<p><span style="font-family:Papyrus; font-size:2em;">CUDA</span></p>
<p>附录<br>完整code：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Convenience function for checking CUDA runtime API results</span></span><br><span class="line"><span class="comment">// can be wrapped around any runtime API call. No-op in release builds.</span></span><br><span class="line"><span class="function"><span class="keyword">inline</span> cudaError_t <span class="title">checkCuda</span><span class="params">(cudaError_t result)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> defined(DEBUG) || defined(_DEBUG)</span></span><br><span class="line">  <span class="keyword">if</span> (result != cudaSuccess) &#123;</span><br><span class="line">    <span class="built_in">fprintf</span>(<span class="built_in">stderr</span>, <span class="string">"CUDA Runtime Error: %s\n"</span>, cudaGetErrorString(result));</span><br><span class="line">    assert(result == cudaSuccess);</span><br><span class="line">  &#125;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">  <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">__<span class="function">global__ <span class="keyword">void</span> <span class="title">kernel</span><span class="params">(<span class="keyword">float</span> *a, <span class="keyword">int</span> offset)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">int</span> i = offset + threadIdx.x + blockIdx.x*blockDim.x;</span><br><span class="line">  <span class="keyword">float</span> x = (<span class="keyword">float</span>)i;</span><br><span class="line">  <span class="keyword">float</span> s = sinf(x); </span><br><span class="line">  <span class="keyword">float</span> c = cosf(x);</span><br><span class="line">  a[i] = a[i] + sqrtf(s*s+c*c);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">float</span> <span class="title">maxError</span><span class="params">(<span class="keyword">float</span> *a, <span class="keyword">int</span> n)</span> </span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">float</span> maxE = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">    <span class="keyword">float</span> error = <span class="built_in">fabs</span>(a[i]<span class="number">-1.0f</span>);</span><br><span class="line">    <span class="keyword">if</span> (error &gt; maxE) maxE = error;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> maxE;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> **argv)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">int</span> blockSize = <span class="number">256</span>, nStreams = <span class="number">4</span>;</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">int</span> n = <span class="number">4</span> * <span class="number">1024</span> * blockSize * nStreams;</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">int</span> streamSize = n / nStreams;</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">int</span> streamBytes = streamSize * <span class="keyword">sizeof</span>(<span class="keyword">float</span>);</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">int</span> bytes = n * <span class="keyword">sizeof</span>(<span class="keyword">float</span>);</span><br><span class="line">   </span><br><span class="line">  <span class="keyword">int</span> devId = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">if</span> (argc &gt; <span class="number">1</span>) devId = atoi(argv[<span class="number">1</span>]);</span><br><span class="line"></span><br><span class="line">  cudaDeviceProp prop;</span><br><span class="line">  checkCuda( cudaGetDeviceProperties(&amp;prop, devId));</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">"Device : %s\n"</span>, prop.name);</span><br><span class="line">  checkCuda( cudaSetDevice(devId) );</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// allocate pinned host memory and device memory</span></span><br><span class="line">  <span class="keyword">float</span> *a, *d_a;</span><br><span class="line">  checkCuda( cudaMallocHost((<span class="keyword">void</span>**)&amp;a, bytes) );      <span class="comment">// host pinned</span></span><br><span class="line">  checkCuda( cudaMalloc((<span class="keyword">void</span>**)&amp;d_a, bytes) );    <span class="comment">// device</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">float</span> ms; <span class="comment">// elapsed time in milliseconds</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">// create events and streams</span></span><br><span class="line">  cudaEvent_t startEvent, stopEvent, dummyEvent;</span><br><span class="line">  cudaStream_t stream[nStreams];</span><br><span class="line">  checkCuda( cudaEventCreate(&amp;startEvent) );</span><br><span class="line">  checkCuda( cudaEventCreate(&amp;stopEvent) );</span><br><span class="line">  checkCuda( cudaEventCreate(&amp;dummyEvent) );</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; nStreams; ++i)</span><br><span class="line">    checkCuda( cudaStreamCreate(&amp;stream[i]) );</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// baseline case - sequential transfer and execute</span></span><br><span class="line">  <span class="built_in">memset</span>(a, <span class="number">0</span>, bytes);</span><br><span class="line">  checkCuda( cudaEventRecord(startEvent,<span class="number">0</span>) );</span><br><span class="line">  checkCuda( cudaMemcpy(d_a, a, bytes, cudaMemcpyHostToDevice) );</span><br><span class="line">  kernel&lt;&lt;&lt;n/blockSize, blockSize&gt;&gt;&gt;(d_a, <span class="number">0</span>);</span><br><span class="line">  checkCuda( cudaMemcpy(a, d_a, bytes, cudaMemcpyDeviceToHost) );</span><br><span class="line">  checkCuda( cudaEventRecord(stopEvent, <span class="number">0</span>) );</span><br><span class="line">  checkCuda( cudaEventSynchronize(stopEvent) );</span><br><span class="line">  checkCuda( cudaEventElapsedTime(&amp;ms, startEvent, stopEvent) );</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">"Time for sequential transfer and execute (ms): %f\n"</span>, ms);</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">"  max error: %e\n"</span>, maxError(a, n));</span><br><span class="line"></span><br><span class="line">  <span class="comment">// asynchronous version 1: loop over &#123;copy, kernel, copy&#125;</span></span><br><span class="line">  <span class="built_in">memset</span>(a, <span class="number">0</span>, bytes);</span><br><span class="line">  checkCuda( cudaEventRecord(startEvent,<span class="number">0</span>) );</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; nStreams; ++i) &#123;</span><br><span class="line">    <span class="keyword">int</span> offset = i * streamSize;</span><br><span class="line">    checkCuda( cudaMemcpyAsync(&amp;d_a[offset], &amp;a[offset], </span><br><span class="line">                               streamBytes, cudaMemcpyHostToDevice, </span><br><span class="line">                               stream[i]) );</span><br><span class="line">    kernel&lt;&lt;&lt;streamSize/blockSize, blockSize, <span class="number">0</span>, stream[i]&gt;&gt;&gt;(d_a, offset);</span><br><span class="line">    checkCuda( cudaMemcpyAsync(&amp;a[offset], &amp;d_a[offset], </span><br><span class="line">                               streamBytes, cudaMemcpyDeviceToHost,</span><br><span class="line">                               stream[i]) );</span><br><span class="line">  &#125;</span><br><span class="line">  checkCuda( cudaEventRecord(stopEvent, <span class="number">0</span>) );</span><br><span class="line">  checkCuda( cudaEventSynchronize(stopEvent) );</span><br><span class="line">  checkCuda( cudaEventElapsedTime(&amp;ms, startEvent, stopEvent) );</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">"Time for asynchronous V1 transfer and execute (ms): %f\n"</span>, ms);</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">"  max error: %e\n"</span>, maxError(a, n));</span><br><span class="line"></span><br><span class="line">  <span class="comment">// asynchronous version 2: </span></span><br><span class="line">  <span class="comment">// loop over copy, loop over kernel, loop over copy</span></span><br><span class="line">  <span class="built_in">memset</span>(a, <span class="number">0</span>, bytes);</span><br><span class="line">  checkCuda( cudaEventRecord(startEvent,<span class="number">0</span>) );</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; nStreams; ++i)</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">int</span> offset = i * streamSize;</span><br><span class="line">    checkCuda( cudaMemcpyAsync(&amp;d_a[offset], &amp;a[offset], </span><br><span class="line">                               streamBytes, cudaMemcpyHostToDevice,</span><br><span class="line">                               stream[i]) );</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; nStreams; ++i)</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">int</span> offset = i * streamSize;</span><br><span class="line">    kernel&lt;&lt;&lt;streamSize/blockSize, blockSize, <span class="number">0</span>, stream[i]&gt;&gt;&gt;(d_a, offset);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; nStreams; ++i)</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">int</span> offset = i * streamSize;</span><br><span class="line">    checkCuda( cudaMemcpyAsync(&amp;a[offset], &amp;d_a[offset], </span><br><span class="line">                               streamBytes, cudaMemcpyDeviceToHost,</span><br><span class="line">                               stream[i]) );</span><br><span class="line">  &#125;</span><br><span class="line">  checkCuda( cudaEventRecord(stopEvent, <span class="number">0</span>) );</span><br><span class="line">  checkCuda( cudaEventSynchronize(stopEvent) );</span><br><span class="line">  checkCuda( cudaEventElapsedTime(&amp;ms, startEvent, stopEvent) );</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">"Time for asynchronous V2 transfer and execute (ms): %f\n"</span>, ms);</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">"  max error: %e\n"</span>, maxError(a, n));</span><br><span class="line"></span><br><span class="line">  <span class="comment">// cleanup</span></span><br><span class="line">  checkCuda( cudaEventDestroy(startEvent) );</span><br><span class="line">  checkCuda( cudaEventDestroy(stopEvent) );</span><br><span class="line">  checkCuda( cudaEventDestroy(dummyEvent) );</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; nStreams; ++i)</span><br><span class="line">    checkCuda( cudaStreamDestroy(stream[i]) );</span><br><span class="line">  cudaFree(d_a);</span><br><span class="line">  cudaFreeHost(a);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/11/28/CUDA-overlap-data-transfer/" data-id="ck5bbuogs001xa2fz24us9cl2" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/CUDA/" rel="tag">CUDA</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2019/11/28/CUDA-optimize-data-transfer/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          CUDA-optimize data transfer
        
      </div>
    </a>
  
  
    <a href="/2019/11/27/CUDA-Performance-Metrics/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">CUDA-Performance Metrics</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/C/">C++</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/CUDA/">CUDA</a><span class="category-list-count">18</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/LeetCode/">LeetCode</a><span class="category-list-count">10</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linear-Algebra/">Linear Algebra</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Utility/">Utility</a><span class="category-list-count">7</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Algorithms/" rel="tag">Algorithms</a><span class="tag-list-count">10</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CUDA/" rel="tag">CUDA</a><span class="tag-list-count">17</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Algorithms/" style="font-size: 10px;">Algorithms</a> <a href="/tags/CUDA/" style="font-size: 20px;">CUDA</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">January 2020</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">December 2019</a><span class="archive-list-count">10</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">November 2019</a><span class="archive-list-count">6</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/10/">October 2019</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/08/">August 2019</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/07/">July 2019</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/1970/01/">January 1970</a><span class="archive-list-count">1</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2020/01/14/CUDA-APOD-Strong-Scaling-Weak-Scaling/">CUDA-APOD Strong-Scaling Weak-Scaling</a>
          </li>
        
          <li>
            <a href="/2020/01/13/Trouble-Shooting/">Trouble-Shooting</a>
          </li>
        
          <li>
            <a href="/2020/01/03/Linear-Algebra-%E7%9C%8B%E5%BE%85%E7%9F%A9%E9%98%B5%E7%9A%84%E8%A7%86%E8%A7%92/">Linear Algebra-看待矩阵的视角</a>
          </li>
        
          <li>
            <a href="/2020/01/01/%E6%B1%87%E6%80%BBShortCuts/">汇总ShortCuts</a>
          </li>
        
          <li>
            <a href="/2019/12/31/Linux%E5%AE%89%E8%A3%85cuDNN/">Linux安装cuDNN</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2020 Junhui<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div>
</body>
</html>