<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>caffe-使用已有的lenet模型 | Junhui&#39;s Journal</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="关于如何使用，在网上找了半天，没有一篇博客说清楚。之后才发现，下载好的caffe的examples目录中就是我想找的。通过examples，caffe的工作流程基本明了。一般由4步：  数据准备： 将原始数据转化为caffe-format 定义网络结构和参数， 定义训练超参数solver， 训练  给个例子mnist 1.数据准备回到caffe的根目录后执行下面脚本： 12$.&#x2F;data">
<meta property="og:type" content="article">
<meta property="og:title" content="caffe-使用已有的lenet模型">
<meta property="og:url" content="http://yoursite.com/2020/03/07/caffe-%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8/index.html">
<meta property="og:site_name" content="Junhui&#39;s Journal">
<meta property="og:description" content="关于如何使用，在网上找了半天，没有一篇博客说清楚。之后才发现，下载好的caffe的examples目录中就是我想找的。通过examples，caffe的工作流程基本明了。一般由4步：  数据准备： 将原始数据转化为caffe-format 定义网络结构和参数， 定义训练超参数solver， 训练  给个例子mnist 1.数据准备回到caffe的根目录后执行下面脚本： 12$.&#x2F;data">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2020-03-07T15:06:20.000Z">
<meta property="article:modified_time" content="2020-06-09T15:50:57.582Z">
<meta property="article:author" content="Junhui">
<meta property="article:tag" content="Caffe">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Junhui&#39;s Journal" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 4.2.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Junhui&#39;s Journal</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-caffe-如何使用" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/03/07/caffe-%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8/" class="article-date">
  <time datetime="2020-03-07T15:06:20.000Z" itemprop="datePublished">2020-03-07</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Caffe/">Caffe</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      caffe-使用已有的lenet模型
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>关于如何使用，在网上找了半天，没有一篇博客说清楚。之后才发现，下载好的caffe的examples目录中就是我想找的。通过examples，caffe的工作流程基本明了。一般由4步：</p>
<ol>
<li>数据准备： 将原始数据转化为caffe-format</li>
<li>定义网络结构和参数，</li>
<li>定义训练超参数solver，</li>
<li>训练</li>
</ol>
<p>给个例子mnist</p>
<h1 id="1-数据准备"><a href="#1-数据准备" class="headerlink" title="1.数据准备"></a>1.数据准备</h1><p>回到caffe的根目录后执行下面脚本：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$.&#x2F;data&#x2F;mnist&#x2F;get_mnist.sh</span><br><span class="line">$.&#x2F;examples&#x2F;mnist&#x2F;create_mnist.sh</span><br></pre></td></tr></table></figure>

<p>上述代码所做的事情是：先下载解压mnist数据集，后将源数据通过<code>build/examples/mnist/convert_mnist_data.bin</code>写入将原始mnist数据写成<code>LMDB</code>格式，所以会有两个文件生成：<code>mnist_train_lmdb</code>和<code>mnist_test_lmdb</code>。</p>
<h1 id="2-定义模型结构和参数"><a href="#2-定义模型结构和参数" class="headerlink" title="2.定义模型结构和参数"></a>2.定义模型结构和参数</h1><p>我使用caffe为我们定义好的<code>LeNet</code>网络，它的定义在文件<code>examples/mnist/lenet_train_test.prototxt</code>中。定义的格式是Google Protobuff，解析<code>.prorotxt</code>文件的　统一规则由文件<code>/src/caffe/proto/caffe.proto.</code>提供。</p>
<p>打开文件<code>lenet_train_test.prototxt</code>，是lenet的网络结构：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">name: &quot;LeNet&quot;</span><br><span class="line">layer &#123;</span><br><span class="line">&#x2F;&#x2F; ...layer definition...</span><br><span class="line">include: &#123; phase: TRAIN &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>若干层（Layer）堆叠在一起，构成了一个网络（Net）。lenet网络每层定义的细节间附录。</li>
<li>这个文件被称作<code>network definition protobuf file</code>。其中<code>top</code>表示这层输出，<code>bottom</code>表示这层出入。caffe中模型的逻辑图结构与其<code>.prototxt</code>文件的对应。</li>
<li>网络结构可以通过可视化工具绘制（详见后）。</li>
</ul>
<h1 id="3-指明训练超参数：solver-prototxt"><a href="#3-指明训练超参数：solver-prototxt" class="headerlink" title="3.指明训练超参数：solver.prototxt"></a>3.指明训练超参数：solver.prototxt</h1><p>从这里查看训练超参数<code>examples/mnist/lenet_solver.prototxt</code>。在caffe中，设定训练超参数（非训练参数）被称作<code>solver</code>，这个文件被称作<code>solver protobuf file</code>，也是Google protobuff 文件格式。如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 网络结构定义</span></span><br><span class="line">net: <span class="string">"examples/mnist/lenet_train_test.prototxt"</span></span><br><span class="line"><span class="comment"># Test阶段的迭代次数。batch_size也是100，所以由10,000测试数据</span></span><br><span class="line">test_iter: 100</span><br><span class="line"><span class="comment"># 每500次训练后执行1次测试</span></span><br><span class="line">test_interval: 500</span><br><span class="line"><span class="comment"># The base learning rate, momentum and the weight decay of the network.</span></span><br><span class="line">base_lr: 0.01</span><br><span class="line">momentum: 0.9</span><br><span class="line">weight_decay: 0.0005</span><br><span class="line"><span class="comment"># 设定学习率的策略</span></span><br><span class="line">lr_policy: <span class="string">"inv"</span></span><br><span class="line">gamma: 0.0001</span><br><span class="line">power: 0.75</span><br><span class="line"><span class="comment"># 每100次迭代后，打印</span></span><br><span class="line">display: 100</span><br><span class="line"><span class="comment"># 最大迭代次数</span></span><br><span class="line">max_iter: 10000</span><br><span class="line"><span class="comment"># 每5000次记录一次快照，中间结果</span></span><br><span class="line">snapshot: 5000</span><br><span class="line">snapshot_prefix: <span class="string">"examples/mnist/lenet"</span></span><br><span class="line"><span class="comment"># 用什么计算</span></span><br><span class="line">solver_mode: GPU</span><br></pre></td></tr></table></figure>
<p><font color="red">这个文件在程序中按照<code>caffe.proto</code>的协议解析到一个<code>Caffe::SolverParameter</code>对象中，进而将解析后的参数使用到网络中。用于解析的文件是<code>caffe.pb.h</code>和<code>caffe.pb.cc</code>，其位于<code>build/src/caffe/proto/</code></font>。</p>
<p>默认使用GPU。可以使用同目录的其他的参数配置文件（不同的模型）：</p>
<p><code>lenet_multistep_solver.prototxt</code><br><code>lenet_solver_adam.prototxt</code><br><code>lenet_solver_rmsprop.prototxt</code></p>
<h1 id="4-训练与测试"><a href="#4-训练与测试" class="headerlink" title="4.训练与测试"></a>4.训练与测试</h1><p>有了caffe-format的数据；有了网络结构；有了确定的超参数，就可以执行下面脚本开始训练：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.&#x2F;examples&#x2F;mnist&#x2F;train_lenet.sh</span><br></pre></td></tr></table></figure>

<p><code>train_lenet.sh</code>文件包含一行代码：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env sh</span></span><br><span class="line"><span class="built_in">set</span> -e</span><br><span class="line"> </span><br><span class="line">./build/tools/caffe train --solver=examples/mnist/lenet_solver.prototxt <span class="variable">$@</span></span><br></pre></td></tr></table></figure>

<p>使用<code>caffe</code>命令（这个<code>caffe</code>是tools中的命令，这是caffe提供的命令行接口：<code>cmdcaffe</code>）， 指明是<code>trian</code>，指明训练超参数配置，即使用哪个<code>*solver.prototxt</code>文件。(而网络结构超参数的地址，在<code>*solver.prototxt</code>中指明)</p>
<p>执行包括两部分：</p>
<ul>
<li><p>输出模型结构</p>
<p>  包括每一层输入的大小，方便debug。</p>
</li>
<li><p>训练过程</p>
</li>
</ul>
<p>训练结束后，在<code>examples/mnist/</code>路径下生成两个文件<code>lenet_iter_10000.caffemodel</code>和<code>lenet_iter_10000.solverstate</code>。</p>
<ol>
<li><code>.caffemodel</code>文件是最终模型，二进制文件。</li>
<li><code>.solverstate</code>是保存的训练状态（snapshot），可以从此继续开始训练。</li>
</ol>
<h1 id="训练结束"><a href="#训练结束" class="headerlink" title="训练结束"></a>训练结束</h1><p><code>lenet_iter_10000</code>是binary protobuf 文件，就是训练10000次的最终模型，用于对真实样本的推理。</p>
<p>MNIST数据集是小数据集，所以使用GPU的效果并不好，原因是GPU的计算核心与存储的通讯开销。所以对于复杂模型和数据集GPU的速度提升是显著的。</p>
<h1 id="使用预训练的model"><a href="#使用预训练的model" class="headerlink" title="使用预训练的model"></a>使用预训练的model</h1><p>训练结束后生成的<code>.caffemodel</code>是可以直接拿来使用的模型（其实就是所有训练好的参数），用作推理。如何使用？</p>
<p>如果要使用预训练的模型，从这里下载预训练的模型<a href="http://dl.caffe.berkeleyvision.org/" target="_blank" rel="noopener">caffe model index</a>，如<code>bvlc_reference_caffenet.caffemodel</code>， 并且将其放到<code>caffe-root/models/bvlc_reference_caffenet/</code>中。</p>
<p>使用预训练模型：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 指明 -weights 关键字，提供预训练模型</span></span><br><span class="line">./build/tools/caffe \</span><br><span class="line">train \</span><br><span class="line">--solver examples/finetuning_on_flickr_style/solver.prototxt \</span><br><span class="line">--weights models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel</span><br></pre></td></tr></table></figure>

<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>生成制定格式数据{数据&amp;模型之数据}：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$.&#x2F;data&#x2F;mnist&#x2F;get_mnist.sh</span><br><span class="line">$.&#x2F;examples&#x2F;mnist&#x2F;create_mnist.sh</span><br></pre></td></tr></table></figure>

<p>在GPU上训练{数据&amp;模型之模型}：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">./build/tools/caffe train \</span><br><span class="line">--solver=examples/mnist/lenet_solver.prototxt -gpu 0</span><br></pre></td></tr></table></figure>
<p>关键字为<code>train</code>，需要提供<code>*solver.prototxt</code>文件，和网络结构文件，后者的路径在<code>*solver.prototxt</code>文件中指明。有了结构参数和超参数，就可以进行学习。</p>
<p>从5000次接着训练：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">./build/tools/caffe train \</span><br><span class="line">-solver examples/mnist/lenet_solver.prototxt \</span><br><span class="line">-snapshot examples/mnist/lenet_iter_5000.solverstate</span><br></pre></td></tr></table></figure>

<p>处理训练所需还要提供快照文件<code>.solverstate</code>。</p>
<h1 id="附录-lenet模型定义"><a href="#附录-lenet模型定义" class="headerlink" title="附录 lenet模型定义"></a>附录 lenet模型定义</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br></pre></td><td class="code"><pre><span class="line">name: <span class="string">"LeNet"</span></span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"mnist"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"Data"</span></span><br><span class="line">  top: <span class="string">"data"</span></span><br><span class="line">  top: <span class="string">"label"</span></span><br><span class="line">  include &#123;</span><br><span class="line">    phase: TRAIN  <span class="comment"># 本层只用于训练过程中</span></span><br><span class="line">  &#125;</span><br><span class="line">  transform_param &#123;  <span class="comment"># 数据变换使用的方所因子</span></span><br><span class="line">    scale: 0.00390625</span><br><span class="line">  &#125;</span><br><span class="line">  data_param &#123;     <span class="comment"># 数据层参数，包括二进制数据的路径</span></span><br><span class="line">    <span class="built_in">source</span>: <span class="string">"examples/mnist/mnist_train_lmdb"</span></span><br><span class="line">    batch_size: 64</span><br><span class="line">    backend: LMDB</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"mnist"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"Data"</span></span><br><span class="line">  top: <span class="string">"data"</span></span><br><span class="line">  top: <span class="string">"label"</span></span><br><span class="line">  include &#123;</span><br><span class="line">    phase: TEST   <span class="comment"># 同样的数据层，只用于测试阶段</span></span><br><span class="line">  &#125;</span><br><span class="line">  transform_param &#123;</span><br><span class="line">    scale: 0.00390625</span><br><span class="line">  &#125;</span><br><span class="line">  data_param &#123;</span><br><span class="line">    <span class="built_in">source</span>: <span class="string">"examples/mnist/mnist_test_lmdb"</span></span><br><span class="line">    batch_size: 100</span><br><span class="line">    backend: LMDB</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"conv1"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"Convolution"</span></span><br><span class="line">  bottom: <span class="string">"data"</span></span><br><span class="line">  top: <span class="string">"conv1"</span></span><br><span class="line">  param &#123;</span><br><span class="line">    lr_mult: 1  <span class="comment"># 权值学习速率因子，1表示保持与全局参数一致</span></span><br><span class="line">  &#125;</span><br><span class="line">  param &#123;</span><br><span class="line">    lr_mult: 2  <span class="comment"># bias学习因子，2表示是全局的2倍</span></span><br><span class="line">  &#125;</span><br><span class="line">  convolution_param &#123;  <span class="comment"># 卷基层参数</span></span><br><span class="line">    num_output: 20</span><br><span class="line">    kernel_size: 5</span><br><span class="line">    stride: 1</span><br><span class="line">    weight_filler &#123;</span><br><span class="line">      <span class="built_in">type</span>: <span class="string">"xavier"</span>  <span class="comment"># 权值使用xavier方法初始化？</span></span><br><span class="line">    &#125;</span><br><span class="line">    bias_filler &#123;</span><br><span class="line">      <span class="built_in">type</span>: <span class="string">"constant"</span>  <span class="comment"># bias初始化为常量？</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"pool1"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"Pooling"</span></span><br><span class="line">  bottom: <span class="string">"conv1"</span></span><br><span class="line">  top: <span class="string">"pool1"</span></span><br><span class="line">  pooling_param &#123;</span><br><span class="line">    pool: MAX</span><br><span class="line">    kernel_size: 2</span><br><span class="line">    stride: 2</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"conv2"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"Convolution"</span></span><br><span class="line">  bottom: <span class="string">"pool1"</span></span><br><span class="line">  top: <span class="string">"conv2"</span></span><br><span class="line">  param &#123;</span><br><span class="line">    lr_mult: 1</span><br><span class="line">  &#125;</span><br><span class="line">  param &#123;</span><br><span class="line">    lr_mult: 2</span><br><span class="line">  &#125;</span><br><span class="line">  convolution_param &#123;</span><br><span class="line">    num_output: 50</span><br><span class="line">    kernel_size: 5</span><br><span class="line">    stride: 1</span><br><span class="line">    weight_filler &#123;</span><br><span class="line">      <span class="built_in">type</span>: <span class="string">"xavier"</span></span><br><span class="line">    &#125;</span><br><span class="line">    bias_filler &#123;</span><br><span class="line">      <span class="built_in">type</span>: <span class="string">"constant"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"pool2"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"Pooling"</span></span><br><span class="line">  bottom: <span class="string">"conv2"</span></span><br><span class="line">  top: <span class="string">"pool2"</span></span><br><span class="line">  pooling_param &#123;</span><br><span class="line">    pool: MAX</span><br><span class="line">    kernel_size: 2</span><br><span class="line">    stride: 2</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"ip1"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"InnerProduct"</span></span><br><span class="line">  bottom: <span class="string">"pool2"</span></span><br><span class="line">  top: <span class="string">"ip1"</span></span><br><span class="line">  param &#123;</span><br><span class="line">    lr_mult: 1</span><br><span class="line">  &#125;</span><br><span class="line">  param &#123;</span><br><span class="line">    lr_mult: 2</span><br><span class="line">  &#125;</span><br><span class="line">  inner_product_param &#123; <span class="comment"># 全连接层InnerProduct</span></span><br><span class="line">    num_output: 500   </span><br><span class="line">    weight_filler &#123;</span><br><span class="line">      <span class="built_in">type</span>: <span class="string">"xavier"</span></span><br><span class="line">    &#125;</span><br><span class="line">    bias_filler &#123;</span><br><span class="line">      <span class="built_in">type</span>: <span class="string">"constant"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;   <span class="comment"># 非现行变换层</span></span><br><span class="line">  name: <span class="string">"relu1"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"ReLU"</span></span><br><span class="line">  bottom: <span class="string">"ip1"</span></span><br><span class="line">  top: <span class="string">"ip1"</span></span><br><span class="line">&#125;</span><br><span class="line">layer &#123;  </span><br><span class="line">  name: <span class="string">"ip2"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"InnerProduct"</span></span><br><span class="line">  bottom: <span class="string">"ip1"</span></span><br><span class="line">  top: <span class="string">"ip2"</span></span><br><span class="line">  param &#123;</span><br><span class="line">    lr_mult: 1</span><br><span class="line">  &#125;</span><br><span class="line">  param &#123;</span><br><span class="line">    lr_mult: 2</span><br><span class="line">  &#125;</span><br><span class="line">  inner_product_param &#123;</span><br><span class="line">    num_output: 10</span><br><span class="line">    weight_filler &#123;</span><br><span class="line">      <span class="built_in">type</span>: <span class="string">"xavier"</span></span><br><span class="line">    &#125;</span><br><span class="line">    bias_filler &#123;</span><br><span class="line">      <span class="built_in">type</span>: <span class="string">"constant"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"accuracy"</span>   <span class="comment"># 计算accuracy 只用于Test阶段</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"Accuracy"</span></span><br><span class="line">  bottom: <span class="string">"ip2"</span></span><br><span class="line">  bottom: <span class="string">"label"</span></span><br><span class="line">  top: <span class="string">"accuracy"</span></span><br><span class="line">  include &#123;</span><br><span class="line">    phase: TEST</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"loss"</span>   <span class="comment"># loss层</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"SoftmaxWithLoss"</span></span><br><span class="line">  bottom: <span class="string">"ip2"</span></span><br><span class="line">  bottom: <span class="string">"label"</span></span><br><span class="line">  top: <span class="string">"loss"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/03/07/caffe-%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8/" data-id="ckatsrgsk0046xqfzdag77562" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Caffe/" rel="tag">Caffe</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2020/03/09/Cpp-pro-tip-2/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Cpp pro tip 尽可能使用const
        
      </div>
    </a>
  
  
    <a href="/2020/03/07/Caffe-%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8-2/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Caffe-Blob Layer Net</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/C/">C++</a><span class="category-list-count">12</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/CUDA/">CUDA</a><span class="category-list-count">35</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Caffe/">Caffe</a><span class="category-list-count">15</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Deep-Learning/">Deep Learning</a><span class="category-list-count">11</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/LeetCode/">LeetCode</a><span class="category-list-count">16</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linear-Algebra/">Linear Algebra</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Machine-Learning/">Machine Learning</a><span class="category-list-count">15</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Reinforcement-Learning/">Reinforcement Learning</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Utility/">Utility</a><span class="category-list-count">12</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%BE%85%E5%BD%92%E7%B1%BB/">待归类</a><span class="category-list-count">2</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Algorithms/" rel="tag">Algorithms</a><span class="tag-list-count">43</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CUDA/" rel="tag">CUDA</a><span class="tag-list-count">31</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Caffe/" rel="tag">Caffe</a><span class="tag-list-count">15</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Test-Analysis/" rel="tag">Test Analysis</a><span class="tag-list-count">6</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Algorithms/" style="font-size: 20px;">Algorithms</a> <a href="/tags/CUDA/" style="font-size: 16.67px;">CUDA</a> <a href="/tags/Caffe/" style="font-size: 13.33px;">Caffe</a> <a href="/tags/Test-Analysis/" style="font-size: 10px;">Test Analysis</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/06/">June 2020</a><span class="archive-list-count">18</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/03/">March 2020</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/02/">February 2020</a><span class="archive-list-count">15</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">January 2020</a><span class="archive-list-count">12</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">December 2019</a><span class="archive-list-count">10</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">November 2019</a><span class="archive-list-count">6</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/10/">October 2019</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/09/">September 2019</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/08/">August 2019</a><span class="archive-list-count">38</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/07/">July 2019</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/1970/01/">January 1970</a><span class="archive-list-count">1</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2020/06/10/caffe-%E6%95%B0%E6%8D%AE-%E6%A8%A1%E5%9E%8B-%E6%A8%A1%E5%9E%8B%E8%BE%93%E5%87%BAlog/">caffe-数据&amp;模型-模型输出log</a>
          </li>
        
          <li>
            <a href="/2020/06/09/caffe-%E6%95%B0%E6%8D%AE-%E6%A8%A1%E5%9E%8B-%E6%A8%A1%E5%9E%8B/">caffe-数据&amp;模型-模型</a>
          </li>
        
          <li>
            <a href="/2020/06/08/caffe-Net-hpp/">caffe-Net.hpp</a>
          </li>
        
          <li>
            <a href="/2020/06/08/cpp-void%E5%9E%8B%E6%8C%87%E9%92%88/">cpp-void型指针</a>
          </li>
        
          <li>
            <a href="/2020/06/07/caffe-Layer%E4%B8%AD%E6%9C%89%E4%BB%80%E4%B9%88/">caffe-Layer中有什么</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2020 Junhui<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div>
</body>
</html>