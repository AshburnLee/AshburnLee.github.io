<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>caffe-数据&amp;模型-模型 | Junhui&#39;s Journal</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="模型三部分参数模型是caffe学习系统包含数据与模型两个核心组件之一。一个caffe模型含有三部分参数：  要学习的参数：  即权值，通过 初始化和反向传播得到更新。随着训练的结束，要学习的参数就此确定，也意味着确定了一个具体的模型。这个模型或者说是最终的学习参数会保存在.caffemodel文件中。我们可以直接使用这个模型，或者是在这个模型的基础上继续学习。  网络结构超参数：  就是Net的蓝">
<meta property="og:type" content="article">
<meta property="og:title" content="caffe-数据&amp;模型-模型">
<meta property="og:url" content="http://yoursite.com/2020/06/09/caffe-%E6%95%B0%E6%8D%AE-%E6%A8%A1%E5%9E%8B-%E6%A8%A1%E5%9E%8B/index.html">
<meta property="og:site_name" content="Junhui&#39;s Journal">
<meta property="og:description" content="模型三部分参数模型是caffe学习系统包含数据与模型两个核心组件之一。一个caffe模型含有三部分参数：  要学习的参数：  即权值，通过 初始化和反向传播得到更新。随着训练的结束，要学习的参数就此确定，也意味着确定了一个具体的模型。这个模型或者说是最终的学习参数会保存在.caffemodel文件中。我们可以直接使用这个模型，或者是在这个模型的基础上继续学习。  网络结构超参数：  就是Net的蓝">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2020-06-09T09:30:40.000Z">
<meta property="article:modified_time" content="2020-06-16T12:43:43.719Z">
<meta property="article:author" content="Junhui">
<meta property="article:tag" content="Caffe">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Junhui&#39;s Journal" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 4.2.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Junhui&#39;s Journal</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-caffe-数据-模型-模型" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/06/09/caffe-%E6%95%B0%E6%8D%AE-%E6%A8%A1%E5%9E%8B-%E6%A8%A1%E5%9E%8B/" class="article-date">
  <time datetime="2020-06-09T09:30:40.000Z" itemprop="datePublished">2020-06-09</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Caffe/">Caffe</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      caffe-数据&amp;模型-模型
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="模型三部分参数"><a href="#模型三部分参数" class="headerlink" title="模型三部分参数"></a>模型三部分参数</h1><p>模型是caffe学习系统包含数据与模型两个核心组件之一。一个caffe模型含有三部分参数：</p>
<ul>
<li>要学习的参数：</li>
</ul>
<p>即权值，通过 初始化和反向传播得到更新。随着训练的结束，要学习的参数就此确定，也意味着确定了一个具体的模型。这个模型或者说是最终的学习参数会保存在<code>.caffemodel</code>文件中。我们可以直接使用这个模型，或者是在这个模型的基础上继续学习。</p>
<ul>
<li>网络结构超参数：</li>
</ul>
<p>就是Net的蓝图，即如何构建一个具体的Net，是一种构建策略。比如当前卷积层的kernel数量，kernel大小，步长等参数，显然，结构参数是在训练网络前就确定了的。注意：同一个Net的训练结构和测试结构可能不同。结构参数由Net的蓝图文件<code>.prototxt</code>提供，读取这个文件，得到Net的结构细节，从而指导caffe构建制定Net。</p>
<ul>
<li>训练超参数：</li>
</ul>
<p>控用于制训练过程的参数，如learning rate，迭代次数，CPU或GPU训练，等。其描述存在于一个<code>.prototxt</code>文件，一般使用<code>solver.prototxt</code>这个文件名。</p>
<h1 id="例"><a href="#例" class="headerlink" title="例"></a>例</h1><p>先准备数据。在将原始数据（raw data）转换为LMDB格式之后，就可以由数据层（DataLayer）不断从LMDB（磁盘上）读取数据进入网络。</p>
<p><font color="red">为了对caffe的pipline有个清晰的理解</font>，在工作目录创建文件夹<code>my_linearReggresion</code> 存放关于这个网络的所有内容，将之前创建好的LMDB数据文件放入 <code>my_linearReggresion</code>。之后创建网络结构文件 <code>mylr.prototxt</code> 和训练超参数文件 <code>lr_solver.prototxt</code>。</p>
<p>此时的<code>my_linearReggresion</code>目录tree如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── lr_solver.prototxt</span><br><span class="line">├── mnist_test_lmdb</span><br><span class="line">│   ├── data.mdb</span><br><span class="line">│   └── lock.mdb</span><br><span class="line">├── mnist_train_lmdb</span><br><span class="line">│   ├── data.mdb</span><br><span class="line">│   └── lock.mdb</span><br><span class="line">└── mylr.prototxt</span><br></pre></td></tr></table></figure>

<p>上述是以一个简单的logistic reggresion为例。其网络结构如下图（<font color="red">包含训练和测试两个结构，两者共同的层只需定义一遍，不同阶段的要分别定义</font>）：<br>[插图结构图]<br>参照结构图，定义网络结构超参数文件和训练超参数文件。</p>
<h1 id="编辑mylr-prototxt"><a href="#编辑mylr-prototxt" class="headerlink" title="编辑mylr.prototxt"></a>编辑<code>mylr.prototxt</code></h1><p>先编辑网络结构超参数文件，就是编辑<code>mylr.prototxt</code>文件。如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line">name: <span class="string">"lrNet"</span></span><br><span class="line"><span class="comment"># 数据层，用于train</span></span><br><span class="line">layer&#123;</span><br><span class="line">    name: <span class="string">"mnist"</span></span><br><span class="line">    <span class="built_in">type</span>: <span class="string">"Data"</span></span><br><span class="line">    top: <span class="string">"data"</span></span><br><span class="line">    top: <span class="string">"label"</span></span><br><span class="line">    include &#123;</span><br><span class="line">        phase: TRAIN</span><br><span class="line">    &#125;</span><br><span class="line">    transform_param&#123;</span><br><span class="line">        scale: 0.0039063</span><br><span class="line">    &#125;</span><br><span class="line">    data_param&#123;</span><br><span class="line">        <span class="built_in">source</span>: <span class="string">"MNIST_LMDB_PATH/mnist_train_lmdb"</span></span><br><span class="line">        batch_size: 64</span><br><span class="line">        backend: lmdb</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># 数据层，用于test</span></span><br><span class="line">layer&#123;</span><br><span class="line">    name: <span class="string">"mnist"</span></span><br><span class="line">    <span class="built_in">type</span>: <span class="string">"Data"</span>  <span class="comment"># 从哪里定义的“Data”</span></span><br><span class="line">    top: <span class="string">"data"</span></span><br><span class="line">    top: <span class="string">"label"</span></span><br><span class="line">    include &#123;</span><br><span class="line">        phase: TEST</span><br><span class="line">    &#125;</span><br><span class="line">    transform_param&#123;  <span class="comment"># 从哪里定义</span></span><br><span class="line">        scale: 0.0039063</span><br><span class="line">    &#125;</span><br><span class="line">    data_param&#123;   <span class="comment"># 从哪里定义</span></span><br><span class="line">        <span class="built_in">source</span>: <span class="string">"MNIST_LMDB_PATH/mnist_test_lmdb"</span></span><br><span class="line">        batch_size: 100</span><br><span class="line">        backend: lmdb</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># 内积层</span></span><br><span class="line">layer&#123;</span><br><span class="line">    name: <span class="string">"ip"</span></span><br><span class="line">    <span class="built_in">type</span>: <span class="string">"InnerProduct"</span> <span class="comment"># 从哪里定义</span></span><br><span class="line">    bottom: <span class="string">"data"</span></span><br><span class="line">    top: <span class="string">"ip"</span></span><br><span class="line">    param&#123;   <span class="comment"># 从哪里定义</span></span><br><span class="line">        lr_mult: 1</span><br><span class="line">    &#125;</span><br><span class="line">    param&#123;</span><br><span class="line">        lr_mult: 2</span><br><span class="line">    &#125;</span><br><span class="line">    inner_product_param&#123;  <span class="comment"># 从哪里定义</span></span><br><span class="line">        num_output: 10</span><br><span class="line">        weight_filler&#123;</span><br><span class="line">            <span class="built_in">type</span>: <span class="string">"xavier"</span></span><br><span class="line">        &#125;</span><br><span class="line">        bias_filler&#123;</span><br><span class="line">            <span class="built_in">type</span>: <span class="string">"constant"</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># 在Test阶段使用</span></span><br><span class="line">layer&#123;</span><br><span class="line">    name: <span class="string">"accuracy"</span></span><br><span class="line">    <span class="built_in">type</span>: <span class="string">"Accuracy"</span></span><br><span class="line">    bottom: <span class="string">"ip"</span></span><br><span class="line">    bottom: <span class="string">"label"</span></span><br><span class="line">    top: <span class="string">"accuracy"</span></span><br><span class="line">    include &#123;</span><br><span class="line">        phase: TEST</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">layer&#123;</span><br><span class="line">    name: <span class="string">"loss"</span></span><br><span class="line">    <span class="built_in">type</span>: <span class="string">"SoftMaxWithLoss"</span></span><br><span class="line">    bottom: <span class="string">"ip"</span></span><br><span class="line">    bottom: <span class="string">"label"</span></span><br><span class="line">    top: <span class="string">"loss"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>其中<code>source</code>提供LMDB数据的路径，提供绝对路径不用担心出错。</p>
<h1 id="编辑lr-solver-prototxt"><a href="#编辑lr-solver-prototxt" class="headerlink" title="编辑lr_solver.prototxt"></a>编辑<code>lr_solver.prototxt</code></h1><p>按照上述蓝图构建用于训练的网络和用于测试的网络。之后编辑训练超参数文件<code>lr_solver.prototxt</code>：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 结构文件的路径，告诉caffe，构建蓝图在哪</span></span><br><span class="line">net: <span class="string">"PATH/lr.prototxt"</span></span><br><span class="line">test_iter: 100</span><br><span class="line"><span class="comment"># 每500次做一次测试</span></span><br><span class="line">test_interval: 500</span><br><span class="line">base_lr: 0.01</span><br><span class="line">momentum: 0.9</span><br><span class="line">weight_delay: 0.0005</span><br><span class="line">lr_policy: <span class="string">"inv"</span></span><br><span class="line">gamma: 0.0001</span><br><span class="line">power: 0.75</span><br><span class="line">max_iter: 10000</span><br><span class="line"><span class="comment"># 每迭代5000次拍个快照</span></span><br><span class="line">snapshot: 5000</span><br><span class="line">snapshot_prefix: <span class="string">"PATH/mnist/lrNet"</span></span><br><span class="line">solver_mode: GPU</span><br></pre></td></tr></table></figure>
<p>note: 想上添加<code>type</code>关键字，用来指定所使用的优化方法，如<code>type: &quot;Nesterov&quot;</code>，<code>type: &quot;AdaGrad&quot;</code>，<code>type: &quot;AdaDelta&quot;</code>等。默认使用<code>SGD</code>。<br>有了数据有了模型就可以训练了：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">CAFFE train \</span><br><span class="line">--solver=PATH/lr_solver.prototxt</span><br></pre></td></tr></table></figure>

<p>其中<code>CAFFE</code>，表示caffe_master提前编译好的caffe工具，就像在caffe_master中的命令<code>./build/tools/caffe</code>。</p>
<p>总结，要想正确运行，必须保证所配置的路径是有效的：</p>
<ul>
<li>用于执行指令的<code>build/tools/caffe</code>命令的路径，</li>
<li>训练超参数文件的路径<code>lr_solver.prototxt</code>，</li>
<li>LMDB数据路径，</li>
<li>模型结构超参数文件路径<code>mylr.prototxt</code>，</li>
</ul>
<h1 id="对于Layer的类型"><a href="#对于Layer的类型" class="headerlink" title="对于Layer的类型"></a>对于Layer的类型</h1><p>caffe现有的<code>Layer type</code>：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">known types: AbsVal, Accuracy, ArgMax, BNLL, BatchNorm, </span><br><span class="line">BatchReindex, Bias, Clip, Concat, ContrastiveLoss, Convolution, </span><br><span class="line">Crop, Data, Deconvolution, Dropout, DummyData, ELU, Eltwise, </span><br><span class="line">Embed, EuclideanLoss, Exp, Filter, Flatten, HDF5Data, </span><br><span class="line">HDF5Output, HingeLoss, Im2col, ImageData, InfogainLoss, </span><br><span class="line">InnerProduct, Input, LRN, LSTM, LSTMUnit, Log, MVN, MemoryData, </span><br><span class="line">MultinomialLogisticLoss, PReLU, Parameter, Pooling, Power, </span><br><span class="line">Python, RNN, ReLU, Reduction, Reshape, SPP, Scale, Sigmoid, </span><br><span class="line">SigmoidCrossEntropyLoss, Silence, Slice, Softmax, </span><br><span class="line">SoftmaxWithLoss, Split, Swish, TanH, Threshold, Tile, WindowData</span><br></pre></td></tr></table></figure>

<p>当训练并测试完毕，会有模型文件和快照文件保存于当前目录：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── lr_solver.prototxt</span><br><span class="line">├── mnist_test_lmdb</span><br><span class="line">│   ├── data.mdb</span><br><span class="line">│   └── lock.mdb</span><br><span class="line">├── mnist_train_lmdb</span><br><span class="line">│   ├── data.mdb</span><br><span class="line">│   └── lock.mdb</span><br><span class="line">├── my_lr_iter_10000.caffemodel</span><br><span class="line">├── my_lr_iter_10000.solverstate</span><br><span class="line">├── my_lr_iter_5000.caffemodel</span><br><span class="line">├── my_lr_iter_5000.solverstate</span><br><span class="line">└── mylr.prototxt</span><br></pre></td></tr></table></figure>

<p><font color="gree" size="5">问题</font>：<br>这些关键字是在哪了与Layer的实现对应起来的呢？<font color="red">当将自己实现的Layer或其他组件键入到caffe源码中时，就需要在某处添加对应关键字。</font></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/06/09/caffe-%E6%95%B0%E6%8D%AE-%E6%A8%A1%E5%9E%8B-%E6%A8%A1%E5%9E%8B/" data-id="ckb95zgvz0000c6fz37cz1r86" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Caffe/" rel="tag">Caffe</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2020/06/10/caffe-%E6%95%B0%E6%8D%AE-%E6%A8%A1%E5%9E%8B-%E6%A8%A1%E5%9E%8B%E8%BE%93%E5%87%BAlog/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          caffe-数据&amp;模型-模型输出log
        
      </div>
    </a>
  
  
    <a href="/2020/06/08/caffe-Net-hpp/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">caffe-Net.hpp</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/C/">C++</a><span class="category-list-count">13</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/CUDA/">CUDA</a><span class="category-list-count">36</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Caffe/">Caffe</a><span class="category-list-count">18</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Deep-Learning/">Deep Learning</a><span class="category-list-count">11</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/LeetCode/">LeetCode</a><span class="category-list-count">29</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linear-Algebra/">Linear Algebra</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Machine-Learning/">Machine Learning</a><span class="category-list-count">15</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Reinforcement-Learning/">Reinforcement Learning</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Utility/">Utility</a><span class="category-list-count">12</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%BE%85%E5%BD%92%E7%B1%BB/">待归类</a><span class="category-list-count">3</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Algorithms/" rel="tag">Algorithms</a><span class="tag-list-count">56</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CUDA/" rel="tag">CUDA</a><span class="tag-list-count">34</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Caffe/" rel="tag">Caffe</a><span class="tag-list-count">18</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Test-Analysis/" rel="tag">Test Analysis</a><span class="tag-list-count">6</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Algorithms/" style="font-size: 20px;">Algorithms</a> <a href="/tags/CUDA/" style="font-size: 16.67px;">CUDA</a> <a href="/tags/Caffe/" style="font-size: 13.33px;">Caffe</a> <a href="/tags/Test-Analysis/" style="font-size: 10px;">Test Analysis</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/07/">July 2020</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/06/">June 2020</a><span class="archive-list-count">31</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/03/">March 2020</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/02/">February 2020</a><span class="archive-list-count">15</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">January 2020</a><span class="archive-list-count">12</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">December 2019</a><span class="archive-list-count">10</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">November 2019</a><span class="archive-list-count">6</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/10/">October 2019</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/09/">September 2019</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/08/">August 2019</a><span class="archive-list-count">38</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/07/">July 2019</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/1970/01/">January 1970</a><span class="archive-list-count">1</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2020/07/12/LeetCode-Trie/">LeetCode-Trie</a>
          </li>
        
          <li>
            <a href="/2020/07/11/LeetCode-BST-%E6%89%BE%E5%89%8D%E9%A9%B1%E4%B8%8E%E5%90%8E%E7%BB%A7%E7%BB%93%E7%82%B9/">LeetCode-BST 找前驱与后继结点</a>
          </li>
        
          <li>
            <a href="/2020/07/08/CUDA-%E5%B9%B6%E8%A1%8CRadix-Sort/">CUDA-并行Radix Sort</a>
          </li>
        
          <li>
            <a href="/2020/07/02/LeetCode-%E5%88%A4%E6%96%AD%E9%93%BE%E8%A1%A8%E6%98%AF%E5%90%A6%E7%9B%B8%E4%BA%A4/">LeetCode-判断链表是否相交</a>
          </li>
        
          <li>
            <a href="/2020/07/01/cpp-%E9%9D%99%E6%80%81%E5%86%85%E5%AD%98-%E6%A0%88%E5%86%85%E5%AD%98-%E5%8A%A8%E6%80%81%E5%86%85%E5%AD%98/">cpp-静态内存-栈内存-动态内存</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2020 Junhui<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div>
</body>
</html>