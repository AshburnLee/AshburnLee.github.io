<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>Junhui&#39;s Journal</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Junhui&#39;s Journal">
<meta property="og:url" content="http://yoursite.com/page/4/index.html">
<meta property="og:site_name" content="Junhui&#39;s Journal">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Junhui">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Junhui&#39;s Journal" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 4.2.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Junhui&#39;s Journal</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-caffe-命令行与python接口" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/06/03/caffe-%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%8Epython%E6%8E%A5%E5%8F%A3/" class="article-date">
  <time datetime="2020-06-03T08:07:58.000Z" itemprop="datePublished">2020-06-03</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Caffe/">Caffe</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/06/03/caffe-%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%8Epython%E6%8E%A5%E5%8F%A3/">caffe 命令行与python接口</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="命令行接口-cmdcaffe"><a href="#命令行接口-cmdcaffe" class="headerlink" title="命令行接口 cmdcaffe"></a>命令行接口 cmdcaffe</h1><p>caffe经过编译后才会生成对应的工具，这个工具在目录<code>caffe-ROOT/build/tools</code>中，在此路目录中可用的命令有：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">./caffe train           <span class="comment">#train or finetune a model</span></span><br><span class="line">./caffe <span class="built_in">test</span>            <span class="comment">#score a model</span></span><br><span class="line">./caffe device_query    <span class="comment">#show GPU diagnostic information</span></span><br><span class="line">./caffe time            <span class="comment">#benchmark model execution time</span></span><br></pre></td></tr></table></figure>

<h2 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h2><h3 id="训练-1"><a href="#训练-1" class="headerlink" title="训练"></a>训练</h3><p>caffe提供三种训练方式。</p>
<ol>
<li><p>从头开始训练模型。需要提供<code>.prototxt</code>配置文件的路径，如：</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 训练，默认使用CPU</span></span><br><span class="line">./build/tools/caffe train \</span><br><span class="line">-solver examples/mnist/lenet_solver.prototxt</span><br><span class="line"><span class="comment"># 使用编号为2 的GPU训练</span></span><br><span class="line">./build/tools/caffe train \</span><br><span class="line">-solver examples/mnist/lenet_solver.prototxt \</span><br><span class="line">-gpu 2</span><br></pre></td></tr></table></figure>
</li>
<li><p>从snapshot中恢复训练。需要提供<code>.solverstate</code>文件路径</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 提供 -snapshot继续训练</span></span><br><span class="line">./build/tools/caffe train \</span><br><span class="line">-solver examples/mnist/lenet_solver.prototxt \</span><br><span class="line">-snapshot examples/mnist/lenet_iter_5000.solverstate</span><br></pre></td></tr></table></figure>

<p> <font color="orange" size="4">如果最初设定的最大训练次数不够的话</font>，可以在配置文件<code>lenet_prototxt.solver</code>中修改<code>max_iter: 10000</code>，比如增加此时为20000.</p>
</li>
<li><p>使用预训练模型微调(迁移学习)。需要提供<code>.caffemodel</code>文件路径</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 指明 -weights 关键字，提供预训练模型</span></span><br><span class="line">./build/tools/caffe train \</span><br><span class="line">-solver examples/finetuning_on_flickr_style/solver.prototxt \</span><br><span class="line">-weights models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel</span><br></pre></td></tr></table></figure>

<p> 这里由完整的微调例子<code>examples/finetuning_on_flickr_style</code></p>
</li>
</ol>
<h3 id="多GPU并行"><a href="#多GPU并行" class="headerlink" title="多GPU并行"></a>多GPU并行</h3><p>在<code>-gpu</code>后指定要使用的GPU编号，如<code>-gpu 0,1,2,3</code>，表示使用4个GPU并行计算。使用多GPU时，相同的网络配置会被分配到每一个gpu，每一个GPU所处理数据的batch_size相同，所以，整体并行处理的数据量是<code>batch_size*4</code>。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用可用的所有GPU设备</span></span><br><span class="line">caffe train -solver examples/mnist/lenet_solver.prototxt -gpu all</span><br></pre></td></tr></table></figure>

<h3 id="检查GPU"><a href="#检查GPU" class="headerlink" title="检查GPU"></a>检查GPU</h3><p>使用如下命令检查指定GPU是否正常工作：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./build/tools/caffe device_query -gpu 0</span><br></pre></td></tr></table></figure>
<p>返回0号GPU的硬件信息：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">I0603 16:40:28.905443 13455 caffe.cpp:138] Querying GPUs 0</span><br><span class="line">I0603 16:40:28.927069 13455 common.cpp:178] Device id:                     0</span><br><span class="line">I0603 16:40:28.927090 13455 common.cpp:179] Major revision number:         6</span><br><span class="line">I0603 16:40:28.927093 13455 common.cpp:180] Minor revision number:         1</span><br><span class="line">I0603 16:40:28.927096 13455 common.cpp:181] Name:                          GeForce GTX 1050</span><br><span class="line">I0603 16:40:28.927099 13455 common.cpp:182] Total global memory:           2099904512</span><br><span class="line">I0603 16:40:28.927103 13455 common.cpp:183] Total shared memory per block: 49152</span><br><span class="line">I0603 16:40:28.927106 13455 common.cpp:184] Total registers per block:     65536</span><br><span class="line">I0603 16:40:28.927109 13455 common.cpp:185] Warp size:                     32</span><br><span class="line">I0603 16:40:28.927112 13455 common.cpp:186] Maximum memory pitch:          2147483647</span><br><span class="line">I0603 16:40:28.927115 13455 common.cpp:187] Maximum threads per block:     1024</span><br><span class="line">I0603 16:40:28.927119 13455 common.cpp:188] Maximum dimension of block:    1024, 1024, 64</span><br><span class="line">I0603 16:40:28.927122 13455 common.cpp:191] Maximum dimension of grid:     2147483647, 65535, 65535</span><br><span class="line">I0603 16:40:28.927125 13455 common.cpp:194] Clock rate:                    1493000</span><br><span class="line">I0603 16:40:28.927129 13455 common.cpp:195] Total constant memory:         65536</span><br><span class="line">I0603 16:40:28.927151 13455 common.cpp:196] Texture alignment:             512</span><br><span class="line">I0603 16:40:28.927155 13455 common.cpp:197] Concurrent copy and execution: Yes</span><br><span class="line">I0603 16:40:28.927160 13455 common.cpp:199] Number of multiprocessors:     5</span><br><span class="line">I0603 16:40:28.927183 13455 common.cpp:200] Kernel execution timeout:      Yes</span><br></pre></td></tr></table></figure>

<h3 id="准确度测试"><a href="#准确度测试" class="headerlink" title="准确度测试"></a>准确度测试</h3><p>测试会给出模型的每一batch的loss和accuracy以及整体平均的loss和accuracy。<font color="red"><code>test</code>表示只进行forward计算，没有backward。即推理，而非训练</font>。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">./build/tools/caffe <span class="built_in">test</span> \</span><br><span class="line">-model examples/mnist/lenet_train_test.prototxt \</span><br><span class="line">-weights examples/mnist/lenet_iter_10000.caffemodel \</span><br><span class="line">-gpu 0 \</span><br><span class="line">-iterations 100</span><br></pre></td></tr></table></figure>

<p>在<code>lenet_train_test.prototxt</code>所定义的模型结构上，使用模型<code>lenet_iter_10000.caffemodel</code>，对测试样本执行100次iteration。batch_size为100，所以iteration×batch_size=10000，覆盖了所有的测试样本<font color="orange">这个测试数据在哪??</font></p>
<h3 id="时间测试"><a href="#时间测试" class="headerlink" title="时间测试"></a>时间测试</h3><p>指明<code>./build/tools/caffe time</code>测试模型，输出每一层的前先计算后向计算的时间。</p>
<ol>
<li><p>下面为lenet计时cpu计算10次迭代。（默认测试50次迭代）</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">./build/tools/caffe time \</span><br><span class="line">-model examples/mnist/lenet_train_test.prototxt \</span><br><span class="line">-iterations 10</span><br></pre></td></tr></table></figure>
<p> 结果：</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">I0603 17:30:35.768501 15346 caffe.cpp:365] *** Benchmark begins ***</span><br><span class="line">I0603 17:30:35.768518 15346 caffe.cpp:366] Testing <span class="keyword">for</span> 10 iterations.</span><br><span class="line">I0603 17:30:35.835475 15346 caffe.cpp:394] Iteration: 1 forward-backward time: 66 ms.</span><br><span class="line">I0603 17:30:35.902711 15346 caffe.cpp:394] Iteration: 2 forward-backward time: 67 ms.</span><br><span class="line">I0603 17:30:35.969769 15346 caffe.cpp:394] Iteration: 3 forward-backward time: 67 ms.</span><br><span class="line">I0603 17:30:36.036651 15346 caffe.cpp:394] Iteration: 4 forward-backward time: 66 ms.</span><br><span class="line">I0603 17:30:36.105055 15346 caffe.cpp:394] Iteration: 5 forward-backward time: 68 ms.</span><br><span class="line">I0603 17:30:36.174151 15346 caffe.cpp:394] Iteration: 6 forward-backward time: 69 ms.</span><br><span class="line">I0603 17:30:36.241129 15346 caffe.cpp:394] Iteration: 7 forward-backward time: 66 ms.</span><br><span class="line">I0603 17:30:36.308782 15346 caffe.cpp:394] Iteration: 8 forward-backward time: 67 ms.</span><br><span class="line">I0603 17:30:36.376447 15346 caffe.cpp:394] Iteration: 9 forward-backward time: 67 ms.</span><br><span class="line">I0603 17:30:36.443658 15346 caffe.cpp:394] Iteration: 10 forward-backward time: 67 ms.</span><br><span class="line">I0603 17:30:36.443676 15346 caffe.cpp:397] Average time per layer: </span><br><span class="line">I0603 17:30:36.443698 15346 caffe.cpp:400]      mnist	forward: 0.015 ms.</span><br><span class="line">I0603 17:30:36.443706 15346 caffe.cpp:403]      mnist	backward: 0.0009 ms.</span><br><span class="line">I0603 17:30:36.443711 15346 caffe.cpp:400]      conv1	forward: 7.4511 ms.</span><br><span class="line">I0603 17:30:36.443714 15346 caffe.cpp:403]      conv1	backward: 7.8538 ms.</span><br><span class="line">I0603 17:30:36.443718 15346 caffe.cpp:400]      pool1	forward: 3.3165 ms.</span><br><span class="line">I0603 17:30:36.443740 15346 caffe.cpp:403]      pool1	backward: 0.5728 ms.</span><br><span class="line">I0603 17:30:36.443745 15346 caffe.cpp:400]      conv2	forward: 12.81 ms.</span><br><span class="line">I0603 17:30:36.443769 15346 caffe.cpp:403]      conv2	backward: 25.1095 ms.</span><br><span class="line">I0603 17:30:36.443774 15346 caffe.cpp:400]      pool2	forward: 1.5992 ms.</span><br><span class="line">I0603 17:30:36.443778 15346 caffe.cpp:403]      pool2	backward: 0.5698 ms.</span><br><span class="line">I0603 17:30:36.443783 15346 caffe.cpp:400]        ip1	forward: 2.6873 ms.</span><br><span class="line">I0603 17:30:36.443787 15346 caffe.cpp:403]        ip1	backward: 4.9053 ms.</span><br><span class="line">I0603 17:30:36.443791 15346 caffe.cpp:400]      relu1	forward: 0.0563 ms.</span><br><span class="line">I0603 17:30:36.443809 15346 caffe.cpp:403]      relu1	backward: 0.0507 ms.</span><br><span class="line">I0603 17:30:36.443814 15346 caffe.cpp:400]        ip2	forward: 0.1712 ms.</span><br><span class="line">I0603 17:30:36.443819 15346 caffe.cpp:403]        ip2	backward: 0.2362 ms.</span><br><span class="line">I0603 17:30:36.443845 15346 caffe.cpp:400]       loss	forward: 0.0529 ms.</span><br><span class="line">I0603 17:30:36.443848 15346 caffe.cpp:403]       loss	backward: 0.0013 ms.</span><br><span class="line">I0603 17:30:36.443868 15346 caffe.cpp:408] Average Forward pass: 28.1725 ms.</span><br><span class="line">I0603 17:30:36.443892 15346 caffe.cpp:410] Average Backward pass: 39.3101 ms.</span><br><span class="line">I0603 17:30:36.443895 15346 caffe.cpp:412] Average Forward-Backward: 67.5 ms.</span><br><span class="line">I0603 17:30:36.443900 15346 caffe.cpp:414] Total Time: 675 ms.</span><br><span class="line">I0603 17:30:36.443918 15346 caffe.cpp:415] *** Benchmark ends ***</span><br></pre></td></tr></table></figure></li>
<li><p>使用GPU测试10 侧迭代：</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">./build/tools/caffe time \</span><br><span class="line">-model examples/mnist/lenet_train_test.prototxt \</span><br><span class="line">-gpu 0 \</span><br><span class="line">-iterations 10</span><br></pre></td></tr></table></figure>

<p> 结果：</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">I0603 17:32:11.830056 15434 caffe.cpp:365] *** Benchmark begins ***</span><br><span class="line">... <span class="comment"># 省略</span></span><br><span class="line">I0603 17:32:11.876488 15434 caffe.cpp:414] Total Time: 43.9143 ms.</span><br><span class="line">I0603 17:32:11.876494 15434 caffe.cpp:415] *** Benchmark ends ***</span><br></pre></td></tr></table></figure>
</li>
<li><p>测试某个训练好的模型各层执行时间。</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">./build/tools/caffe time \</span><br><span class="line">-model examples/mnist/lenet_train_test.prototxt \</span><br><span class="line">-weights examples/mnist/lenet_iter_10000.caffemodel \</span><br><span class="line">-gpu 0 \</span><br><span class="line">-iterations 10</span><br></pre></td></tr></table></figure>
<h1 id="python接口-pycaffe"><a href="#python接口-pycaffe" class="headerlink" title="python接口 pycaffe"></a>python接口 pycaffe</h1></li>
</ol>
<p>pycaffe接口需要先编译，看<a href="https://ashburnlee.github.io/2020/03/06/caffe-%E5%AE%89%E8%A3%85%E5%8F%8Atrouble-shooting/" target="_blank" rel="noopener">这里</a></p>
<p>在<code>caffe/examples</code>中的ipython notebook中是使用pycaffe的实例。 </p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/06/03/caffe-%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%8Epython%E6%8E%A5%E5%8F%A3/" data-id="ckaz6nepw0000edfz4ynb076l" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Caffe/" rel="tag">Caffe</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-cpp-lambda-function" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/06/03/cpp-lambda-function/" class="article-date">
  <time datetime="2020-06-03T04:54:16.000Z" itemprop="datePublished">2020-06-03</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/C/">C++</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/06/03/cpp-lambda-function/">cpp-lambda function</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>在STL中的许多函数都需要提供一个<code>binary comp function</code>，指明是从大到小还是从小到大，比如<code>sort()</code>函数，最大最小堆等。</p>
<p>这个 <code>comp</code>函数 可以是函数指针或函数对象。也可以是个<code>lambda</code>函数：</p>
<h2 id="lambda函数"><a href="#lambda函数" class="headerlink" title="lambda函数"></a>lambda函数</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cout</span>&lt;&lt;[](<span class="keyword">float</span> f)-&gt;<span class="keyword">int</span> &#123;<span class="keyword">return</span> <span class="built_in">abs</span>(f)&#125;;(<span class="number">-3.5</span>)&lt;&lt;<span class="built_in">endl</span>;</span><br></pre></td></tr></table></figure>
<p>返回3.</p>
<p>其中<code>[]</code>中是<code>lambda indicators</code>。用法如下：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[ ]：<span class="comment">//不捕获任何外部变量</span></span><br><span class="line">[=]：<span class="comment">//以值的形式捕获所有外部变量</span></span><br><span class="line">[&amp;]：<span class="comment">//以引用的形式捕获所有外部变量</span></span><br><span class="line">[x, &amp;y]：<span class="comment">//x以值捕获，y以引用捕获</span></span><br><span class="line">[=, &amp;z]：<span class="comment">//z以引用捕获，其他以值形式捕获</span></span><br><span class="line">[&amp;, x]：<span class="comment">//x以值行形式捕获，其他以引用形式捕获</span></span><br></pre></td></tr></table></figure>

<p>例子：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> comp = [](<span class="keyword">const</span> <span class="keyword">auto</span>&amp; x, <span class="keyword">const</span> <span class="keyword">auto</span>&amp; y) &#123; <span class="keyword">return</span> x.second &lt; y.second; &#125;;</span><br><span class="line"></span><br><span class="line">sort(vec.begin(), vec.end(), comp)</span><br><span class="line">sort(vec.begin(), vec.end(), [](<span class="keyword">auto</span> x, <span class="keyword">auto</span> y)&#123;<span class="keyword">return</span> x&gt;y&#125;);</span><br></pre></td></tr></table></figure>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/06/03/cpp-lambda-function/" data-id="ckayvo1uj0000sffz0sm18y4i" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-pip下载加速" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/06/03/pip%E4%B8%8B%E8%BD%BD%E5%8A%A0%E9%80%9F/" class="article-date">
  <time datetime="2020-06-03T04:45:06.000Z" itemprop="datePublished">2020-06-03</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Utility/">Utility</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/06/03/pip%E4%B8%8B%E8%BD%BD%E5%8A%A0%E9%80%9F/">pip下载加速</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>pip下载时添加国内源：</p>
<p>清华：<a href="https://pypi.tuna.tsinghua.edu.cn/simple" target="_blank" rel="noopener">https://pypi.tuna.tsinghua.edu.cn/simple</a> \</p>
<h2 id="临时使用："><a href="#临时使用：" class="headerlink" title="临时使用："></a>临时使用：</h2><p>可以在使用pip的时候加参数<code>-i https://pypi.tuna.tsinghua.edu.cn/simple</code></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -i https://pypi.tuna.tsinghua.edu.cn/simple protobuf</span><br></pre></td></tr></table></figure>

<h2 id="永久修改："><a href="#永久修改：" class="headerlink" title="永久修改："></a>永久修改：</h2><p>Linux下，在文件<code>~/.pip/pip.conf</code> (没有就创建一个文件夹及文件)添加内容如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[global]</span><br><span class="line">index-url &#x3D; https:&#x2F;&#x2F;pypi.tuna.tsinghua.edu.cn&#x2F;simple</span><br><span class="line">[install]</span><br><span class="line">trusted-host&#x3D;mirrors.aliyun.com</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/06/03/pip%E4%B8%8B%E8%BD%BD%E5%8A%A0%E9%80%9F/" data-id="ckayvgf000009lufzeopu6kdu" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-论文下载加速" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/06/03/%E8%AE%BA%E6%96%87%E4%B8%8B%E8%BD%BD%E5%8A%A0%E9%80%9F/" class="article-date">
  <time datetime="2020-06-03T04:07:07.000Z" itemprop="datePublished">2020-06-03</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Utility/">Utility</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/06/03/%E8%AE%BA%E6%96%87%E4%B8%8B%E8%BD%BD%E5%8A%A0%E9%80%9F/">论文下载加速</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>如果你使用科学上网，那么在arxiv上下载论文没有什么问题，如果没有，下面方法可以解决加载下载缓慢的问题。</p>
<h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><p>使用中科院arxiv的镜像地址：<a href="http://xxx.itp.ac.cn" target="_blank" rel="noopener">http://xxx.itp.ac.cn</a></p>
<h2 id="具体使用"><a href="#具体使用" class="headerlink" title="具体使用"></a>具体使用</h2><p>将要访问 arxiv 链接中的域名从 <a href="https://arxiv.org" target="_blank" rel="noopener">https://arxiv.org</a> 换成 <a href="http://xxx.itp.ac.cn" target="_blank" rel="noopener">http://xxx.itp.ac.cn</a> </p>
<p>如：</p>
<p><a href="https://arxiv.org/pdf/1608.00367" target="_blank" rel="noopener">https://arxiv.org/pdf/1608.00367</a></p>
<p>换成：</p>
<p><a href="http://xxx.itp.ac.cn/pdf/1608.00367" target="_blank" rel="noopener">http://xxx.itp.ac.cn/pdf/1608.00367</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/06/03/%E8%AE%BA%E6%96%87%E4%B8%8B%E8%BD%BD%E5%8A%A0%E9%80%9F/" data-id="ckayvgf01000alufz9zx0ggnw" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-LeetCode-对称的二叉树" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/06/03/LeetCode-%E5%AF%B9%E7%A7%B0%E7%9A%84%E4%BA%8C%E5%8F%89%E6%A0%91/" class="article-date">
  <time datetime="2020-06-03T02:51:30.000Z" itemprop="datePublished">2020-06-03</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/LeetCode/">LeetCode</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/06/03/LeetCode-%E5%AF%B9%E7%A7%B0%E7%9A%84%E4%BA%8C%E5%8F%89%E6%A0%91/">LeetCode-对称的二叉树</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>判断一棵二叉树是否是对称的，例子如下。左边数是一个对称二叉树，而右边不是：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">    5               5</span><br><span class="line">   &#x2F; \             &#x2F; \</span><br><span class="line">  4   4           5   5</span><br><span class="line"> &#x2F;\   &#x2F;\         &#x2F;\   &#x2F;</span><br><span class="line">7 8   8 7       5 5  5</span><br></pre></td></tr></table></figure>

<h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h2><p>对于左边的树，既然对称那么遍历顺序<code>root-&gt;l-&gt;r</code>与<code>root-&gt;r-&gt;l</code>得到的节点序列是相同的。均为{5,4,7,8,4,8,7}，而对于右边的非对称树，两种遍历序列也是相同的。所以此方法不可行，而且还用到额外的存储空间。</p>
<p>但是如果将遍历到的空结点也放入序列中，就可以了。不过下面的实现，使用online方法，避免二外空间的使用。</p>
<h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"> * struct TreeNode &#123;</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     TreeNode *left;</span></span><br><span class="line"><span class="comment"> *     TreeNode *right;</span></span><br><span class="line"><span class="comment"> *     TreeNode() : val(0), left(nullptr), right(nullptr) &#123;&#125;</span></span><br><span class="line"><span class="comment"> *     TreeNode(int x) : val(x), left(nullptr), right(nullptr) &#123;&#125;</span></span><br><span class="line"><span class="comment"> *     TreeNode(int x, TreeNode *left, TreeNode *right) : val(x), left(left), right(right) &#123;&#125;</span></span><br><span class="line"><span class="comment"> * &#125;;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">isSymmetric</span><span class="params">(TreeNode* root)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> symetric(root, root);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">symetric</span><span class="params">(TreeNode* root1, TreeNode* root2)</span></span>&#123;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 都为空：</span></span><br><span class="line">        <span class="keyword">if</span> (root1==<span class="literal">nullptr</span> &amp;&amp; root2==<span class="literal">nullptr</span>) <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        <span class="comment">// 只有一个为空：</span></span><br><span class="line">        <span class="keyword">if</span> (root1==<span class="literal">nullptr</span> || root2==<span class="literal">nullptr</span>) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        <span class="comment">// 都不为空，但值不相等</span></span><br><span class="line">        <span class="keyword">if</span> (root1-&gt;val != root2-&gt;val) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 值相等： </span></span><br><span class="line">        <span class="comment">// 则继续判断 root1-&gt;左==root2-&gt;右 &amp;&amp; root1-&gt;右==root2-&gt;左</span></span><br><span class="line">        <span class="keyword">return</span> symetric(root1-&gt;left, root2-&gt;right) &amp;&amp; </span><br><span class="line">                symetric(root1-&gt;right, root2-&gt;left);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>体会这里完备的表达式：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 都为空：</span></span><br><span class="line"><span class="keyword">if</span> (root1==<span class="literal">nullptr</span> &amp;&amp; root2==<span class="literal">nullptr</span>) <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line"><span class="comment">// 只有一个为空：</span></span><br><span class="line"><span class="keyword">if</span> (root1==<span class="literal">nullptr</span> || root2==<span class="literal">nullptr</span>) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line"><span class="comment">// 都不为空，但值不相等</span></span><br><span class="line"><span class="keyword">if</span> (root1-&gt;val != root2-&gt;val) <span class="keyword">return</span> <span class="literal">false</span>;</span><br></pre></td></tr></table></figure>
<p>neat！！</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/06/03/LeetCode-%E5%AF%B9%E7%A7%B0%E7%9A%84%E4%BA%8C%E5%8F%89%E6%A0%91/" data-id="ckayvgezn0000lufz33zucfsj" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Algorithms/" rel="tag">Algorithms</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-LeetCode-判断是否是子树" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/06/03/LeetCode-%E5%88%A4%E6%96%AD%E6%98%AF%E5%90%A6%E6%98%AF%E5%AD%90%E6%A0%91/" class="article-date">
  <time datetime="2020-06-03T02:09:46.000Z" itemprop="datePublished">2020-06-03</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/LeetCode/">LeetCode</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/06/03/LeetCode-%E5%88%A4%E6%96%AD%E6%98%AF%E5%90%A6%E6%98%AF%E5%AD%90%E6%A0%91/">LeetCode-判断是否是子树</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>有两棵树，A和B，判断B是否是A的子树。<br>如下图左为A，右为B：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">    <span class="number">5</span></span><br><span class="line">   / \</span><br><span class="line">  <span class="number">4</span>   <span class="number">6</span>           <span class="number">4</span></span><br><span class="line"> / \   \         / \</span><br><span class="line"><span class="number">7</span>   <span class="number">8</span>   <span class="number">9</span>       <span class="number">7</span>   <span class="number">8</span></span><br><span class="line">   / \</span><br><span class="line">  <span class="number">1</span>   <span class="number">2</span></span><br></pre></td></tr></table></figure>

<p>有两种情况：</p>
<ol>
<li>B 可以只是A子树的一部分。那么上例中B是A的子树。</li>
<li>B 严格是A的子树。那么上例中B不是A的子树。</li>
</ol>
<h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h2><p>两种情况主题思路是一样的：<br>第一步，在Ａ中找与B的根节点一样的结点。先序遍历，如果B的根节点与Ａ的当前结点不同，那么分别考察Ａ的左子树和右子树。</p>
<p>第二步，当在Ａ中找到B的根节点一样的结点Ｒ后，判断Ａ以Ｒ为树根的子树是否与Ｂ相同。此时就要区分上述两种情况了。</p>
<h2 id="实现："><a href="#实现：" class="headerlink" title="实现："></a>实现：</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="comment">// 先序遍历找到R</span></span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">findR</span><span class="params">(Node* s, Node* t)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (!s &amp;&amp; !t) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        <span class="keyword">if</span> (!s || !t) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">bool</span> res = <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (s-&gt;val == t-&gt;val) &#123;</span><br><span class="line">            res = isSubTree(s, t);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (!res) res = findR(s-&gt;left, t);</span><br><span class="line">        <span class="keyword">if</span> (!res) res = findR(s-&gt;right, t);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">isSubTree</span><span class="params">(Node* a, Node* b)</span> </span>&#123;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">/// relativaly equal 第一种情况</span></span><br><span class="line">        <span class="keyword">if</span> (a==<span class="literal">nullptr</span> &amp;&amp; b==<span class="literal">nullptr</span>) <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        <span class="keyword">if</span> (a==<span class="literal">nullptr</span> &amp;&amp; b!=<span class="literal">nullptr</span>) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        <span class="keyword">if</span> (a!=<span class="literal">nullptr</span> &amp;&amp; b==<span class="literal">nullptr</span>) <span class="keyword">return</span> <span class="literal">true</span>; </span><br><span class="line"></span><br><span class="line">        <span class="comment">/// absolutly equal 第二种情况</span></span><br><span class="line">        <span class="comment">//if (a==nullptr &amp;&amp; b==nullptr) return true;</span></span><br><span class="line">        <span class="comment">//if ((!a &amp;&amp; b) || (a &amp;&amp; !b)) return false;  </span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (a-&gt;val != b-&gt;val) <span class="keyword">return</span>  <span class="literal">false</span>;</span><br><span class="line">        <span class="keyword">return</span> isSubTree(a-&gt;left, b-&gt;left) &amp;&amp; isSubTree(a-&gt;right, b-&gt;right);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>注意：</p>
<ol>
<li>只要访问一个对象，就要提前判断这个对象是否合法。</li>
<li>树的问题绝大数情况是要对数进行遍历，上述问题就是先序遍历。</li>
<li>注意递归返回值，返回值是bool型，</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/06/03/LeetCode-%E5%88%A4%E6%96%AD%E6%98%AF%E5%90%A6%E6%98%AF%E5%AD%90%E6%A0%91/" data-id="ckayvgezr0001lufzcv442wvd" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Algorithms/" rel="tag">Algorithms</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-caffe-sigmoid-cross-entropy-loss-layer类" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/06/02/caffe-sigmoid-cross-entropy-loss-layer%E7%B1%BB/" class="article-date">
  <time datetime="2020-06-01T22:46:30.000Z" itemprop="datePublished">2020-06-02</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Caffe/">Caffe</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/06/02/caffe-sigmoid-cross-entropy-loss-layer%E7%B1%BB/">caffe-sigmoid_cross_entropy_loss_layer类</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="sigmoid-cross-entropy-loss-layer类"><a href="#sigmoid-cross-entropy-loss-layer类" class="headerlink" title="sigmoid_cross_entropy_loss_layer类"></a>sigmoid_cross_entropy_loss_layer类</h1><p>头文件： <code>./include/caffe/layers/sigmoid_cross_entropy_loss_layer.hpp</code><br>CPU实现： <code>./src/caffe/layers/sigmoid_cross_entropy_loss_layer.cpp</code><br>GPU实现： <code>./src/caffe/layers/sigmoid_cross_entropy_loss_layer.cu</code></p>
<h2 id="所需要基本操作的CPU和GPU实现："><a href="#所需要基本操作的CPU和GPU实现：" class="headerlink" title="所需要基本操作的CPU和GPU实现："></a>所需要基本操作的CPU和GPU实现：</h2><p><code>bottom_diff = sigmoid_output_data - target</code> 的实现如下</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// CPU</span></span><br><span class="line">caffe_sub(count, sigmoid_output_data, target, bottom_diff):</span><br><span class="line"></span><br><span class="line"><span class="comment">// 对应的GPU</span></span><br><span class="line">caffe_copy(count, sigmoid_output_data, bottom_diff);</span><br><span class="line">caffe_gpu_axpy(count, Dtype(<span class="number">-1</span>), target, bottom_diff);</span><br></pre></td></tr></table></figure>

<p><code>bottom_diff</code> 中每个元素乘以<code>loss_weight</code>， 共操作<code>count</code>个元素。其实现如下：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// CPU</span></span><br><span class="line">caffe_scal(count, loss_weight, bottom_diff);</span><br><span class="line"><span class="comment">// GPU</span></span><br><span class="line">caffe_gpu_scal(count, loss_weight, bottom_diff);</span><br></pre></td></tr></table></figure>

<p>上述函数分别使用了<code>cBLAS</code> 和<code>cuBlas</code>两个库函数。<code>sigmoid_output_data</code>是前向传播的结果。上述两步其实是反向传播的过程，最终将结果写入<code>bottom_diff</code>中，它是<code>Blob</code>的一部分，会随着数据的走向继续传播下去。</p>
<h2 id="后向传播"><a href="#后向传播" class="headerlink" title="后向传播"></a>后向传播</h2><ol>
<li><p>CPU</p>
 <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="keyword">void</span> SigmoidCrossEntropyLossLayer&lt;Dtype&gt;::Backward_cpu(</span><br><span class="line">						<span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; top, </span><br><span class="line">						<span class="keyword">const</span> <span class="built_in">vector</span>&lt;<span class="keyword">bool</span>&gt;&amp; propagate_down,</span><br><span class="line">						<span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom) &#123;</span><br><span class="line"><span class="keyword">if</span> (propagate_down[<span class="number">1</span>]) &#123;</span><br><span class="line">	LOG(FATAL) &lt;&lt; <span class="keyword">this</span>-&gt;type()</span><br><span class="line">			&lt;&lt; <span class="string">" Layer cannot backpropagate to label inputs."</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (propagate_down[<span class="number">0</span>]) &#123;</span><br><span class="line">	<span class="comment">// First, compute the diff</span></span><br><span class="line">	<span class="keyword">const</span> <span class="keyword">int</span> count = bottom[<span class="number">0</span>]-&gt;count();</span><br><span class="line">	<span class="keyword">const</span> Dtype* sigmoid_output_data = sigmoid_output_-&gt;cpu_data();</span><br><span class="line">	<span class="keyword">const</span> Dtype* target = bottom[<span class="number">1</span>]-&gt;cpu_data();</span><br><span class="line">	Dtype* bottom_diff = bottom[<span class="number">0</span>]-&gt;mutable_cpu_diff();</span><br><span class="line">	caffe_sub(count, sigmoid_output_data, target, bottom_diff);</span><br><span class="line">	<span class="comment">// Zero out gradient of ignored targets.</span></span><br><span class="line">	<span class="keyword">if</span> (has_ignore_label_) &#123;</span><br><span class="line">	<span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; count; ++i) &#123;</span><br><span class="line">			<span class="keyword">const</span> <span class="keyword">int</span> target_value = <span class="keyword">static_cast</span>&lt;<span class="keyword">int</span>&gt;(target[i]);</span><br><span class="line">			<span class="keyword">if</span> (target_value == ignore_label_) &#123;</span><br><span class="line">				bottom_diff[i] = <span class="number">0</span>;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// Scale down gradient</span></span><br><span class="line">	Dtype loss_weight = top[<span class="number">0</span>]-&gt;cpu_diff()[<span class="number">0</span>] / normalizer_;</span><br><span class="line">	caffe_scal(count, loss_weight, bottom_diff);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p> 因为是在CPU端，与GPU无关，所以上述code中没有<code>gpu_data</code>或<code>gpu_diff</code>。<br> 主要操作，取数据，执行操作：</p>
 <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 取Blob数据</span></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> count = bottom[<span class="number">0</span>]-&gt;count();</span><br><span class="line"><span class="keyword">const</span> Dtype* sigmoid_output_data = sigmoid_output_-&gt;cpu_data();</span><br><span class="line"><span class="keyword">const</span> Dtype* target = bottom[<span class="number">1</span>]-&gt;cpu_data();</span><br><span class="line">Dtype* bottom_diff = bottom[<span class="number">0</span>]-&gt;mutable_cpu_diff();</span><br><span class="line"><span class="comment">// 如上述操作</span></span><br><span class="line">caffe_sub(count, sigmoid_output_data, target, bottom_diff);</span><br></pre></td></tr></table></figure>
</li>
<li><p>GPU</p>
<p> 与cpu相似：</p>
 <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="keyword">void</span> SigmoidCrossEntropyLossLayer&lt;Dtype&gt;::Backward_gpu(</span><br><span class="line">						<span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; top, </span><br><span class="line">						<span class="keyword">const</span> <span class="built_in">vector</span>&lt;<span class="keyword">bool</span>&gt;&amp; propagate_down,</span><br><span class="line">						<span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom) &#123;</span><br><span class="line">	<span class="keyword">if</span> (propagate_down[<span class="number">1</span>]) &#123;</span><br><span class="line">	LOG(FATAL) &lt;&lt; <span class="keyword">this</span>-&gt;type()</span><br><span class="line">				&lt;&lt; <span class="string">" Layer cannot backpropagate to label inputs."</span>;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> (propagate_down[<span class="number">0</span>]) &#123;</span><br><span class="line">		<span class="comment">// First, compute the diff</span></span><br><span class="line">		<span class="keyword">const</span> <span class="keyword">int</span> count = bottom[<span class="number">0</span>]-&gt;count();</span><br><span class="line">		<span class="keyword">const</span> Dtype* sigmoid_output_data = sigmoid_output_-&gt;gpu_data();</span><br><span class="line">		<span class="keyword">const</span> Dtype* target = bottom[<span class="number">1</span>]-&gt;gpu_data();</span><br><span class="line">		Dtype* bottom_diff = bottom[<span class="number">0</span>]-&gt;mutable_gpu_diff();</span><br><span class="line">		caffe_copy(count, sigmoid_output_data, bottom_diff);</span><br><span class="line">		caffe_gpu_axpy(count, Dtype(<span class="number">-1</span>), target, bottom_diff);</span><br><span class="line">		<span class="comment">// Zero out gradient of ignored targets.</span></span><br><span class="line">		<span class="keyword">if</span> (has_ignore_label_) &#123;</span><br><span class="line">			<span class="comment">// NOLINT_NEXT_LINE(whitespace/operators)</span></span><br><span class="line">			SigmoidCrossEntropyLossIgnoreDiffGPU&lt;Dtype&gt;&lt;&lt;&lt;CAFFE_GET_BLOCKS(count),</span><br><span class="line">			CAFFE_CUDA_NUM_THREADS&gt;&gt;&gt;(count, ignore_label_, target, bottom_diff);</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">// Scale down gradient</span></span><br><span class="line">		Dtype loss_weight = top[<span class="number">0</span>]-&gt;cpu_diff()[<span class="number">0</span>] / normalizer_;</span><br><span class="line">		caffe_gpu_scal(count, loss_weight, bottom_diff);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p> 加上kernel函数，其作用是将不需要计算梯度的位置设为零，与CPU含义相同：</p>
 <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line">__<span class="function">global__ <span class="keyword">void</span> <span class="title">SigmoidCrossEntropyLossIgnoreDiffGPU</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">						<span class="keyword">const</span> <span class="keyword">int</span> count,</span></span></span><br><span class="line"><span class="function"><span class="params">						<span class="keyword">const</span> <span class="keyword">int</span> ignore_label, </span></span></span><br><span class="line"><span class="function"><span class="params">						<span class="keyword">const</span> Dtype* target, </span></span></span><br><span class="line"><span class="function"><span class="params">						Dtype* diff)</span> </span>&#123;</span><br><span class="line">		CUDA_KERNEL_LOOP(i, count) &#123;</span><br><span class="line">			<span class="keyword">const</span> <span class="keyword">int</span> target_value = <span class="keyword">static_cast</span>&lt;<span class="keyword">int</span>&gt;(target[i]);</span><br><span class="line">			<span class="keyword">if</span> (target_value == ignore_label) &#123;</span><br><span class="line">				diff[i] = <span class="number">0</span>;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</li>
</ol>
<h2 id="前向传播"><a href="#前向传播" class="headerlink" title="前向传播"></a>前向传播</h2><p>头文件中的成员属性：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// 一个SigmoidLayer类对象指针，预测值到概率值的映射</span></span><br><span class="line"><span class="built_in">shared_ptr</span>&lt;SigmoidLayer&lt;Dtype&gt; &gt; sigmoid_layer_;</span><br><span class="line"><span class="comment">/// 接收SigmoidLayer的输出.</span></span><br><span class="line"><span class="built_in">shared_ptr</span>&lt;Blob&lt;Dtype&gt; &gt; sigmoid_output_;</span><br><span class="line"><span class="comment">/// bottom vector holder to call the underlying SigmoidLayer::Forward</span></span><br><span class="line"><span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt; sigmoid_bottom_vec_;</span><br><span class="line"><span class="comment">/// top vector holder to call the underlying SigmoidLayer::Forward</span></span><br><span class="line"><span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt; sigmoid_top_vec_;</span><br><span class="line"><span class="comment">/// Whether to ignore instances with a certain label.</span></span><br><span class="line"><span class="keyword">bool</span> has_ignore_label_;</span><br><span class="line"><span class="comment">/// The label indicating that an instance should be ignored.</span></span><br><span class="line"><span class="keyword">int</span> ignore_label_;</span><br><span class="line"><span class="comment">/// How to normalize the loss.</span></span><br><span class="line">LossParameter_NormalizationMode normalization_;</span><br><span class="line">Dtype normalizer_;</span><br><span class="line"><span class="keyword">int</span> outer_num_, inner_num_;</span><br></pre></td></tr></table></figure>

<p>先执行forward操作：<code>sigmoid_layer_-&gt;Forward(_, _)</code> 。其参数<code>sigmoid_bottom_vec_</code>和<code>sigmoid_top_vec_</code>是两个该类的成员变量，其值随操作的执行而改变，这里要改变的是前者，这个实现在源码中的成员函数<code>LayerSetUp()</code>。</p>
<p><code>sigmoid_layer_</code>也是成员变量，其定义：<code>shared_ptr&lt;SigmoidLayer&lt;Dtype&gt; &gt; sigmoid_layer_;</code>。CPU和GPU实现见下：</p>
<ol>
<li><p>CPU</p>
 <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="keyword">void</span> SigmoidCrossEntropyLossLayer&lt;Dtype&gt;::Forward_cpu(</span><br><span class="line">						<span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom, </span><br><span class="line">						<span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) &#123;</span><br><span class="line">	<span class="comment">// The forward pass computes the sigmoid outputs.</span></span><br><span class="line">	<span class="comment">// 1. Forward计算sigmoid 的输出，并且取数据</span></span><br><span class="line">	sigmoid_bottom_vec_[<span class="number">0</span>] = bottom[<span class="number">0</span>];</span><br><span class="line">	sigmoid_layer_-&gt;Forward(sigmoid_bottom_vec_, sigmoid_top_vec_);</span><br><span class="line">	<span class="comment">// Compute the loss (negative log likelihood)</span></span><br><span class="line">	<span class="comment">// Stable version of loss computation from input data</span></span><br><span class="line">	<span class="keyword">const</span> Dtype* input_data = bottom[<span class="number">0</span>]-&gt;cpu_data();</span><br><span class="line">	<span class="keyword">const</span> Dtype* target = bottom[<span class="number">1</span>]-&gt;cpu_data();</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 2. 计算 对数似然</span></span><br><span class="line">	<span class="keyword">int</span> valid_count = <span class="number">0</span>;</span><br><span class="line">	Dtype loss = <span class="number">0</span>;</span><br><span class="line">	<span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; bottom[<span class="number">0</span>]-&gt;count(); ++i) &#123;</span><br><span class="line">		<span class="keyword">const</span> <span class="keyword">int</span> target_value = <span class="keyword">static_cast</span>&lt;<span class="keyword">int</span>&gt;(target[i]);</span><br><span class="line">		<span class="keyword">if</span> (has_ignore_label_ &amp;&amp; target_value == ignore_label_) &#123;</span><br><span class="line">			<span class="keyword">continue</span>;</span><br><span class="line">		&#125;</span><br><span class="line">		loss -= input_data[i] * (target[i] - (input_data[i] &gt;= <span class="number">0</span>)) -</span><br><span class="line">			<span class="built_in">log</span>(<span class="number">1</span> + <span class="built_in">exp</span>(input_data[i] - <span class="number">2</span> * input_data[i] * (input_data[i] &gt;= <span class="number">0</span>)));</span><br><span class="line">		++valid_count;</span><br><span class="line">	&#125;</span><br><span class="line">	normalizer_ = get_normalizer(normalization_, valid_count);</span><br><span class="line">	top[<span class="number">0</span>]-&gt;mutable_cpu_data()[<span class="number">0</span>] = loss / normalizer_;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</li>
</ol>
<p>再看<code>sigmoid_layer_-&gt;Forward(_, _);</code>，<code>SigmoidLayer</code>类并没有<code>Formard()</code>方法，所以此方法一定是从其父类继承而来。看源码找到继承顺序：<code>SigmoidLayer::NeuronLayer::Layer</code>，所以这里的<code>Forward()</code>是<code>Layer</code>类的方法，祥看<code>Layer.hpp</code>。</p>
<ol start="2">
<li><p>GPU</p>
<p> 与CPU类似，将CPU中的for循环由kernel函数代替：</p>
 <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line">__<span class="function">global__ <span class="keyword">void</span> <span class="title">SigmoidCrossEntropyLossForwardGPU</span><span class="params">(<span class="keyword">const</span> <span class="keyword">int</span> nthreads,</span></span></span><br><span class="line"><span class="function"><span class="params">		<span class="keyword">const</span> Dtype* input_data, <span class="keyword">const</span> Dtype* target, Dtype* loss,</span></span></span><br><span class="line"><span class="function"><span class="params">		<span class="keyword">const</span> <span class="keyword">bool</span> has_ignore_label_, <span class="keyword">const</span> <span class="keyword">int</span> ignore_label_,</span></span></span><br><span class="line"><span class="function"><span class="params">		Dtype* counts)</span> </span>&#123;</span><br><span class="line">	CUDA_KERNEL_LOOP(i, nthreads) &#123;</span><br><span class="line">		<span class="keyword">const</span> <span class="keyword">int</span> target_value = <span class="keyword">static_cast</span>&lt;<span class="keyword">int</span>&gt;(target[i]);</span><br><span class="line">		<span class="keyword">if</span> (has_ignore_label_ &amp;&amp; target_value == ignore_label_) &#123;</span><br><span class="line">			loss[i] = <span class="number">0</span>;</span><br><span class="line">			counts[i] = <span class="number">0</span>;</span><br><span class="line">		&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">			loss[i] = input_data[i] * (target[i] - (input_data[i] &gt;= <span class="number">0</span>)) -</span><br><span class="line">				<span class="built_in">log</span>(<span class="number">1</span> + <span class="built_in">exp</span>(input_data[i] - <span class="number">2</span> * input_data[i] *</span><br><span class="line">				(input_data[i] &gt;= <span class="number">0</span>)));</span><br><span class="line">			counts[i] = <span class="number">1</span>;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p> GPU中的前传播：</p>
 <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span> SigmoidCrossEntropyLossLayer&lt;Dtype&gt;::Forward_gpu()&#123;...&#125;</span><br></pre></td></tr></table></figure>
<p> 函数体省略，不过在源码中有一点提出：</p>
 <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Since this memory is not used for anything, we use it here to avoid having</span></span><br><span class="line"><span class="comment">// to allocate new GPU memory to accumulate intermediate results.</span></span><br><span class="line">Dtype* loss_data = bottom[<span class="number">0</span>]-&gt;mutable_gpu_diff();</span><br><span class="line">Dtype* count_data = bottom[<span class="number">1</span>]-&gt;mutable_gpu_diff();</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line"><span class="comment">// Clear scratch memory to prevent interfering with backward (see #6202).</span></span><br><span class="line">caffe_gpu_set(bottom[<span class="number">0</span>]-&gt;count(), Dtype(<span class="number">0</span>), bottom[<span class="number">0</span>]-&gt;mutable_gpu_diff());</span><br><span class="line">caffe_gpu_set(bottom[<span class="number">1</span>]-&gt;count(), Dtype(<span class="number">0</span>), bottom[<span class="number">1</span>]-&gt;mutable_gpu_diff());</span><br></pre></td></tr></table></figure>

<p> 这是CPU版本中没有的，因为kernel函数中需要传入对象数组，但是这部分的地址没有被开辟，所以为了避免在GPU上为中间结果开辟空间，所以使用Blob的暂时没有使用到的部分，作为临时存储空间，只不过，函数结束后要清理这部分空间。</p>
<h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><p> 这个类除了上述的方法，还有其他方法详见源文件。</p>
</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/06/02/caffe-sigmoid-cross-entropy-loss-layer%E7%B1%BB/" data-id="ckax32ye80002lcfz8wrwhkd6" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Caffe/" rel="tag">Caffe</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-caffe-sigmoidLayer类" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/06/02/caffe-sigmoidLayer%E7%B1%BB/" class="article-date">
  <time datetime="2020-06-01T22:44:29.000Z" itemprop="datePublished">2020-06-02</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Caffe/">Caffe</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/06/02/caffe-sigmoidLayer%E7%B1%BB/">caffe-sigmoidLayer类</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>源码初体验，看一下sigmoid_layer类。</p>
<h1 id="sigmoid-layers类"><a href="#sigmoid-layers类" class="headerlink" title="sigmoid_layers类"></a>sigmoid_layers类</h1><p>这个类的所有内容</p>
<p>头文件： <code>./include/caffe/layers/sigmoid_layer.hpp</code><br>CPU实现： <code>./src/caffe/layers/sigmoid_layer.cpp</code><br>GPU实现：<code>./src/caffe/layers/sigmoid_layer.cu</code></p>
<p>对于这个类的官方文档<a href="http://caffe.berkeleyvision.org/tutorial/net_layer_blob.html" target="_blank" rel="noopener">见此</a></p>
<h2 id="头文件sigmoid-layer-hpp中包含"><a href="#头文件sigmoid-layer-hpp中包含" class="headerlink" title="头文件sigmoid_layer.hpp中包含"></a>头文件sigmoid_layer.hpp中包含</h2><ol>
<li>继承自NeuronLayer::Layer类的构造函数：SigmoidLayer()</li>
<li>返回这个列的名字：type()</li>
<li>前先计算的CPU声明：Forward_cpu()和GPU声明：Forward_gpu()</li>
<li>后传计算的CPU声明：Backward_cpu()和GPU声明：Backward_gpu()</li>
</ol>
<h2 id="前向传播"><a href="#前向传播" class="headerlink" title="前向传播"></a>前向传播</h2><ol>
<li><p>CPU</p>
<p> 前向计算是将bottom数据经过sigmoid函数得到top数据。所以其基本操作是sigmoid()。CPU实现：</p>
 <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Dtype <span class="title">sigmoid</span><span class="params">(Dtype x)</span> </span>&#123;</span><br><span class="line">	<span class="keyword">return</span> <span class="number">0.5</span> * <span class="built_in">tanh</span>(<span class="number">0.5</span> * x) + <span class="number">0.5</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p> 有了sigmoid()，前向传播计算如下：</p>
 <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span> SigmoidLayer&lt;Dtype&gt;::Forward_cpu(<span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom, <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) &#123;</span><br><span class="line">	Dtype* bottom_data = bottom[<span class="number">0</span>]-&gt;cpu_data();</span><br><span class="line">	Dtype* top_data = top[<span class="number">0</span>]-&gt;mutable_cpu_data();</span><br><span class="line">	<span class="keyword">int</span> count = bottom[<span class="number">0</span>]-&gt;count();</span><br><span class="line"></span><br><span class="line">	<span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; count; ++i) &#123;</span><br><span class="line">		top_data[i] = sigmoid(bottom_data[i]);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p> Blob是caffe中最小的数据载体，Blob的定义见Blob的笔记博客。</p>
</li>
<li><p>GPU<br> sigmoid()对应的GPU实现：</p>
 <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">__<span class="function">global__ <span class="keyword">void</span> <span class="title">SigmoidForward</span><span class="params">(<span class="keyword">const</span> <span class="keyword">int</span> n, <span class="keyword">const</span> Dtype* in, Dtype* out)</span> </span>&#123;</span><br><span class="line">	CUDA_KERNEL_LOOP(index, n) &#123;</span><br><span class="line">		out[index] = <span class="number">0.5</span> * <span class="built_in">tanh</span>(<span class="number">0.5</span> * in[index]) + <span class="number">0.5</span>;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p> 其中<code>CUDA_KERNEL_LOOP(index, n)</code>给定线程id，并且将线程映射到数据上，实现数据并行。其宏定义在这里<code>include/caffe/util/device_alternate.hpp</code>：</p>
 <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// CUDA: grid stride looping</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> CUDA_KERNEL_LOOP(i, n) \</span></span><br><span class="line"> 	<span class="keyword">for</span> (<span class="keyword">int</span> i = blockIdx.x * blockDim.x + threadIdx.x; \</span><br><span class="line">      i &lt; (n); \</span><br><span class="line">      i += blockDim.x * gridDim.x)</span><br></pre></td></tr></table></figure>
<p> 这是个通用的循环，具体细节见关于CUDA的笔记博客。</p>
<p> 同样的，GPU的前行传播：</p>
 <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span> SigmoidLayer&lt;Dtype&gt;::Forward_gpu(<span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom, <span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) &#123;</span><br><span class="line">	Dtype* bottom_data = bottom[<span class="number">0</span>]-&gt;gpu_data();</span><br><span class="line">	Dtype* top_data = top[<span class="number">0</span>]-&gt;mutable_gpu_data();</span><br><span class="line">	<span class="keyword">int</span> count = bottom[<span class="number">0</span>]-&gt;count();</span><br><span class="line"></span><br><span class="line">	SigmoidForward&lt;Dtype&gt;&lt;&lt;&lt;CAFFE_GET_BLOCKS(count), CAFFE_CUDA_NUM_THREADS&gt;&gt;&gt;(</span><br><span class="line">	count, bottom_data, top_data);</span><br><span class="line">	CUDA_POST_KERNEL_CHECK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p> 其中指定了当下机器每block可用threads数目，并可计算出使用到的block数。</p>
<p> 具体地：<code>CAFFE_CUDA_NUM_THREADS</code>=512，每个block启用512个threads，而    <code>CAFFE_GET_BLOCKS(count)</code>：</p>
 <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">inline</span> <span class="keyword">int</span> <span class="title">CAFFE_GET_BLOCKS</span><span class="params">(<span class="keyword">const</span> <span class="keyword">int</span> N)</span> </span>&#123;</span><br><span class="line">	<span class="keyword">return</span> (N + <span class="number">512</span> - <span class="number">1</span>) / <span class="number">512</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p> 对于像sigmoid简单的算子，直观上看，GPU实现其实就是将CPU实现的最内层的循环去掉，用并行执行的kernel函数替代。</p>
</li>
</ol>
<h2 id="后向传播"><a href="#后向传播" class="headerlink" title="后向传播"></a>后向传播</h2><ol>
<li><p>CPU</p>
<p> 根据sigmoid 反向传播公式可以很容易写出如下：{<font color="red" size="4">将code中去掉的const都加上</font>}</p>
 <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span> SigmoidLayer&lt;Dtype&gt;::Backward_cpu(</span><br><span class="line">							<span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; top,</span><br><span class="line">							<span class="built_in">vector</span>&lt;<span class="keyword">bool</span>&gt;&amp; propagate_down,</span><br><span class="line">							<span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom) &#123;</span><br><span class="line">	<span class="keyword">if</span> (propagate_down[<span class="number">0</span>]) &#123;</span><br><span class="line">		Dtype* top_data = top[<span class="number">0</span>]-&gt;cpu_data();</span><br><span class="line">		Dtype* top_diff = top[<span class="number">0</span>]-&gt;cpu_diff();</span><br><span class="line">		Dtype* bottom_diff = bottom[<span class="number">0</span>]-&gt;mutable_cpu_diff();</span><br><span class="line">		<span class="keyword">int</span> count = bottom[<span class="number">0</span>]-&gt;count();</span><br><span class="line">		<span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; count; ++i) &#123;</span><br><span class="line">			<span class="keyword">const</span> Dtype sigmoid_x = top_data[i];</span><br><span class="line">			bottom_diff[i] = top_diff[i] * sigmoid_x * (<span class="number">1.</span> - sigmoid_x);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p> 其中<code>top_diff[i]</code>是与前行传播的输出有关的数值。</p>
</li>
<li><p>GPU</p>
<p> 对于GPU实现，只需将上述code 中最内层循环用kernel函数代替，所以要实现kernel函数：{<font color="red" size="4">将code中去掉的const都加上</font>}</p>
 <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">__<span class="function">global__ <span class="keyword">void</span> <span class="title">SigmoidBackward</span><span class="params">(<span class="keyword">const</span> <span class="keyword">int</span> n, </span></span></span><br><span class="line"><span class="function"><span class="params">							Dtype* in_diff,</span></span></span><br><span class="line"><span class="function"><span class="params">							Dtype* out_data, </span></span></span><br><span class="line"><span class="function"><span class="params">							Dtype* out_diff)</span> </span>&#123;</span><br><span class="line">	CUDA_KERNEL_LOOP(index, n) &#123;</span><br><span class="line">	Dtype sigmoid_x = out_data[index];</span><br><span class="line">		out_diff[index] = in_diff[index] * sigmoid_x * (<span class="number">1</span> - sigmoid_x);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p> 替换循环：{<font color="red" size="4">将code中去掉的const都加上</font>}</p>
 <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span> SigmoidLayer&lt;Dtype&gt;::Backward_gpu(<span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; top,</span><br><span class="line">							<span class="built_in">vector</span>&lt;<span class="keyword">bool</span>&gt;&amp; propagate_down,</span><br><span class="line">							<span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom) &#123;</span><br><span class="line">	<span class="keyword">if</span> (propagate_down[<span class="number">0</span>]) &#123;</span><br><span class="line">		Dtype* top_data = top[<span class="number">0</span>]-&gt;gpu_data();</span><br><span class="line">		Dtype* top_diff = top[<span class="number">0</span>]-&gt;gpu_diff();</span><br><span class="line">		Dtype* bottom_diff = bottom[<span class="number">0</span>]-&gt;mutable_gpu_diff();</span><br><span class="line">		<span class="keyword">int</span> count = bottom[<span class="number">0</span>]-&gt;count();</span><br><span class="line"></span><br><span class="line">		SigmoidBackward&lt;Dtype&gt;&lt;&lt;&lt;CAFFE_GET_BLOCKS(count), CAFFE_CUDA_NUM_THREADS&gt;&gt;&gt;(</span><br><span class="line">			count, top_diff, top_data, bottom_diff);</span><br><span class="line">		CUDA_POST_KERNEL_CHECK;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p> 上述很直接。</p>
</li>
</ol>
<p><font color="gree" size="5">敲黑板</font><br><font color="orange" size="4">技巧</font>：在linux中使用<code>grep</code>命令可以在一个项目中查找关键字：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep -n -H -r <span class="string">"CUDA_KERNEL_LOOP"</span></span><br></pre></td></tr></table></figure>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/06/02/caffe-sigmoidLayer%E7%B1%BB/" data-id="ckax32ycl0000lcfzhejk7s23" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Caffe/" rel="tag">Caffe</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-anaconda-虚拟环境" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/03/26/anaconda-%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83/" class="article-date">
  <time datetime="2020-03-25T23:54:49.000Z" itemprop="datePublished">2020-03-26</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Utility/">Utility</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/03/26/anaconda-%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83/">anaconda 虚拟环境</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="conda-虚拟环境"><a href="#conda-虚拟环境" class="headerlink" title="conda 虚拟环境"></a>conda 虚拟环境</h2><p>conda使得在不同项目中使用不同版本的包包，不同环境中的包互不冲突。<br>而且可以指定包的版本，非常方便。</p>
<p>常用命令：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">conda env list        <span class="comment"># 列出已存在的虚拟环境</span></span><br><span class="line">conda create --name yolo python=3.5  <span class="comment">#新建yolo环境并且安装python3.5</span></span><br><span class="line"></span><br><span class="line">conda activate yolo   <span class="comment">#进入或者切换到yolo</span></span><br><span class="line">conda deactivate</span><br><span class="line">conda info --envs</span><br><span class="line"></span><br><span class="line">conda search keras   <span class="comment">#搜索keras的所有可下载版本</span></span><br><span class="line">conda list -n yolo   <span class="comment">#列出yolo环境中已有 包</span></span><br><span class="line">conda install -n yolo keras==2.1.5  <span class="comment">#向指定环境中安装指定的包</span></span><br><span class="line"></span><br><span class="line">conda remove -n yolo keras</span><br><span class="line">conda upgrade -n yolo keras</span><br><span class="line"></span><br><span class="line">conda remove -n yolo --all    <span class="comment">#删除整个yolo环境</span></span><br><span class="line">conda create -n yolo --<span class="built_in">clone</span> yolov3   <span class="comment">#复制yolo环境</span></span><br><span class="line"></span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/</span><br><span class="line">conda config --<span class="built_in">set</span> show_channel_urls yes   <span class="comment">#设置搜索时显示通道地址</span></span><br><span class="line">conda config --show      <span class="comment">#产看镜像源</span></span><br></pre></td></tr></table></figure>

<h2 id="trouble-shooting"><a href="#trouble-shooting" class="headerlink" title="trouble shooting"></a>trouble shooting</h2><p>错误：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install: Segmentation fault</span><br></pre></td></tr></table></figure>

<p>原因：由于网络或者其他原因，包下载不完整。</p>
<p>解决：清除所有不完整的缓存，后重新安装。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda clean -a</span><br></pre></td></tr></table></figure>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/03/26/anaconda-%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83/" data-id="ckatxvx5c0002lzfzd7ej0jyx" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-LeetCode-nowcoder-深入理解链表" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/03/12/LeetCode-nowcoder-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E9%93%BE%E8%A1%A8/" class="article-date">
  <time datetime="2020-03-12T09:40:51.000Z" itemprop="datePublished">2020-03-12</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/LeetCode/">LeetCode</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/03/12/LeetCode-nowcoder-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E9%93%BE%E8%A1%A8/">LeetCode-符串通配符</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>自己处理输入输出</p>
<ul>
<li><p>描述：</p>
<p>  实现如下2个通配符：</p>
<ol>
<li><p><code>*</code>：匹配0个或以上的字符（字符由英文字母和数字0-9组成，不区分大小写。下同）</p>
</li>
<li><p><code>？</code>：匹配1个字符</p>
<p>input:先输入一个带有通配符的字符串，再输入一个需要匹配的字符串。如：</p>
<p><code>te?t*.*</code> <br><code>txt12.xls</code></p>
<p>output:返回匹配的结果，正确输出true，错误输出false。如上例返回false。</p>
</li>
</ol>
</li>
<li><p>思路：</p>
<ol>
<li>终止条件先后有序</li>
<li>对于<code>if(*str1 == &#39;*&#39;)</code>中，三个递归match，好好体会三种情况<ol>
<li><code>a*c</code>, <code>ac</code>。<code>*</code>与0个匹配</li>
<li><code>a*c</code>, <code>abc</code>。<code>*</code>与1个匹配</li>
<li><code>a*c</code>, <code>abbbc</code>。<code>*</code>与多个匹配</li>
</ol>
</li>
</ol>
</li>
<li><p>实现：</p>
  <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">match</span><span class="params">(<span class="keyword">char</span>* str1, <span class="keyword">char</span>* str2)</span></span>&#123;</span><br><span class="line">    <span class="comment">// 终止条件 同时到字符串尾，放回true</span></span><br><span class="line">    <span class="keyword">if</span>(*str1 == <span class="string">'\0'</span>  &amp;&amp; *str2 == <span class="string">'\0'</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    <span class="comment">// 只有一个到尾，返回false。不会两者都到尾，因为上一个if判断过了</span></span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span>(*str1 == <span class="string">'\0'</span> || *str2 == <span class="string">'\0'</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    <span class="comment">// 对于‘？’，一定匹配，所以查看下一对字符</span></span><br><span class="line">    <span class="keyword">if</span>(*str1 == <span class="string">'?'</span>)</span><br><span class="line">        <span class="keyword">return</span> match(str1+<span class="number">1</span>, str2+<span class="number">1</span>);</span><br><span class="line">    <span class="comment">// 当两个字符相等，一定匹配，查看下一对字符</span></span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span>(*str1 == *str2)</span><br><span class="line">        <span class="keyword">return</span> match(str1+<span class="number">1</span>, str2+<span class="number">1</span>);</span><br><span class="line">        </span><br><span class="line">    <span class="comment">// 对于‘*’, 匹配零个，一个或多个</span></span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span>(*str1 == <span class="string">'*'</span>)</span><br><span class="line">        <span class="keyword">return</span> match(str1+<span class="number">1</span>, str2) ||    <span class="comment">//零个</span></span><br><span class="line">               match(str1+<span class="number">1</span>, str2+<span class="number">1</span>) ||  <span class="comment">// 一个</span></span><br><span class="line">               match(str1, str2+<span class="number">1</span>);      <span class="comment">// 多个</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="keyword">char</span> str1[<span class="number">100</span>], str2[<span class="number">100</span>];</span><br><span class="line">    <span class="keyword">while</span>(<span class="built_in">cin</span>&gt;&gt;str1&gt;&gt;str2)&#123;</span><br><span class="line">        <span class="keyword">if</span>(match(str1, str2))</span><br><span class="line">            <span class="built_in">cout</span>&lt;&lt;<span class="string">"true"</span>&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            <span class="built_in">cout</span>&lt;&lt;<span class="string">"false"</span>&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/03/12/LeetCode-nowcoder-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E9%93%BE%E8%A1%A8/" data-id="ckatsrgs1002txqfz3xpwejc8" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Algorithms/" rel="tag">Algorithms</a></li></ul>

    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    
    <a class="extend prev" rel="prev" href="/page/3/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span><a class="page-number" href="/page/5/">5</a><a class="page-number" href="/page/6/">6</a><span class="space">&hellip;</span><a class="page-number" href="/page/15/">15</a><a class="extend next" rel="next" href="/page/5/">Next &amp;raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/C/">C++</a><span class="category-list-count">13</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/CUDA/">CUDA</a><span class="category-list-count">37</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Caffe/">Caffe</a><span class="category-list-count">18</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Deep-Learning/">Deep Learning</a><span class="category-list-count">11</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/LeetCode/">LeetCode</a><span class="category-list-count">30</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linear-Algebra/">Linear Algebra</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Machine-Learning/">Machine Learning</a><span class="category-list-count">15</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Reinforcement-Learning/">Reinforcement Learning</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Utility/">Utility</a><span class="category-list-count">12</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%BE%85%E5%BD%92%E7%B1%BB/">待归类</a><span class="category-list-count">3</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Algorithms/" rel="tag">Algorithms</a><span class="tag-list-count">57</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CUDA/" rel="tag">CUDA</a><span class="tag-list-count">35</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Caffe/" rel="tag">Caffe</a><span class="tag-list-count">18</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Test-Analysis/" rel="tag">Test Analysis</a><span class="tag-list-count">6</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Algorithms/" style="font-size: 20px;">Algorithms</a> <a href="/tags/CUDA/" style="font-size: 16.67px;">CUDA</a> <a href="/tags/Caffe/" style="font-size: 13.33px;">Caffe</a> <a href="/tags/Test-Analysis/" style="font-size: 10px;">Test Analysis</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/07/">July 2020</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/06/">June 2020</a><span class="archive-list-count">31</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/03/">March 2020</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/02/">February 2020</a><span class="archive-list-count">15</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">January 2020</a><span class="archive-list-count">12</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">December 2019</a><span class="archive-list-count">10</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">November 2019</a><span class="archive-list-count">6</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/10/">October 2019</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/09/">September 2019</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/08/">August 2019</a><span class="archive-list-count">38</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/07/">July 2019</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/1970/01/">January 1970</a><span class="archive-list-count">1</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2020/07/19/CUDA-%E7%BA%BF%E7%A8%8B-warp-%E5%BB%B6%E6%97%B6%E9%9A%90%E8%97%8F/">CUDA-线程-warp-延时隐藏</a>
          </li>
        
          <li>
            <a href="/2020/07/14/LeetCode-Trie-search-regular-expression/">LeetCode-Trie-search regular expression</a>
          </li>
        
          <li>
            <a href="/2020/07/12/LeetCode-Trie/">LeetCode-Trie</a>
          </li>
        
          <li>
            <a href="/2020/07/11/LeetCode-BST-%E6%89%BE%E5%89%8D%E9%A9%B1%E4%B8%8E%E5%90%8E%E7%BB%A7%E7%BB%93%E7%82%B9/">LeetCode-BST 找前驱与后继结点</a>
          </li>
        
          <li>
            <a href="/2020/07/08/CUDA-%E5%B9%B6%E8%A1%8CRadix-Sort/">CUDA-并行Radix Sort</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2020 Junhui<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div>
</body>
</html>